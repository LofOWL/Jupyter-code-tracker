[{"block": 0, "type": "code", "linesLength": 1, "startIndex": 0, "lines": ["## parameters:\n\n#################################\n## data parameters:\n#################################\n\n## number of rows to process\nnum_rows = 10**7\n## number of categorical variables; will process categorical variables 0:n_sparse_features\nn_sparse_features = 26\n## number of numeric features; numeric variables 0:n_num_features \nn_num_features = 13\n\n#################################\n## Feature Engineering parameters:\n#################################\n\n# categorical_var_strategy = 'targ-enc' ## options are 'string-index' or 'targ-enc'\n# replace_small_levels = False\ncategorical_var_strategy = 'string-index' ## options are 'string-index' or 'targ-enc'\nreplace_small_levels = True\nsmall_level_freq_thresh = 10 ## same threshold used by winners: https://www.csie.ntu.edu.tw/~r01922136/kaggle-2014-criteo.pdf\n## constructed variables:\nfile_tail = 'try2'\ntable_to_save = 'criteo_dac_proc_{}sparse_{}num_{}freqthresh_{}rows_{}catstrat+{}'.format(n_sparse_features,n_num_features, small_level_freq_thresh, num_rows, categorical_var_strategy, file_tail)\n\noutput_dir = 'dbfs:/mnt/adlsgen2'\n\n#################################\n## LightGBM params\n#################################\n\nclassifier_lightgbm_iterations = 3  \nn_folds = 4                         \nnum_leaves_grid = [32,64]\n\n#################################\n## Control and Verbosity Parameters\n#################################\n\n## run describe on the input table\ndescribe = False\n## save the result of the preprocessing pipeline as a table.\nsave_as_table = False\nrun_crossvalidation = False\n\nimport os\n\noutfile = os.path.join(output_dir,table_to_save+'.parquet')\n\nprint(outfile)\n"]}, {"block": 1, "type": "markdown", "linesLength": 1, "startIndex": 1, "lines": ["## load data loader"]}, {"block": 2, "type": "code", "linesLength": 1, "startIndex": 2, "lines": ["# from reco_utils.dataset.criteo_dac import load_spark_df"]}, {"block": 3, "type": "code", "linesLength": 1, "startIndex": 3, "lines": ["## read in the data - this takes some time...8-10 minutes\n# df = load_spark_df(spark=spark, dbutils=dbutils)\n## print('writing to parquet...')\n## df.write.parquet('dbfs:/FileStore/dac_train.parquet')\n# df = sqlContext.read.parquet(\"/FileStore/dac_train.parquet\")\ndf = sqlContext.read.parquet('dbfs:/mnt/adlsgen2/dac_train_nocatna.parquet')\n# Could ADLS be causing issues?\n# df = sqlContext.read.parquet(\"/mnt/adlsgen2/dac_train.parquet\")"]}, {"block": 4, "type": "markdown", "linesLength": 1, "startIndex": 4, "lines": ["## Get number of rows"]}, {"block": 5, "type": "code", "linesLength": 1, "startIndex": 5, "lines": ["total_rows = df.count()\nprint('{} rows in raw data file. Limiting this to {} ({}\\%)'.format(total_rows, num_rows, num_rows/total_rows))\nif num_rows > 0:\n  df = df.limit(num_rows)"]}, {"block": 6, "type": "markdown", "linesLength": 1, "startIndex": 6, "lines": ["## Describe the data"]}, {"block": 7, "type": "code", "linesLength": 1, "startIndex": 7, "lines": ["if describe:\n  ## This can take quite a bit of time...\n  cur_descr = df.describe()\n  display(cur_descr)"]}, {"block": 8, "type": "code", "linesLength": 1, "startIndex": 8, "lines": ["## boundary check n_sparse_features\nif n_sparse_features < 0 or n_sparse_features > 26:\n  raise ValueError('n_sparse_features must be between 0 and 26...')\nelse:\n  print('Running with {} sparse (i.e. categorical) features.'.format(n_sparse_features))\n  \n## boundary check n_num_features\nif n_num_features < 0 or n_num_features > 13:\n  raise ValueError('n_num_features must be between 0 and 13...')\nelse:\n  print('Running with {} numeric features.'.format(n_num_features))\n  \nif n_num_features+n_sparse_features < 1:\n  raise ValueError('total number of features is less than 1.')"]}, {"block": 9, "type": "markdown", "linesLength": 1, "startIndex": 9, "lines": ["## Imports"]}, {"block": 10, "type": "code", "linesLength": 1, "startIndex": 10, "lines": ["## for feature engineering:\nfrom pyspark.sql.functions import col, when, count, isnan\nfrom pyspark.ml.feature import (Imputer,StringIndexer,VectorAssembler)\nfrom pyspark.ml.pipeline import Pipeline\n\n## for modeling:\nfrom mmlspark import LightGBMClassifier\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n"]}, {"block": 11, "type": "markdown", "linesLength": 1, "startIndex": 11, "lines": ["## Define what features to process\n\n- `features` maps to numeric features that need to have missing values replaced\n- `sparse_features` maps to the first `n_sparse_features` categorical / string variables"]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 12, "lines": ["\n## features are int features (does median imputation)\nfeatures = [x for x in df.columns if x[0:3] == 'int'][0:n_num_features]\n## sparse_features are str features \nsparse_features = [x for x in df.columns if x[0:3] == 'cat'][0:n_sparse_features]\n\nprint(sparse_features)"]}, {"block": 13, "type": "markdown", "linesLength": 1, "startIndex": 13, "lines": ["## Fill Missing Values in String Vars"]}, {"block": 14, "type": "code", "linesLength": 1, "startIndex": 14, "lines": ["## fill  missing values in string variables\n## done already and saved above - something weird was going on, where this transformation wasn't propagating to fcut...\n## df = df.na.fill('M', subset = sparse_features)\n## df.write.mode('overwrite').parquet('dbfs:/mnt/adlsgen2/dac_train_nocatna.parquet')\n\nprint(sparse_features)\nprint(df.count())\nfor i in sparse_features:\n  display(df.select([count(when(col(c).isNull(), c)).alias(c) for c in sparse_features]))\n"]}, {"block": 15, "type": "markdown", "linesLength": 1, "startIndex": 15, "lines": ["## Replace infrequent levels with a special value"]}, {"block": 16, "type": "code", "linesLength": 1, "startIndex": 16, "lines": ["## only do it if replace_small_levels is true AND small_level_freq_thresh\nif small_level_freq_thresh > 0 and replace_small_levels:\n  ## count frequency of levels, and repalce if F <= threshold for each categorical variable\n  print('Assigning Rare levels a special value')\n  fcut_cat_levels_dict = {i: df.groupby(i).count().\n   select(i, when(col('count') > small_level_freq_thresh, col(i)).otherwise(\"RARE\").alias(i+'_fcut')) for i in sparse_features}\n  ## now join them back...\n  for i in sparse_features:\n    df = df.join(fcut_cat_levels_dict[i], i, how = 'left')\n  ## update the variables we're using as sparse variables:\n  sparse_features = [f + '_fcut' for f in sparse_features]\n  print('Categorical Features updated to be: {}'.format(' '.join(sparse_features)))"]}, {"block": 17, "type": "code", "linesLength": 1, "startIndex": 17, "lines": ["## do additional work if doing targ-enc\nif categorical_var_strategy == 'targ-enc':\n  ## have to do additional work to compute p(label|level)\n  ## this should be done only on training data then applied to testing. Note for later.\n  labelbylevel_dict = {i: df.groupby(i).mean('label').select([i, col(\"avg(label)\").alias(i+\"_trgt\")]) for i in sparse_features}  \n  ## set up the graph to do all the joins:\n  for i in sparse_features:\n    df = df.join(labelbylevel_dict[i], i, how = \"left\")\n  ## update the variables we're using as sparse:\n  sparse_features = [f + '_trgt' for f in sparse_features]\n  print('Categorical Features updated to be: {}'.format(' '.join(sparse_features)))"]}, {"block": 18, "type": "markdown", "linesLength": 1, "startIndex": 18, "lines": ["## Recast `int` variables to `float`\n\n`Imputer()` only works with `float` or `double` type. We could import the data as floats, or run directly on ints using the `df.na.fill()` method.\n\nCurrently using this approach to keep the work in the pipeline."]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 19, "lines": ["## cast ints to floats, because Imputer only works with floats\n## and only pull out the strings with the frequency cutoff\nsql_lst = ['cast({} as float) {}'.format(x, x) for x in features] + sparse_features + ['label']\nrecast_df = df.selectExpr(*[sql_lst])"]}, {"block": 20, "type": "code", "linesLength": 1, "startIndex": 20, "lines": ["## persist to disk to trigger transforms\n## about 25 minutes on l16s x 4\n## time depends on steps and parameters above.\n# recast_df.write.mode('overwrite').parquet(outfile)\n# del recast_df\nrecast_df = sqlContext.read.parquet(outfile)"]}, {"block": 21, "type": "code", "linesLength": 1, "startIndex": 21, "lines": ["num_imputer = Imputer(strategy='median',\n              inputCols=features,\n              outputCols=[f + '_imp' for f in features])\n\nif categorical_var_strategy == 'string-index':\n  print('Using StringIndexer for categorical variables.')\n  pipeline = Pipeline(stages=[\n    num_imputer,\n    # LightGBM can handle categoricals directly if StringIndexer is used through meta-data\n    *[StringIndexer(inputCol=f, outputCol=f+'_vec') for f in sparse_features],\n    VectorAssembler(inputCols= [f + '_imp' for f in features] +\n                    [f + '_vec' for f in sparse_features],\n                    outputCol='features')\n  ])\nelif categorical_var_strategy == 'targ-enc':\n  print('Using target-encoding for categorical variables.')\n  ## build the pipeline\n  pipeline = Pipeline(stages=[\n    num_imputer,\n    VectorAssembler(inputCols= [f + '_imp' for f in features] +\n                    [f for f in sparse_features],\n                    outputCol='features')\n  ])  \nelse:\n  raise ValueError('Unknown strategy for categorical_var_strategy. Should be either \"string-index\" or \"targ-enc\"')"]}, {"block": 22, "type": "code", "linesLength": 1, "startIndex": 22, "lines": ["## run the pipeline:\ntrain_proc_df = pipeline.fit(recast_df).transform(recast_df)"]}, {"block": 23, "type": "code", "linesLength": 1, "startIndex": 23, "lines": ["from pyspark.sql.functions import isnan, when, count, col\n\nprint(sparse_features)\nfor i in sparse_features:\n  display(train_proc_df.select([count(when(col(c).isNull(), c)).alias(c) for c in sparse_features]))\n#  display(train_proc_df.select([count(when(isnan(c), c)).alias(c) for c in df.columns]))"]}, {"block": 24, "type": "code", "linesLength": 1, "startIndex": 24, "lines": ["## save after pipeline? This can be an issue...\n## train_proc_df.write.mode('overwrite').parquet(outfile)"]}, {"block": 25, "type": "code", "linesLength": 1, "startIndex": 25, "lines": ["## describe label to see balance\nif describe:\n  display(train_proc_df.select(['label']).describe())"]}, {"block": 26, "type": "code", "linesLength": 1, "startIndex": 26, "lines": ["if describe:\n  display(train_proc_df.select('features').limit(2))"]}, {"block": 27, "type": "markdown", "linesLength": 1, "startIndex": 27, "lines": ["## Set up the Classifier:"]}, {"block": 28, "type": "code", "linesLength": 1, "startIndex": 28, "lines": ["model = LightGBMClassifier(featuresCol='features',\n                           labelCol='label',\n                           numIterations=classifier_lightgbm_iterations,\n                           numLeaves=31,\n                           maxDepth=10,\n                           isUnbalance=True)"]}, {"block": 29, "type": "markdown", "linesLength": 1, "startIndex": 29, "lines": ["## Fit the model.\n\nto see if simple use-case works"]}, {"block": 30, "type": "code", "linesLength": 1, "startIndex": 30, "lines": ["## try just fitting the model, not with CV\n## model fit works, sometimes.\n## failed I think with full data and 26 cat features l16s x 4\n## 10M rows and full columns: 7.5 minutes\nmodel_fit = model.fit(train_proc_df)"]}, {"block": 31, "type": "code", "linesLength": 1, "startIndex": 31, "lines": ["if run_crossvalidation:\n  grid = (ParamGridBuilder()\n          .addGrid(model.numLeaves, num_leaves_grid) \n          .build())\n  evaluator = BinaryClassificationEvaluator(labelCol='label')\n  cv = CrossValidator(estimator=model, estimatorParamMaps=grid, evaluator=evaluator, numFolds=n_folds)\n  cv_fit = cv.fit(train_proc_df)\n  print(cv_fit)"]}]