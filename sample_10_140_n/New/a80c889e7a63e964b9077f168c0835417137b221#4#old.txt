[{"block": 0, "type": "markdown", "linesLength": 23, "startIndex": 0, "lines": ["# Visualizations and more analysis with PmagPy\n", "\n", "This notebook demonstrates PmagPy functions that can be used to visualize data as well as those that conduct statistical tests that have associated visualizations.\n", "\n", "## Guide to PmagPy\n", "\n", "The notebook is one of a series of notebooks that demonstrate the functionality of PmagPy. The other notebooks are:\n", "\n", "- [PmagPy_introduction.ipynb](PmagPy_introduction.ipynb) This notebook introduces PmagPy and lists the functions that are demonstrated in the other notebooks. \n", "- [PmagPy_calculations.ipynb](PmagPy_calculations.ipynb) This notebook demonstrates many of the PmagPy calculation functions such as those that rotate directions, return statistical parameters, and simulate data from specified distributions\n", "- [PmagPy_MagIC.ipynb](PmagPy_MagIC.ipynb) This notebook demonstrates how PmagPy can be used to read and write data to and from the MagIC database format including conversion from many individual lab measurement file formats.\n", "\n", "## Customizing this notebook\n", "\n", "If you want to make changes to this notebook, you should make a copy (see File menu).  Otherwise each time you update **PmagPy**, your changes will be overwritten.\n", "\n", "## Get started\n", "\n", "To use the functions in this notebook, we have to   import the **PmagPy** modules **pmagplotlib**, **pmag** and **ipmag** and some other handy functions for use in the notebook.  This is done in the following code block which must be executed before running any other code block. To execute, click on the code block and then click on the \"Run\" button in the menu.  \n", "\n", "In order to access the example data, this notebook is meant to be run in the PmagPy-data directory (PmagPy directory for developers).\n", "\n", "Try it!  Run the code block below (click on the cell and then click 'Run'):"]}, {"block": 1, "type": "code", "linesLength": 23, "startIndex": 23, "lines": ["import pmagpy.pmag as pmag\n", "import pmagpy.pmagplotlib as pmagplotlib\n", "import pmagpy.ipmag as ipmag\n", "import pmagpy.contribution_builder as cb\n", "from pmagpy import convert_2_magic as convert\n", "import matplotlib.pyplot as plt # our plotting buddy\n", "import numpy as np # the fabulous NumPy package\n", "import pandas as pd # and of course Pandas\n", "# test if Basemap and/or cartopy is installed\n", "has_basemap, Basemap = pmag.import_basemap()\n", "has_cartopy, Cartopy = pmag.import_cartopy()\n", "# test if xlwt is installed (allows you to export to excel)\n", "try:\n", "    import xlwt\n", "    has_xlwt = True\n", "except ImportError:\n", "    has_xlwt = False\n", "# This allows you to make matplotlib plots inside the notebook.  \n", "%matplotlib inline \n", "from IPython.display import Image\n", "import os\n", "\n", "print('All modules imported!')"]}, {"block": 2, "type": "markdown", "linesLength": 50, "startIndex": 46, "lines": ["### Functions demonstrated within [PmagPy_plots_analysis.ipynb](PmagPy_plots_tests.ipynb):\n", "- Functions in **PmagPy_plots_tests.ipynb**\n", "    - [ani_depthplot](#ani_depthplot) : plots anisotropy data against depth in stratigraphic section (Xmas tree plots)\n", "    - [aniso_magic](#aniso_magic) : makes plots of anisotropy data and bootstrapped confidences \n", "    - [biplot_magic](#biplot_magic) : plots different columns against each other in MagIC formatted data files\n", "    - [chi_magic](#chi_magic) : plots magnetic susceptibility data in MagIC format as function of field, frequency or temperature\n", "    - [common_mean](#common_mean) : graphical approach to testing two sets of directions for common mean using bootstrap\n", "    - [cont_rot](#cont_rot) : makes plots of continents after rotation to specified coordinate system\n", "    - [core_depthplot](#core_depthplot) : plots MagIC formatted data \n", "    - [curie](#curie) : makes plots of Curie Temperature data and provides estimates for Tc\n", "    - [dayplot_magic](#dayplot_magic) : makes Day et al. (1977) and other plots with hysteresis statistics\n", "    - [dmag_magic](#dmag_magic) : plots remanence against demagnetization step for MagIC formatted files\n", "    - [eqarea](#eqarea) and [eqarea_magic](#eqarea_magic) : makes equal area projections for directions\n", "    - [eqarea_ell](#eqarea_ell) : makes equal area projections for directions with specified confidence ellipses\n", "    - [find_ei](#find_ei) : finds the inclination unflattening factor that unsquishes directions to match TK03 distribution\n", "    - [fishqq](#fishqq): makes a Quantile-Quantile plot for directions against uniform and exponential distributions\n", "    - [foldtest](#foldtest) & [foldtest_magic](#foldtest_magic) : finds  tilt correction that maximizes concentration of directions, with bootstrap confidence bounds.          \n", "    - [forc_diagram](#forc_diagram): plots FORC diagrams for both conventional and irregular FORCs\n", "    - [hysteresis_magic](#hysteresis_magic) : makes plots of hysteresis data (not FORCs). \n", "    - [irm_unmix](#irm_unmix) : analyzes IRM acquisition data in terms of coercivity distributions\n", "    - [irmaq_magic](#irm_magic) : plots IRM acquistion data\n", "    - [lnp_magic](#lnp_magic) : plots lines and planes for site level data and calculates best fit mean and alpha_95\n", "    - [lowes](#lowes) : makes a plot of the Lowe's spectrum for a geomagnetic field model\n", "    - [lowrie](#lowrie) and [lowrie_magic](#lowrie_magic) : makes plots of Lowrie's (1990) 3D-IRM demagnetization experiments\n", "    - [plot_cdf](#plot_cdf) and [plot_2cdfs](#plot_2cdfs) : makes a cumulative distribution plot of data\n", "    - [plotdi_a](#plotdi_a) : makes equal are plots of directions and their $\\alpha_{95}$s\n", "    - [plot_geomagia](#plot_geomagia) : makes plots from files downloaded from the  geomagia website\n", "    - [plot_mag_map](#plot_mag_map) : makes a color contour plot of geomagnetic field models\n", "    - [plot_magic_keys](#plot_magic_keys) : plots data from MagIC formatted data files\n", "    - [plot_map_pts](#plot_map_pts) : plots points on maps\n", "    - [plot_ts](#plot_ts) : makes a plot of the desired Geomagnetic Reversal time scale\n", "    - [polemap_magic](#polemap_magic) : reads in MagIC formatted file with paleomagnetic poles and plots them\n", "    - [qqplot](#qqplot) : makes a Quantile-Quantile plot for data against a normal distribution\n", "    - [qqunf](#qqunf) : makes a Quantile-Quantile plot for data against a uniform distribution\n", "    - [quick_hyst](#quick_hyst) : makes hysteresis plots\n", "    - [revtest](#revtest) & [revtest_magic](#revtest_magic) : performs a bootstrap reversals test\n", "    - [thellier_magic](#thellier_magic) : makes plots of thellier-thellier data. \n", "    - [vgpmap_magic](#vgpmap_magic) : reads in MagIC formatted file with virtual geomagnetic poles and plots them\n", "    - [watsons_v](#watsons_v) : makes a graph for Watson's V test for common mean\n", "    - [zeq](#zeq) and [zeq_magic](#zeq_magic) : makes quick zijderveld plots for measurement data\n", "\n", "- Maps: \n", "    - [cont_rot](#cont_rot) : makes plots of continents after rotation to specified coordinate system\n", "    - [plot_mag_map](#plot_mag_map) : makes a color contour plot of geomagnetic field models\n", "    - [plot_map_pts](#plot_map_pts) : plots points on maps\n", "    - [polemap_magic](#polemap_magic) : reads in MagIC formatted file with paleomagnetic poles and plots them\n", "    - [vgpmap_magic](#vgpmap_magic) : reads in MagIC formatted file with virtual geomagnetic poles and plots them\n", "\n", "\n", "\n"]}, {"block": 3, "type": "markdown", "linesLength": 11, "startIndex": 96, "lines": ["## Figures\n", "\n", "- The plotting functions make plots to the screen (using the  `%matplotlib inline` magic command), but all **matplotlib** plots can be saved with the command: \n", "\n", "`plt.savefig('PATH_TO_FILE_NAME.FMT') `\n", "\n", "and then viewed in the notebook with:\n", "\n", "`Image('PATH_TO_FILE_NAME.FMT')`\n", "\n", "\n"]}, {"block": 4, "type": "markdown", "linesLength": 8, "startIndex": 107, "lines": ["## ani_depthplot\n", "\n", "\n", "[\\[Essentials Chapter 13\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch13.html#x15-15600013) [\\[MagIC Database\\]](https://earthref.org/MagIC) [\\[command_line_version\\]](http://pmagpy.github.io/PmagPy-cli.html#ani_depthplot.py)\n", "\n", " Anisotropy data can be plotted versus depth. The program **ani_depthplot** uses MagIC formatted data tables. Bulk susceptibility measurements can also be plotted if they are available in a **measurements.txt** formatted file.\n", "\n", "In this example, we will use the data from Tauxe et al. (2015, doi:10.1016/j.epsl.2014.12.034) measured on samples obtained during Expedition 318 of the International Ocean Drilling Program. To get the entire dataset, go to the MagIC data base at: https://www2.earthref.org/MagIC/doi/10.1016/j.epsl.2014.12.034.  Download the data set and unpack it with [ipmag.download_magic](#download_magic).\n"]}, {"block": 5, "type": "markdown", "linesLength": 1, "startIndex": 115, "lines": ["We will use the **ipmag.ani_depthplot()** version of this program."]}, {"block": 6, "type": "code", "linesLength": 1, "startIndex": 116, "lines": ["help(ipmag.ani_depthplot)"]}, {"block": 7, "type": "markdown", "linesLength": 1, "startIndex": 117, "lines": ["And here we go:"]}, {"block": 8, "type": "code", "linesLength": 1, "startIndex": 118, "lines": ["ipmag.ani_depthplot(dir_path='data_files/ani_depthplot');"]}, {"block": 9, "type": "markdown", "linesLength": 9, "startIndex": 119, "lines": ["## aniso_magic\n", "\n", "\n", "[\\[Essentials Chapter 13\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch13.html#x15-15600013) [\\[MagIC Database\\]](https://earthref.org/MagIC) [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#aniso_magic.py)\n", "\n", " Samples were collected from the eastern margin a dike oriented with a bedding pole declination of 110\u2218 and dip of 2\u2218. The data have been imported into a MagIC (data model 3) formatted file named dike_specimens.txt.\n", "\n", "We will make a plot of the data using **ipmag.aniso_magic_nb()**, using the site parametric bootstrap option and plot out the bootstrapped eigenvectors. We will also draw on the trace of the dike.\n", "\n"]}, {"block": 10, "type": "code", "linesLength": 1, "startIndex": 128, "lines": ["help(ipmag.aniso_magic)"]}, {"block": 11, "type": "code", "linesLength": 1, "startIndex": 129, "lines": ["help(ipmag.aniso_magic_nb)"]}, {"block": 12, "type": "code", "linesLength": 2, "startIndex": 130, "lines": ["ipmag.aniso_magic_nb(infile='dike_specimens.txt',dir_path='data_files/aniso_magic',\n", "       iboot=1,ihext=0,ivec=1,PDir=[120,10],ipar=1, save_plots=False) # compare dike directions with plane of dike with pole of 120,10"]}, {"block": 13, "type": "markdown", "linesLength": 5, "startIndex": 132, "lines": [" The specimen eigenvectors are plotted in the top diagram with the usual convention that squares are the V$_1$ directions, triangles are the V$_2$ directions and circles are the V$_3$ directions. All directions are plotted on the lower hemisphere. The bootstrapped eigenvectors are shown in the middle diagram. Cumulative distributions of the bootstrapped eigenvalues are shown in the bottom plot with the 95% confidence bounds plotted as vertical lines. It appears that the magma was moving in the northern and slightly up direction along the dike.\n", "\n", "There are more options to **ipmag.aniso_magic_nb()** that come in handy. In particular, one often wishes to test if a particular fabric is isotropic (the three eigenvalues cannot be distinguished), or if a particular eigenvector is parallel to some direction. For example, undisturbed sedimentary fabrics are oblate (the maximum and intermediate directions cannot be distinguished from one another, but are distinct from the minimum) and the eigenvector associated with the minimum eigenvalue is vertical. These criteria can be tested using the distributions of bootstrapped eigenvalues and eigenvectors.\n", "\n", "The following session illustrates how this is done, using the data in the test file sed_specimens.txt in the aniso_magic directory. "]}, {"block": 14, "type": "code", "linesLength": 2, "startIndex": 137, "lines": ["ipmag.aniso_magic_nb(infile='sed_specimens.txt',dir_path='data_files/aniso_magic',\n", "       iboot=1,ihext=0,ivec=1,Dir=[0,90],vec=3,ipar=1, save_plots=False) # parametric bootstrap and compare V3 with vertical"]}, {"block": 15, "type": "markdown", "linesLength": 1, "startIndex": 139, "lines": ["The top three plots are as in the dike example before, showing a clear triaxial fabric (all three eigenvalues and associated eigenvectors are distinct from one another. In the lower three plots we have the distributions of the three components of the chosen axis, V$_3$, their 95% confidence bounds (dash lines) and the components of the designated direction (solid line). This direction is also shown in the equal area projection above as a red pentagon. The minimum eigenvector is not vertical in this case. "]}, {"block": 16, "type": "markdown", "linesLength": 9, "startIndex": 140, "lines": ["## biplot_magic \n", "\n", "[\\[Essentials Chapter 8\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch8.html#x15-1560008) [\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#biplot_magic.py)\n", "\n", "It is often useful to plot measurements from one experiement against another. For example, rock magnetic studies of sediments often plot the IRM against the ARM or magnetic susceptibility. All of these types of measurements can be imported into a single measurements formatted file and use the MagIC method codes and other clues (lab fields, etc.) to differentiate one measurement from another. \n", "\n", "Data were obtained by Hartl and Tauxe (1997, doi: 10.1111/j.1365-246X.1997.tb04082.x) from a Paleogene core from 28$^{\\circ}$ S (DSDP Site 522) and used for a relative paleointensity study. IRM, ARM, magnetic susceptibility and remanence data were uploaded to the MagIC database. The MagIC measurements formatted file for this study (which you can get from   https://earthref.org/MagIC/doi/10.1111/j.1365-246X.1997.tb04082.x and unpack with [download_magic](#download_magic)  is saved in data_files/biplot_magic/measurements.txt. \n", "\n", "We can create these plots using Pandas.  The key to what the measurements mean is in the [Magic method codes](https://www2.earthref.org/MagIC/method-codes), so we can first get a unique list of all the available method_codes, then plot the ones we are interested in  against each other.  Let's read in the data file in to a **Pandas** DataFrame and exctract the method codes to see what we have: "]}, {"block": 17, "type": "code", "linesLength": 6, "startIndex": 149, "lines": ["# read in the data\n", "meas_df=pd.read_csv('data_files/biplot_magic/measurements.txt',sep='\\t',header=1)\n", "# get the method_codes and print\n", "print(meas_df.method_codes.unique())\n", "# take a look at the top part of the measurements data frame\n", "meas_df.head()"]}, {"block": 18, "type": "markdown", "linesLength": 1, "startIndex": 155, "lines": ["These are: an AF demag step (LT-AF-Z), an ARM (LT-AF-I), an IRM  (LT-IRM) and a susceptibility (LP-X).  Now we can fish out data for each method, merge them by specimen, dropping any missing measurements and finally plot one against the other.  "]}, {"block": 19, "type": "code", "linesLength": 16, "startIndex": 156, "lines": ["# get the IRM data\n", "IRM=meas_df[meas_df.method_codes.str.contains('LT-IRM')]\n", "IRM=IRM[['specimen','magn_mass']] #trim the data frame\n", "IRM.columns=['specimen','IRM'] # rename the column\n", "# do the same for the ARM data\n", "ARM=meas_df[meas_df.method_codes.str.contains('LT-AF-I')]\n", "ARM=ARM[['specimen','magn_mass']]\n", "ARM.columns=['specimen','ARM']\n", "# and the magnetic susceptibility\n", "CHI=meas_df[meas_df.method_codes.str.contains('LP-X')]\n", "CHI=CHI[['specimen','susc_chi_mass']]  \n", "CHI.columns=['specimen','CHI']\n", "# merge IRM ARM data by specimen\n", "RMRMs=pd.merge(IRM,ARM,on='specimen')\n", "# add on the susceptility data\n", "RMRMs=pd.merge(RMRMs,CHI,on='specimen')"]}, {"block": 20, "type": "markdown", "linesLength": 1, "startIndex": 172, "lines": ["Now we are ready to make the plots.  "]}, {"block": 21, "type": "code", "linesLength": 13, "startIndex": 173, "lines": ["fig=plt.figure(1, (12,4)) # make a figure\n", "fig.add_subplot(131) # make the first in a row of three subplots \n", "plt.plot(RMRMs.IRM,RMRMs.ARM,'ro',markeredgecolor='black')\n", "plt.xlabel('IRM (Am$^2$/kg)') # label the X axis\n", "plt.ylabel('ARM (Am$^2$/kg)') # and the Y axis\n", "fig.add_subplot(132)# make the second in a row of three subplots \n", "plt.plot(RMRMs.IRM,RMRMs.CHI,'ro',markeredgecolor='black')\n", "plt.xlabel('IRM (Am$^2$/kg)')\n", "plt.ylabel('$\\chi$ (m$^3$/kg)')\n", "fig.add_subplot(133)# and the third in a row of three subplots \n", "plt.plot(RMRMs.ARM,RMRMs.CHI,'ro',markeredgecolor='black')\n", "plt.xlabel('$\\chi$ (m$^3$/kg)')\n", "plt.ylabel('IRM (Am$^2$/kg)');"]}, {"block": 22, "type": "markdown", "linesLength": 9, "startIndex": 186, "lines": ["## chi_magic\n", "\n", "\n", "[\\[Essentials Chapter 8\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch8.html#x15-1560008) [\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#chi_magic.py)\n", "\n", " It is sometimes useful to measure susceptibility as a function of temperature, applied field and frequency. Here we use a data set that came from the Tiva Canyon Tuff sequence (see Jackson et al., 2006, doi: 10.1029/2006JB004514). \n", "\n", "\n", "**chi_magic** reads in a MagIC formatted file and makes various plots.  We do this using Pandas.\n"]}, {"block": 23, "type": "code", "linesLength": 2, "startIndex": 195, "lines": ["# with ipmag\n", "ipmag.chi_magic('data_files/chi_magic/measurements.txt', save_plots=False)"]}, {"block": 24, "type": "code", "linesLength": 7, "startIndex": 197, "lines": ["# read in data from data model 3 example file using pandas\n", "chi_data=pd.read_csv('data_files/chi_magic/measurements.txt',sep='\\t',header=1)\n", "print (chi_data.columns)\n", "# get arrays of available temps, frequencies and fields\n", "Ts=np.sort(chi_data.meas_temp.unique())\n", "Fs=np.sort(chi_data.meas_freq.unique())\n", "Bs=np.sort(chi_data.meas_field_ac.unique())\n"]}, {"block": 25, "type": "code", "linesLength": 10, "startIndex": 204, "lines": ["# plot chi versus temperature at constant field\n", "b=Bs.max()\n", "for f in Fs:\n", "    this_f=chi_data[chi_data.meas_freq==f]\n", "    this_f=this_f[this_f.meas_field_ac==b]\n", "    plt.plot(this_f.meas_temp,1e6*this_f.susc_chi_volume,label='%i'%(f)+' Hz')\n", "plt.legend()\n", "plt.xlabel('Temperature (K)')\n", "plt.ylabel('$\\chi$ ($\\mu$SI)')\n", "plt.title('B = '+'%7.2e'%(b)+ ' T')"]}, {"block": 26, "type": "code", "linesLength": 10, "startIndex": 214, "lines": ["# plot chi versus frequency at constant B\n", "b=Bs.max()\n", "t=Ts.min()\n", "this_t=chi_data[chi_data.meas_temp==t]\n", "this_t=this_t[this_t.meas_field_ac==b]\n", "plt.semilogx(this_t.meas_freq,1e6*this_t.susc_chi_volume,label='%i'%(t)+' K')\n", "plt.legend()\n", "plt.xlabel('Frequency (Hz)')\n", "plt.ylabel('$\\chi$ ($\\mu$SI)')\n", "plt.title('B = '+'%7.2e'%(b)+ ' T')"]}, {"block": 27, "type": "markdown", "linesLength": 1, "startIndex": 224, "lines": [" You can see the dependence on temperature, frequency and applied field. These data support the suggestion that there is a strong superparamagnetic component in these specimens.\n"]}, {"block": 28, "type": "markdown", "linesLength": 10, "startIndex": 225, "lines": ["## common_mean\n", "\n", "[\\[Essentials Chapter 12\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch12.html#x15-15600012)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#common_mean.py)\n", "\n", " Most paleomagnetists use some form of Fisher Statistics to decide if two directions are statistically distinct or not (see [Essentials Chapter 11](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch11.html#x15-15600011) for a discussion of those techniques. But often directional data are not Fisher distributed and the parametric approach will give misleading answers. In these cases, one can use a boostrap approach, described in detail in [Essentials Chapter 12]. The program **common_mean** can be used for a bootstrap test for common mean to check whether two declination, inclination data sets have a common mean at the 95% level of confidence. \n", " \n", " We want to compare the two data sets: common_mean_ex_file1.dat and common_mean_ex_file2.dat. But first, let\u2019s look at the data in equal area projection using the methods outline in the section on [eqarea](#eqarea).\n", "\n", "\n", "\n"]}, {"block": 29, "type": "code", "linesLength": 5, "startIndex": 235, "lines": ["directions_A=np.loadtxt('data_files/common_mean/common_mean_ex_file1.dat')\n", "directions_B=np.loadtxt('data_files/common_mean/common_mean_ex_file2.dat') \n", "ipmag.plot_net(1)\n", "ipmag.plot_di(di_block=directions_A,color='red')\n", "ipmag.plot_di(di_block=directions_B,color='blue')\n"]}, {"block": 30, "type": "markdown", "linesLength": 1, "startIndex": 240, "lines": ["Now let\u2019s look at the common mean problem using **ipmag.common_mean_bootstrap()**."]}, {"block": 31, "type": "code", "linesLength": 1, "startIndex": 241, "lines": ["help(ipmag.common_mean_bootstrap)"]}, {"block": 32, "type": "code", "linesLength": 1, "startIndex": 242, "lines": ["ipmag.common_mean_bootstrap(directions_A,directions_B,figsize=(9,3))"]}, {"block": 33, "type": "markdown", "linesLength": 5, "startIndex": 243, "lines": ["These plots suggest that the two data sets share a common mean.\n", "\n", "Now compare the data in common_mean_ex_file1.dat with the expected direction at the 5$^{\\circ}$ N latitude that these data were collected (Dec=0, Inc=9.9).\n", "\n", "To do this, we set the second data set to be the desired direction for comparison. "]}, {"block": 34, "type": "code", "linesLength": 2, "startIndex": 248, "lines": ["comp_dir=[0,9.9]\n", "ipmag.common_mean_bootstrap(directions_A,comp_dir,figsize=(9,3))"]}, {"block": 35, "type": "markdown", "linesLength": 1, "startIndex": 250, "lines": ["Apparently the data (cumulative distribution functions) are entirely consistent with the expected direction (dashed lines are the cartesian coordinates of that). "]}, {"block": 36, "type": "markdown", "linesLength": 8, "startIndex": 251, "lines": ["## cont_rot \n", "\n", "[\\[Essentials Chapter 16\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch16.html#x15-15600016)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#cont_rot.py)\n", "\n", "We can  make an orthographic projection with latitude = -20$^{\\circ}$ and longitude = 0$^{\\circ}$ at the center of the African and South American continents reconstructed to 180 Ma using the Torsvik et al. (2008, doi: 10.1029/2007RG000227) poles of finite rotation. We would do this by first holding Africa fixed. \n", "\n", "We need to read in in the outlines of continents from **continents.get_cont()**, rotate them around a rotation pole and angle as specified by the age  and continent in question (from **frp.get_pole()** using **pmag.pt_rot()**.  Then we can plot them using **pmagplotlib.plot_map()**.  If the Basemap version is preferred, use **pmagplotlib.plot_map_basemap()**. \n", "Here we demonstrate this from within  the notebook by just calling the  PmagPy  functions.  "]}, {"block": 37, "type": "code", "linesLength": 4, "startIndex": 259, "lines": ["# load in the continents module\n", "import pmagpy.continents as continents\n", "import pmagpy.frp as frp\n", "help(continents.get_continent)"]}, {"block": 38, "type": "code", "linesLength": 1, "startIndex": 263, "lines": ["help(pmagplotlib.plot_map)"]}, {"block": 39, "type": "code", "linesLength": 20, "startIndex": 264, "lines": ["# retrieve continental outline\n", "# This is the version that uses cartopy and requires installation of cartopy\n", "af=continents.get_continent('af').transpose()\n", "sam=continents.get_continent('sam').transpose()\n", "\n", "\n", "#define options for pmagplotlib.plot_map\n", "plt.figure(1,(5,5))\n", "Opts = {'latmin': -90, 'latmax': 90, 'lonmin': 0., 'lonmax': 360., 'lat_0': -20, \\\n", "            'lon_0': 345,'proj': 'ortho', 'sym': 'r-', 'symsize': 3,\\\n", "            'pltgrid': 0, 'res': 'c', 'boundinglat': 0.}\n", "if has_cartopy:\n", "    pmagplotlib.plot_map(1,af[0],af[1],Opts)\n", "    Opts['sym']='b-'\n", "    pmagplotlib.plot_map(1,sam[0],sam[1],Opts)\n", "elif has_basemap:\n", "    pmagplotlib.plot_map_basemap(1,af[0],af[1],Opts)\n", "    Opts['sym']='b-'\n", "    pmagplotlib.plot_map_basemap(1,sam[0],sam[1],Opts)\n", "    "]}, {"block": 40, "type": "markdown", "linesLength": 1, "startIndex": 284, "lines": ["Now for the rotation part.  These are in a function called **frp.get_pole()**"]}, {"block": 41, "type": "code", "linesLength": 1, "startIndex": 285, "lines": ["help(frp.get_pole)"]}, {"block": 42, "type": "code", "linesLength": 4, "startIndex": 286, "lines": ["# get the rotation pole for south america relative to South Africa at 180 Ma\n", "sam_pole=frp.get_pole('sam',180)\n", "# NB: for african rotations, first rotate other continents to fixed Africa, then \n", "# rotate with South African pole (saf)\n"]}, {"block": 43, "type": "markdown", "linesLength": 1, "startIndex": 290, "lines": ["The rotation is done by **pmag.pt_rot()**."]}, {"block": 44, "type": "code", "linesLength": 1, "startIndex": 291, "lines": ["help(pmag.pt_rot)"]}, {"block": 45, "type": "markdown", "linesLength": 1, "startIndex": 292, "lines": ["so here we go...  "]}, {"block": 46, "type": "code", "linesLength": 12, "startIndex": 293, "lines": ["plt.figure(1,(5,5))\n", "sam_rot=pmag.pt_rot(sam_pole,sam[0],sam[1]) # same for south america\n", "# and plot 'em\n", "Opts['sym']='r-'\n", "if has_cartopy:\n", "    pmagplotlib.plot_map(1,af[0],af[1],Opts)\n", "    Opts['sym']='b-'\n", "    pmagplotlib.plot_map(1,sam_rot[0],sam_rot[1],Opts)\n", "elif has_basemap:\n", "    pmagplotlib.plot_map_basemap(1,af[0],af[1],Opts)\n", "    Opts['sym']='b-'\n", "    pmagplotlib.plot_map_basemap(1,sam_rot[0],sam_rot[1],Opts)"]}, {"block": 47, "type": "markdown", "linesLength": 12, "startIndex": 305, "lines": ["## core_depthplot\n", "\n", "[\\[Essentials Chapter 15\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch15.html#x15-15600015)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#core_depthplot.py)\n", "\n", "The program **core_depthplot** can be used to plot various measurement data versus sample depth. The data must be in the MagIC data format. The program will plot whole core data, discrete sample at a bulk demagnetization step, data from vector demagnetization experiments, and so on. \n", "\n", "We can try this out on some data from DSDP Hole 522, (drilled at 26S/5W) and measured by Tauxe and Hartl (1997, doi: 10.1111/j.1365-246X.1997.tb04082.x). These were  downloaded and unpacked in the [biplot_magic](#biplot_magic) example. More of the data are in the directory ../data_files/core_depthplot. \n", "\n", " In this example, we will plot the alternating field (AF) data after the 15 mT step. The magnetizations will be plotted on a log scale and, as this is a record of the Oligocene, we will plot the Oligocene time scale, using the calibration of Gradstein et al. (2012), commonly referred to as \u201cGTS12\u201d for the the Oligocene. We are only interested in the data between 50 and 150 meters  and we are not interested in the declinations here. \n", "\n", "\n", "All this can be done using the wonders of Pandas data frames using the  data in the **data_files/core_depthplot** directory.   \n"]}, {"block": 48, "type": "markdown", "linesLength": 10, "startIndex": 317, "lines": ["Let's do things this way:\n", "- read in the data from the sites and specimens files.\n", "- Drop the records with NaN for analysts, keeping one of the three lines available for each specimen. \n", "- Make a new column named **site** in the specdimens table that is the same as the **specimen** column.\n", "- (this makes sense because these are core data, so the specimen=sample=site. )\n", "- Merge the two DataFrames on the **site** column.\n", "- filter the data for depths between 50 and 150.\n", "- Plot **dir_inc** versus **core_depth**.  \n", "- Put on GAD field inclination\n", "- plot the time scale"]}, {"block": 49, "type": "code", "linesLength": 8, "startIndex": 327, "lines": ["specimens=pd.read_csv('data_files/core_depthplot/specimens.txt',sep='\\t',header=1)\n", "sites=pd.read_csv('data_files/core_depthplot/sites.txt',sep='\\t',header=1)\n", "specimens=specimens.dropna(subset=['dir_inc']) # kill unwanted lines with duplicate or irrelevent info\n", "specimens['site']=specimens['specimen'] # make a column with site name\n", "data=pd.merge(specimens,sites,on='site') # merge the two data frames on site\n", "data=data[data.core_depth>50] # all levels > 50\n", "data=data[data.core_depth<150] # and < 150\n", "lat=26 # we need this for the GAD INC"]}, {"block": 50, "type": "markdown", "linesLength": 1, "startIndex": 335, "lines": ["Plot versus core_depth"]}, {"block": 51, "type": "code", "linesLength": 16, "startIndex": 336, "lines": ["fig=plt.figure(1,(6,12)) # make the figure\n", "ax=fig.add_subplot(121) # make the first of 2 subplots\n", "plt.ylabel('Depth (m)') # label the Y axis\n", "plt.plot(data.dir_inc,data.core_depth,'k-') # draw on a black line through the data\n", "# draw the data points as cyan dots with black edges\n", "plt.plot(data.dir_inc,data.core_depth,'co',markeredgecolor='black')\n", "plt.title('Inclinations') # put on a title\n", "plt.axvline(0,color='black')# make a central line at inc=0\n", "plt.ylim(150,50) # set the plot Y limits to the desired depths\n", "fig.add_subplot(122) # make the second of two subplots\n", "# plot intensity data on semi-log plot\n", "plt.semilogx(data.int_rel/data.int_rel.mean(),data.core_depth,'k-')\n", "plt.semilogx(data.int_rel/data.int_rel.mean(),\\\n", "             data.core_depth,'co',markeredgecolor='black')\n", "plt.ylim(150,50)\n", "plt.title('Relative Intensity');\n"]}, {"block": 52, "type": "markdown", "linesLength": 1, "startIndex": 352, "lines": ["And now versus age:"]}, {"block": 53, "type": "code", "linesLength": 20, "startIndex": 353, "lines": ["fig=plt.figure(1,(9,12)) # make the figure\n", "ax=fig.add_subplot(131) # make the first of three subplots\n", "pmagplotlib.plot_ts(ax,23,34,timescale='gts12') # plot on the time scale\n", "fig.add_subplot(132) # make the second of three subplots\n", "plt.plot(data.dir_inc,data.core_depth,'k-')\n", "plt.plot(data.dir_inc,data.core_depth,'co',markeredgecolor='black')\n", "plt.ylim(35,23)\n", "# calculate the geocentric axial dipole field for the site latitude\n", "gad=np.degrees(np.arctan(2.*np.tan(np.radians(lat)))) # tan (I) = 2 tan (lat)\n", "# put it on the plot as a green dashed line\n", "plt.axvline(gad,color='green',linestyle='dashed',linewidth=2)\n", "plt.axvline(-gad,color='green',linestyle='dashed',linewidth=2)\n", "plt.title('Inclinations')\n", "plt.ylim(150,50)\n", "fig.add_subplot(133) # make the third of three plots\n", "# plot the intensity data on semi-log plot\n", "plt.semilogx(data.int_rel/data.int_rel.mean(),data.core_depth,'k-')\n", "plt.semilogx(data.int_rel/data.int_rel.mean(),data.core_depth,'co',markeredgecolor='black')\n", "plt.ylim(150,50)\n", "plt.title('Relative Intensity');\n"]}, {"block": 54, "type": "markdown", "linesLength": 6, "startIndex": 373, "lines": ["## curie \n", "\n", "[\\[Essentials Chapter 6\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch6.html#x15-1560006)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#curie.py)\n", "\n", "\n", "Curie Temperature experiments, saved in MagIC formatted files, can be plotted using **ipmag.curie()**."]}, {"block": 55, "type": "code", "linesLength": 1, "startIndex": 379, "lines": ["help(ipmag.curie)"]}, {"block": 56, "type": "code", "linesLength": 2, "startIndex": 380, "lines": ["ipmag.curie(path_to_file='data_files/curie',file_name='curie_example.dat',\\\n", "           window_length=10)"]}, {"block": 57, "type": "markdown", "linesLength": 6, "startIndex": 382, "lines": ["### dayplot_magic\n", "\n", "[\\[Essentials Chapter 5\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch5.html#x15-1560005)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#dayplot_magic.py)\n", "\n", "The program **dayplot_magic**   makes Day (Day et al., 1977), or Squareness-Coercivity and Squareness-Coercivity of Remanence plots (e.g., Tauxe et al., 2002) from the MagIC formatted data.\n", "To do this, we will call **ipmag.dayplot_magic()**."]}, {"block": 58, "type": "code", "linesLength": 1, "startIndex": 388, "lines": ["help(ipmag.dayplot_magic)"]}, {"block": 59, "type": "code", "linesLength": 1, "startIndex": 389, "lines": ["ipmag.dayplot_magic(path_to_file='data_files/dayplot_magic',hyst_file='specimens.txt',save=False)"]}, {"block": 60, "type": "markdown", "linesLength": 8, "startIndex": 390, "lines": ["## dmag_magic\n", "\n", "[\\[Essentials Chapter 9\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch9.html#x15-15600089) [\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#dmag_magic.py)\n", "\n", "\n", "We use **dmag_magic** to plot out the decay of all alternating field demagnetization experiments in MagIC  formatted files.   Here we can take a look at some of the data from   from Cromwell et al.  (2013, doi: 10.1002/ggge.20174). \n", "\n", "This program calls **pmagplotlib.plot_mag()** to plot the demagnetization curve for a sample, site, or entire data file interactively.  There is a version that will prepare dataframes for plotting with this function called **ipmag.plot_dmag()**. So let's try that: "]}, {"block": 61, "type": "code", "linesLength": 1, "startIndex": 398, "lines": ["help(ipmag.plot_dmag)"]}, {"block": 62, "type": "markdown", "linesLength": 1, "startIndex": 399, "lines": ["Read in data from a MagIC data model 3 file.  Let's go ahead and read it in with the full data hierarchy. "]}, {"block": 63, "type": "code", "linesLength": 2, "startIndex": 400, "lines": ["status,data=cb.add_sites_to_meas_table('data_files/dmag_magic')\n", "data.head()"]}, {"block": 64, "type": "markdown", "linesLength": 3, "startIndex": 402, "lines": ["There are several forms of intensity measurements with different normalizations.  \n", "We could hunt through the magn\\_\\* columns to see what is non-blank or we can use the tool **contribution_builder.get_intensity_col()** which returns the first non-zero column.  \n", "\n"]}, {"block": 65, "type": "code", "linesLength": 2, "startIndex": 405, "lines": ["magn_col=cb.get_intensity_col(data)\n", "print (magn_col)"]}, {"block": 66, "type": "markdown", "linesLength": 1, "startIndex": 407, "lines": ["Let's look at what demagnetization data are available to us:"]}, {"block": 67, "type": "code", "linesLength": 1, "startIndex": 408, "lines": ["data.method_codes.unique()"]}, {"block": 68, "type": "markdown", "linesLength": 1, "startIndex": 409, "lines": ["Oops - at least one of our records has blank method_codes!  so, let's get rid of that one."]}, {"block": 69, "type": "code", "linesLength": 1, "startIndex": 410, "lines": ["data=data.dropna(subset=['method_codes'])"]}, {"block": 70, "type": "markdown", "linesLength": 5, "startIndex": 411, "lines": ["We can make the plots in this way: \n", "- select the AF demagnetization data with method_codes = 'LP-DIR-AF'\n", "- make a dataframe with these columns:\n", "     'specimen','treat_ac_field',magn_col,and 'quality'\n", "- call ipmag.plot_dmag() to view the plot: "]}, {"block": 71, "type": "code", "linesLength": 5, "startIndex": 416, "lines": ["af_df=data[data.method_codes.str.contains('LP-DIR-AF')] # select the thermal demag data\n", "af_df=af_df.dropna(subset=['treat_ac_field'])\n", "df=af_df[['specimen','treat_ac_field',magn_col,'quality']]\n", "\n", "df.head()"]}, {"block": 72, "type": "code", "linesLength": 1, "startIndex": 421, "lines": ["ipmag.plot_dmag(data=df,title=\"AF demag\",fignum=1)"]}, {"block": 73, "type": "markdown", "linesLength": 2, "startIndex": 422, "lines": ["This plotted all the data in the file.  we could also plot the data by site \n", "by getting a unique list of site names and then walk through them one by one"]}, {"block": 74, "type": "code", "linesLength": 8, "startIndex": 424, "lines": ["sites=af_df.site.unique()\n", "cnt=1\n", "for site in sites:\n", "    site_df=af_df[af_df.site==site] # fish out this site\n", "    # trim to only AF data. \n", "    site_df=site_df[['specimen','treat_ac_field',magn_col,'quality']] \n", "    ipmag.plot_dmag(data=site_df,title=site,fignum=cnt)\n", "    cnt+=1"]}, {"block": 75, "type": "markdown", "linesLength": 2, "startIndex": 432, "lines": ["We could repeat for thermal data if we felt like it using 'LT-T-Z' as the method_code key\n", "and treat_temp as the step.  We could also save the plots using plt.savefig('FIGNAME.FMT') where FIGNAME could be the site, location, demag type as you wish.  "]}, {"block": 76, "type": "markdown", "linesLength": 2, "startIndex": 434, "lines": ["#### dmag_magic with a downloaded file\n", "Now let's look at a [downloaded](#download_magic) contribution using [dmag_magic](#dmag_magic) as before, but this time with thermal demagnetization. "]}, {"block": 77, "type": "code", "linesLength": 7, "startIndex": 436, "lines": ["ipmag.download_magic(\"magic_contribution_16533.txt\", dir_path=\"data_files/download_magic\", \n", "                     input_dir_path=\"data_files/download_magic\")\n", "status,data=cb.add_sites_to_meas_table('data_files/download_magic')\n", "df=data[data.method_codes.str.contains('LT-T-Z')] # select the thermal demag data\n", "df=df[['specimen','treat_temp','magn_moment','quality']]\n", "df=df.dropna(subset=['treat_temp','magn_moment'])\n", "ipmag.plot_dmag(data=df,title=\"Thermal demag\",fignum=1, dmag_key='treat_temp')"]}, {"block": 78, "type": "markdown", "linesLength": 5, "startIndex": 443, "lines": ["## eqarea\n", "\n", "[\\[Essentials Chapter 2\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch2.html#x15-156000813)[\\[Essentials Appendix B\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ap2.html#x21-227000B#x15-156000813) [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#eqarea.py)\n", "\n", "The problem of plotting equal area projections in Jupyter notebooks was solved by Nick Swanson-Hysell who started the **ipmag** module just for this purpose!  We use **ipmag.plot_net()** to plot the net, then **ipmag.plot_di()** to plot the directions.  "]}, {"block": 79, "type": "code", "linesLength": 1, "startIndex": 448, "lines": ["help(ipmag.plot_di)"]}, {"block": 80, "type": "code", "linesLength": 3, "startIndex": 449, "lines": ["di_block=np.loadtxt('data_files/eqarea/fishrot.out')\n", "ipmag.plot_net(1)\n", "ipmag.plot_di(di_block=di_block,color='red',edge='black')"]}, {"block": 81, "type": "markdown", "linesLength": 29, "startIndex": 452, "lines": ["## eqarea_ell\n", "\n", "[\\[Essentials Chapter 11\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch11.html)\n", "[\\[Essentials Chapter 12\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch12.html)\n", "[\\[Essentials Appendix B\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ap2.html#x21-227000B#x15-156000813) \n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#eqarea_ell.py)\n", "\n", "\n", "\n", "This programe makes  plots of eqarea area projections and confidence ellipses for dec,inc pairs\n", "We make the equal area projects with the **ipmag.plot_net()** and **ipmag.plot_di()** functions.  The options in eqarea_ell are: \n", "    - Bingham mean and ellipse(s)\n", "    - Fisher mean(s) and alpha_95(s)\n", "    - Kent mean(s) - same as Fisher - and Kent ellipse(s)\n", "    - Bootstrapped mean(s)  - same as Fisher - and ellipse(s) \n", "    - Bootstrapped eigenvectors\n", "For Bingham mean, the N/R data are assumed antipodal and the procedure would be:\n", "    - plot the data\n", "    - calculate the bingham ellipse with **pmag.dobingham()**\n", "    - plot the ellipse using **pmag.plot_di_mean_ellipse()**\n", "All others, the data are not assumed antipodal, and must be separated into normal and reverse modes. To do that you can either use **pmag.separate_directions()** to calculate ellipses for each mode, OR use **pmag.flip()** to flip the reverse mode to the normal mode.  To calculate the ellipses: \n", "    - calculate the ellipses for each mode (or the flipped data set):\n", "        - Kent: use **pmag.dokent()**, setting NN to the number of data points\n", "        - Bootstrap : use **pmag.di_boot()** to generate the bootstrapped means\n", "            - either just plot the eigenvectors (ipmag.plot_di()) OR\n", "            - calcualate the bootstrapped ellipses with **pmag.dokent()** setting NN to 1\n", "        - Parametric bootstrap : you need a pandas data frame with the site mean directions, n and kappa.  Then you can use **pmag.dir_df_boot()**.  \n", "    - plot the ellipses if desired. \n", "    "]}, {"block": 82, "type": "code", "linesLength": 4, "startIndex": 481, "lines": ["#read in the data into an array\n", "vectors=np.loadtxt('data_files/eqarea_ell/tk03.out').transpose()\n", "di_block=vectors[0:2].transpose() # decs are di_block[0], incs are di_block[1]\n", "di_block"]}, {"block": 83, "type": "markdown", "linesLength": 1, "startIndex": 485, "lines": ["### Bingham ellipses"]}, {"block": 84, "type": "code", "linesLength": 1, "startIndex": 486, "lines": ["help(pmag.dobingham)"]}, {"block": 85, "type": "code", "linesLength": 1, "startIndex": 487, "lines": ["help(ipmag.plot_di_mean_ellipse)"]}, {"block": 86, "type": "code", "linesLength": 4, "startIndex": 488, "lines": ["ipmag.plot_net(1)\n", "ipmag.plot_di(di_block=di_block)\n", "bpars=pmag.dobingham(di_block)\n", "ipmag.plot_di_mean_ellipse(bpars,color='red',marker='^',markersize=50)"]}, {"block": 87, "type": "markdown", "linesLength": 1, "startIndex": 492, "lines": ["### Fisher mean, a95"]}, {"block": 88, "type": "code", "linesLength": 1, "startIndex": 493, "lines": ["help(pmag.separate_directions)"]}, {"block": 89, "type": "code", "linesLength": 3, "startIndex": 494, "lines": ["vectors=np.loadtxt('data_files/eqarea_ell/tk03.out').transpose()\n", "di_block=vectors[0:2].transpose() # decs are di_block[0], incs are di_block[1]\n", "mode_1,mode_2=pmag.separate_directions(di_block)"]}, {"block": 90, "type": "code", "linesLength": 1, "startIndex": 497, "lines": ["help(ipmag.fisher_mean)"]}, {"block": 91, "type": "code", "linesLength": 2, "startIndex": 498, "lines": ["mode_1_fpars=ipmag.fisher_mean(di_block=mode_1)\n", "mode_2_fpars=ipmag.fisher_mean(di_block=mode_2)"]}, {"block": 92, "type": "code", "linesLength": 1, "startIndex": 500, "lines": ["help(ipmag.plot_di_mean)"]}, {"block": 93, "type": "code", "linesLength": 9, "startIndex": 501, "lines": ["# plot the data\n", "ipmag.plot_net(1)\n", "ipmag.plot_di(di_block=di_block,color='red',edge='black')\n", "# draw on the means and lpha95\n", "ipmag.plot_di_mean(dec=mode_1_fpars['dec'],inc=mode_1_fpars['inc'],a95=mode_1_fpars['alpha95'],\\\n", "                  marker='*',color='blue',markersize=50)\n", "\n", "ipmag.plot_di_mean(dec=mode_2_fpars['dec'],inc=mode_2_fpars['inc'],a95=mode_2_fpars['alpha95'],\\\n", "                  marker='*',color='blue',markersize=50)\n"]}, {"block": 94, "type": "markdown", "linesLength": 1, "startIndex": 510, "lines": ["### Kent mean and ellipse"]}, {"block": 95, "type": "code", "linesLength": 1, "startIndex": 511, "lines": ["help(pmag.dokent)"]}, {"block": 96, "type": "code", "linesLength": 2, "startIndex": 512, "lines": ["mode_1_kpars=pmag.dokent(mode_1,len(mode_1))\n", "mode_2_kpars=pmag.dokent(mode_2,len(mode_2))"]}, {"block": 97, "type": "code", "linesLength": 6, "startIndex": 514, "lines": ["# plot the data\n", "ipmag.plot_net(1)\n", "ipmag.plot_di(di_block=di_block,color='red',edge='black')\n", "# draw on the means and lpha95\n", "ipmag.plot_di_mean_ellipse(mode_1_kpars,marker='*',color='cyan',markersize=20)\n", "ipmag.plot_di_mean_ellipse(mode_2_kpars,marker='*',color='cyan',markersize=20)"]}, {"block": 98, "type": "markdown", "linesLength": 1, "startIndex": 520, "lines": ["### Bootstrap eigenvectors"]}, {"block": 99, "type": "code", "linesLength": 1, "startIndex": 521, "lines": ["help(pmag.di_boot)"]}, {"block": 100, "type": "code", "linesLength": 2, "startIndex": 522, "lines": ["mode_1_BDIs=pmag.di_boot(mode_1)\n", "mode_2_BDIs=pmag.di_boot(mode_2)"]}, {"block": 101, "type": "code", "linesLength": 4, "startIndex": 524, "lines": ["ipmag.plot_net(1)\n", "ipmag.plot_di(di_block=mode_1_BDIs,color='cyan',markersize=1)\n", "ipmag.plot_di(di_block=mode_2_BDIs,color='cyan',markersize=1)\n", "ipmag.plot_di(di_block=di_block,color='red',edge='black')\n"]}, {"block": 102, "type": "markdown", "linesLength": 1, "startIndex": 528, "lines": ["### Bootstrapped ellipses"]}, {"block": 103, "type": "code", "linesLength": 2, "startIndex": 529, "lines": ["mode_1_bpars=pmag.dokent(mode_1_BDIs,1)\n", "mode_2_bpars=pmag.dokent(mode_2_BDIs,1)"]}, {"block": 104, "type": "code", "linesLength": 6, "startIndex": 531, "lines": ["# plot the data\n", "ipmag.plot_net(1)\n", "ipmag.plot_di(di_block=di_block,color='red',edge='black')\n", "# draw on the means and lpha95\n", "ipmag.plot_di_mean_ellipse(mode_1_bpars,marker='*',color='cyan',markersize=20)\n", "ipmag.plot_di_mean_ellipse(mode_2_bpars,marker='*',color='cyan',markersize=20)"]}, {"block": 105, "type": "markdown", "linesLength": 15, "startIndex": 537, "lines": ["## eqarea_magic\n", "\n", "[\\[Essentials Chapter 2\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch2.html#x15-1560008) [\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#eqarea_magic.py)\n", "\n", "\n", "**eqarea_magic** takes MagIC data model 3 files and makes equal area projections of declination, inclination data for a variety of  selections, \n", "i.e. all the data, by site, by sample, or by specimen\n", "It has the option to plot in different coordinate systems (if available) and various ellipses.  It will also make a color contour plot if desired.  \n", "We will do this with **ipmag.plot_net()** and **ipmag_plot_di()** using **Pandas** filtering capability.  \n", "\n", "Let's start with a simple plot of site mean directions, assuming that they were interpreted from measurements using **pmag_gui.py** or some such program and have all the required meta-data.  \n", "\n", "We want data in geographic coordinates (dir_tilt_correction=0).  The keys for directions are dir_dec and dir_inc.     One could add the ellipses using **ipmag.plot_di_mean_ellipse()**.  \n", "\n", "#### whole study\n"]}, {"block": 106, "type": "code", "linesLength": 6, "startIndex": 552, "lines": ["sites=pd.read_csv('data_files/eqarea_magic/sites.txt',sep='\\t',header=1)\n", "site_dirs=sites[sites['dir_tilt_correction']==0]\n", "ipmag.plot_net(1)\n", "di_block=sites[['dir_dec','dir_inc']].values\n", "#ipmag.plot_di(sites['dir_dec'].values,sites['dir_inc'].values,color='blue',markersize=50)\n", "ipmag.plot_di(di_block=di_block,color='blue',markersize=50)"]}, {"block": 107, "type": "code", "linesLength": 2, "startIndex": 558, "lines": ["# or, using ipmag.eqarea_magic:\n", "ipmag.eqarea_magic('data_files/eqarea_magic/sites.txt', save_plots=False)"]}, {"block": 108, "type": "markdown", "linesLength": 2, "startIndex": 560, "lines": ["#### whole study with color contour option\n", "for this we can use the function **pmagplotlib.plot_eq_cont()** which makes a color contour of a dec, inc data"]}, {"block": 109, "type": "code", "linesLength": 1, "startIndex": 562, "lines": ["help(pmagplotlib.plot_eq_cont)"]}, {"block": 110, "type": "code", "linesLength": 2, "startIndex": 563, "lines": ["ipmag.plot_net(1)\n", "pmagplotlib.plot_eq_cont(1,di_block)"]}, {"block": 111, "type": "code", "linesLength": 2, "startIndex": 565, "lines": ["# with ipmag.eqarea_magic\n", "ipmag.eqarea_magic('data_files/eqarea_magic/sites.txt', save_plots=False, contour=True)"]}, {"block": 112, "type": "markdown", "linesLength": 7, "startIndex": 567, "lines": ["#### specimens by site\n", "This study averaged specimens (not samples) by site, so we would like to make plots of all the specimen data for each site.   We can do things the in a similar way to what we did in the **dmag_magic** example.  \n", "A few particulars:\n", "- We will be plotting specimen interpetations in geographic coordinates (dir_tilt_correction=0)\n", "- We need to look at the method codes as there might be fisher means, principal components, great circles, etc.  A complete list of method codes for Direction Estimation can be found here:  https://www2.earthref.org/MagIC/method-codes\n", "- There might be 'bad' directions - 'result_quality'='b' as opposed to 'g'.  \n", "- There are a lot of sites in this study, so let's just look at the first 10...   "]}, {"block": 113, "type": "code", "linesLength": 10, "startIndex": 574, "lines": ["# read in specimen table\n", "spec_df=pd.read_csv('data_files/eqarea_magic/specimens.txt',sep='\\t',header=1) \n", "# read in sample table\n", "samp_df=pd.read_csv('data_files/eqarea_magic/samples.txt',sep='\\t',header=1) \n", "# get only what we need from samples (sample to site mapping)\n", "samp_df=samp_df[['sample','site']] \n", "# merge site to specimen name in the specimen data frame\n", "df_ext=pd.merge(spec_df,samp_df,how='inner',on='sample') \n", "# truncate to the first 10 sites\n", "sites=df_ext.site.unique()[0:11]"]}, {"block": 114, "type": "markdown", "linesLength": 2, "startIndex": 584, "lines": ["We need to filter specimen data for dir_tilt_correction=0\n", "and separate into DE-BFP (best fit planes) and not."]}, {"block": 115, "type": "code", "linesLength": 6, "startIndex": 586, "lines": ["# get the geographic coordinates\n", "spec_df=df_ext[spec_df.dir_tilt_correction==0]\n", "# filter to exclude planes\n", "spec_lines=spec_df[spec_df.method_codes.str.contains('DE-BFP')==False]\n", "# filter for planes\n", "spec_df_gc=spec_df[spec_df.method_codes.str.contains('DE-BFP')==True]"]}, {"block": 116, "type": "code", "linesLength": 2, "startIndex": 592, "lines": ["# here's a new one:\n", "help(ipmag.plot_gc)"]}, {"block": 117, "type": "code", "linesLength": 12, "startIndex": 594, "lines": ["cnt=1\n", "for site in sites:\n", "    plt.figure(cnt)\n", "    ipmag.plot_net(cnt)\n", "    plt.title(site)\n", "    site_lines=spec_lines[spec_lines.site==site] # fish out this site\n", "    ipmag.plot_di(site_lines.dir_dec.values,site_lines.dir_inc.values)\n", "    site_planes=spec_df_gc[spec_df_gc.site==site]\n", "    poles=site_planes[['dir_dec','dir_inc']].values\n", "    if poles.shape[0]>0:\n", "        ipmag.plot_gc(poles,fignum=cnt,color='r')\n", "    cnt+=1"]}, {"block": 118, "type": "code", "linesLength": 2, "startIndex": 606, "lines": ["# using ipmag.eqarea_magic:\n", "ipmag.eqarea_magic('specimens.txt', 'data_files/eqarea_magic', plot_by='sit', save_plots=False)"]}, {"block": 119, "type": "markdown", "linesLength": 8, "startIndex": 608, "lines": ["#### measurements by specimen\n", "\n", "We can do this like this:\n", "\n", "- read in the MagIC data model 3 measurements table into a **Pandas** data frame\n", "- get a list of unique specimen names\n", "- truncate this to the first 10 for this purpose\n", "- plot the dir_dec and dir_inc fields by specimen\n"]}, {"block": 120, "type": "code", "linesLength": 11, "startIndex": 616, "lines": ["# read in measurements table\n", "meas_df=pd.read_csv('data_files/eqarea_magic/measurements.txt',sep='\\t',header=1) \n", "specimens=meas_df.specimen.unique()[0:11]\n", "cnt=1\n", "for spec in specimens:\n", "    meas_spc=meas_df[meas_df.specimen==spec]\n", "    plt.figure(cnt)\n", "    ipmag.plot_net(cnt)\n", "    plt.title(spec)\n", "    ipmag.plot_di(meas_spc.dir_dec.values,meas_spc.dir_inc.values)\n", "    cnt+=1"]}, {"block": 121, "type": "markdown", "linesLength": 1, "startIndex": 627, "lines": ["#### Individual specimens"]}, {"block": 122, "type": "code", "linesLength": 2, "startIndex": 628, "lines": ["# using ipmag.eqarea_magic:\n", "ipmag.eqarea_magic('specimens.txt', 'data_files/eqarea_magic', plot_by='spc', save_plots=False)"]}, {"block": 123, "type": "markdown", "linesLength": 9, "startIndex": 630, "lines": ["## find_ei\n", "\n", "[\\[Essentials Chapter 14\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch14.html#x15-1560008) [\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#find_ei.py)\n", "\n", "This program is meant to find the unflattening factor (see [unsquish](#unsquish) documentation) that brings a sedimentary data set into agreement with the statistical field model TK03 of Tauxe and Kent (2004, doi: 10.1029/145GM08).  It  has been implemented for notebooks as **ipmag.find_ei()**.\n", "\n", "\n", "A data file (data_files/find_EI/find_EI_example.dat) was prepared using the program **[tk03](#tk03)**  to simulate directions at a latitude of 42$^{\\circ}$. with an expected inclination of 61$^{\\circ}$ (which could be gotten using **[dipole_pinc](#dipole_pinc)** of course.  \n", "\n"]}, {"block": 124, "type": "code", "linesLength": 1, "startIndex": 639, "lines": ["help(ipmag.find_ei)"]}, {"block": 125, "type": "code", "linesLength": 2, "startIndex": 640, "lines": ["data=np.loadtxt('data_files/find_EI/find_EI_example.dat')\n", "ipmag.find_ei(data)"]}, {"block": 126, "type": "markdown", "linesLength": 2, "startIndex": 642, "lines": ["In this example, the original expected inclination at paleolatitude of 42 (61$^{\\circ}$) is recovered within the 95% confidence bounds.\n", "\n"]}, {"block": 127, "type": "markdown", "linesLength": 8, "startIndex": 644, "lines": ["## fishqq\n", "\n", "[\\[Essentials Chapter 11\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch11.html) \n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#fishqq.py)\n", "\n", "This program tests whether a given directional data set is Fisher distributed using a Quantile-Quantile plot (see also [qqunf](#qqunf) or [qqplot](#qqplot) for more on Quantile-Quantile plots).  \n", "\n", "Blessedly, **fishqq** has been incorporated into **ipmag.fishqq()** for use within notebooks.  "]}, {"block": 128, "type": "code", "linesLength": 1, "startIndex": 652, "lines": ["help(ipmag.fishqq)"]}, {"block": 129, "type": "code", "linesLength": 3, "startIndex": 653, "lines": ["di_block=np.loadtxt('data_files/fishqq/fishqq_example.txt')\n", "fqpars=ipmag.fishqq(di_block=di_block)\n", "print (fqpars['Test_result'])"]}, {"block": 130, "type": "markdown", "linesLength": 8, "startIndex": 656, "lines": ["## foldtest\n", "\n", "[\\[Essentials Chapter 12\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch12.html) \n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#foldtest.py)\n", "\n", "**foldtest** uses the fold test of Tauxe and Watson (1994, 10.1016/0012-821x(94)90006-x  ) to find the degree of unfolding that produces the tightest distribution of directions (using the eigenvalue $\\tau_1$ as the criterion.  \n", "\n", "This can be done via **pmag.bootstrap_fold_test()**. Note that this can take several minutes.   "]}, {"block": 131, "type": "code", "linesLength": 1, "startIndex": 664, "lines": ["help(ipmag.bootstrap_fold_test)"]}, {"block": 132, "type": "code", "linesLength": 2, "startIndex": 665, "lines": ["data=np.loadtxt('data_files/foldtest/foldtest_example.dat')\n", "ipmag.bootstrap_fold_test(data, num_sims=300)"]}, {"block": 133, "type": "markdown", "linesLength": 8, "startIndex": 667, "lines": ["## foldtest_magic\n", "\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#foldtest_magic.py])\n", "\n", "This is just the MagIC formatted file version of **foldtest** and can be done using **ipmag.bootstrap_fold_test()** as above.  We just have to read in the MagIC formattest files and make a data matrix of the format expected by **ipmag.bootstrap_fold_test()**.  Here, **Pandas** is our friend.  We will: \n", "- Read in the MagIC (data model 3) formatted file\n", "- Make a **Numpy** array with the required fields\n", "- call **ipmag.bootstrap_foldtest_magic()**\n"]}, {"block": 134, "type": "code", "linesLength": 2, "startIndex": 675, "lines": ["sites=pd.read_csv('data_files/foldtest_magic/sites.txt',sep='\\t',header=1)\n", "sites.columns"]}, {"block": 135, "type": "markdown", "linesLength": 3, "startIndex": 677, "lines": ["The columns we need are: dir_dec, dir_inc, bed_dip_direction, bed_dip\n", "The dir_dec and dir_inc have to have a dir_tilt_correction of 0 (geographic coordinates).\n", "A little looking through the sites data file shows that the bed_dip_direction are on a separate line (oh database conversion tool maestro, how clever!).  So we will have to pair the bedding orientations with the geographic directional info.  Thank goodness for **Pandas**!\n"]}, {"block": 136, "type": "code", "linesLength": 14, "startIndex": 680, "lines": ["# read in data file\n", "sites=pd.read_csv('data_files/foldtest_magic/sites.txt',sep='\\t',header=1)\n", "# get the records with bed_dip and bed_dip_direction\n", "sites_bedding=sites.dropna(subset=['bed_dip','bed_dip_direction'])\n", "# get rid of them out of the original data frame\n", "sites.drop(['bed_dip','bed_dip_direction'],axis=1,inplace=True)\n", "# just pick out what we want (bedding orientation of the sites)\n", "sites_bedding=sites_bedding[['site','bed_dip','bed_dip_direction']]\n", "# put them back into the original data frame\n", "sites=pd.merge(sites,sites_bedding,how='inner',on='site')\n", "# now we can pick out the desired coordinate system\n", "sites_geo=sites[sites.dir_tilt_correction==0]\n", "# and make our data array\n", "data=sites_geo[['dir_dec','dir_inc','bed_dip_direction','bed_dip']].values\n"]}, {"block": 137, "type": "markdown", "linesLength": 1, "startIndex": 694, "lines": ["NB: One unfortunate thing about the MagIC data model is that bedding orientation information can be either in the samples.txt or the sites.txt file.  This example assumes the data are in the _sites.txt_ file.  If not, you can read in the _samples.txt_ file and merge the bedding information with the site directions.  "]}, {"block": 138, "type": "code", "linesLength": 2, "startIndex": 695, "lines": ["# and off we go! \n", "ipmag.bootstrap_fold_test(data, num_sims=300)"]}, {"block": 139, "type": "markdown", "linesLength": 2, "startIndex": 697, "lines": ["## forc_diagram\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#forc_diagram.py)"]}, {"block": 140, "type": "code", "linesLength": 22, "startIndex": 699, "lines": ["from programs.forc_diagram import *\n", "\n", "forc = Forc(fileAdres='data_files/forc_diagram/conventional_example.forc',SF=3)\n", "\n", "fig = plt.figure(figsize=(6,5), facecolor='white')\n", "\n", "fig.subplots_adjust(left=0.18, right=0.97,\n", "                    bottom=0.18, top=0.9, wspace=0.5, hspace=0.5)\n", "plt.contour(forc.xi*1000,\n", "            forc.yi*1000,\n", "            forc.zi,9,\n", "            colors='k',linewidths=0.5)#mt to T\n", "\n", "plt.pcolormesh(forc.xi*1000,\n", "               forc.yi*1000,\n", "               forc.zi,\n", "               cmap=plt.get_cmap('rainbow'))#vmin=np.min(rho)-0.2)\n", "plt.colorbar()\n", "plt.xlabel('B$_{c}$ (mT)',fontsize=12)\n", "plt.ylabel('B$_{i}$ (mT)',fontsize=12)\n", "\n", "plt.show()"]}, {"block": 141, "type": "markdown", "linesLength": 4, "startIndex": 721, "lines": ["## histplot\n", "\n", "\n", "You should use the function **plt.hist()** for this - see **[gaussian](#gaussian)** example."]}, {"block": 142, "type": "markdown", "linesLength": 9, "startIndex": 725, "lines": ["## hysteresis_magic\n", "\n", "[\\[Essentials Chapter 5\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch5.html#x15-156000813)\n", "[\\[Essentials Chapter 7\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch7.html#x15-156000813)\n", "[\\[Essentials Appendix C\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ap3.html#x21-227000B#x15-156000813)\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  \n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#hysteresis_magic.py)\n", "\n", "This program plots MagIC formatted measurement data as hysteresis loops, $\\Delta$M, d$\\Delta$M and backfield curves, depending on what data are available.  There is an **ipmag.hysteresis_magic** function that does this for us.  "]}, {"block": 143, "type": "code", "linesLength": 1, "startIndex": 734, "lines": ["help(ipmag.hysteresis_magic)"]}, {"block": 144, "type": "markdown", "linesLength": 1, "startIndex": 735, "lines": ["So let's try this out with some data from Ben-Yosef et al., (2008;doi: 10.1029/2007JB005235). The default is to plot the first 5 specimens and that is enough for us.  We also do not need to save plots at this point.  "]}, {"block": 145, "type": "code", "linesLength": 1, "startIndex": 736, "lines": ["ipmag.hysteresis_magic(output_dir_path='data_files/hysteresis_magic/',save_plots=False)"]}, {"block": 146, "type": "markdown", "linesLength": 1, "startIndex": 737, "lines": ["## irm_unmix"]}, {"block": 147, "type": "code", "linesLength": 13, "startIndex": 738, "lines": ["import matplotlib\n", "from programs.irm_unmix import dataFit, fit_plots\n", "fitResult = dataFit(filePath='data_files/irm_unmix/irm_unmix_example.dat',fitNumber=3)\n", "\n", "xfit=fitResult.fitDf['field']\n", "xraw=fitResult.rawDf['field_log']\n", "yfit=fitResult.pdf_best\n", "yraw=fitResult.rawDf['rem_grad_norm']\n", "\n", "fig = plt.figure(1, figsize=(5, 5))\n", "ax = fig.add_subplot(111)\n", "\n", "fit_plots(ax,xfit,xraw,yfit,yraw)"]}, {"block": 148, "type": "markdown", "linesLength": 8, "startIndex": 751, "lines": ["## irmaq_magic\n", "\n", "[\\[Essentials Chapter 8\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch8.html) \n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#irmaq_magic.py)\n", "\n", "Someone (Saiko Sugisaki) measured a number of samples from IODP Expedition 318 Hole U1359A for IRM acquisition curves. These were converted to the MagIC measurements format and saved in ../irmaq_magic/measurements.txt.  \n", "\n", "This program reads in a MagIC data model 3 file with IRM acquisition data and plots it by calling **pmagplotlib.plot_mag()** with options to plot by entire data file, site, sample or individual specimen.  We can do that too!  All we need to know is the method_code for IRM acquisition (which I do), and to propogate specimen => sample => site identities if any other plotting option besides \"entire file\" or by specimen is desired.  "]}, {"block": 149, "type": "code", "linesLength": 2, "startIndex": 759, "lines": ["plt.clf()\n", "help(pmagplotlib.plot_mag)"]}, {"block": 150, "type": "code", "linesLength": 19, "startIndex": 761, "lines": ["# make the figure\n", "plt.figure(1,(5,5))\n", "#read in the data\n", "data=pd.read_csv('data_files/irmaq_magic/measurements.txt',sep='\\t',header=1)\n", "# fish out the IRM data\n", "data=data[data.method_codes.str.contains('LP-IRM')] # \n", "data['zero']=0 # make a dummy field initialized with zero\n", "data['one']=1 # make a dummy field initialized with one\n", "# make the required list\n", "# possible intensity fields are:\n", "#['magn_moment', 'magn_volume', 'magn_mass', 'magnitude']\n", "# this data file has magn_moment data\n", "# pmagplotlib.plotMT plots data by specimen, so get list of specimens\n", "specimens=data.specimen.unique()\n", "for specimen in specimens: # step through one by one\n", "    spec_df=data[data.specimen==specimen] # get data for this specimen\n", "    # make the data block required\n", "    datablock=np.array(spec_df[['treat_dc_field','zero','zero','magn_moment','one','quality']]).tolist()\n", "    pmagplotlib.plot_mag(1,datablock,'Example',0,'T',1)"]}, {"block": 151, "type": "markdown", "linesLength": 16, "startIndex": 780, "lines": ["### lnp_magic\n", "\n", "[\\[Essentials Chapter 11\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch11.html#x15-156000813)\n", "[\\[Essentials Appendix C\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ap3.html#x21-227000B#x15-156000813)\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  \n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#lnp_magic.py)\n", "\n", "\n", "This program makes equal area projections site by site along with the \n", "Fisher confidence ellipses using the McFadden and McElhinny (1988, doi: 10.1016/0012-821X(88)90072-6) \n", "method for combining lines and planes.  Options are to plot in specimen, geographic or tilt corrected coordinate systems (although the specimen coordinate system is a bit silly if the specimens were not mutually oriented and the geographic and tilt correctioed would presumably be identical except for a coherent rotation of the site.)\n", "It also builds in filters for MAD or $\\alpha_{95}$ cutoffs at the specimen level.\n", "\n", "After filtering, the site level data are processed by **pmag.dolnp()** which calculates the MM88 statistics.  These, along with the data are then plotted by **pmagplotlib.plot_lnp()**.  \n", "\n", "We can do all that from within the notebook, using the wonders of Pandas."]}, {"block": 152, "type": "code", "linesLength": 1, "startIndex": 796, "lines": ["help(pmagplotlib.plot_lnp)"]}, {"block": 153, "type": "code", "linesLength": 6, "startIndex": 797, "lines": ["# read in specimen data\n", "spec_df=pd.read_csv('data_files/lnp_magic/specimens.txt',sep='\\t',header=1)\n", "# filter for quality = 'g'\n", "if 'quality'  in spec_df.columns:\n", "    spec_df=spec_df[spec_df.quality=='g']\n", "spec_df.head()\n"]}, {"block": 154, "type": "markdown", "linesLength": 1, "startIndex": 803, "lines": ["Of course, this being a data file conerted from data model 2.5 there are several lines per specimen. we want the non-blank dir_dec info with the desired (0) tilt correction"]}, {"block": 155, "type": "code", "linesLength": 3, "startIndex": 804, "lines": ["spec_df=spec_df.dropna(subset=['dir_dec','dir_inc','dir_tilt_correction'])\n", "spec_df=spec_df[spec_df.dir_tilt_correction==0]\n", "spec_df.head()"]}, {"block": 156, "type": "markdown", "linesLength": 3, "startIndex": 807, "lines": ["Let's proceed this way:\n", "- get a list of all the site names. for this we will have to pair the sample with the site name from the samples.txt file.\n", "- look at the data (only quality = 'g'), site by site, sending it to first **pmag.dolnp()**, then to **pmagplotlib.plot_lnp()**."]}, {"block": 157, "type": "code", "linesLength": 3, "startIndex": 810, "lines": ["# read in samples table in order to pair site name to specimen data\n", "samp_df=pd.read_csv('data_files/lnp_magic/samples.txt',sep='\\t',header=1)\n", "samp_df.head()"]}, {"block": 158, "type": "markdown", "linesLength": 1, "startIndex": 813, "lines": ["Of course there are duplicate sample records, so let's drop the blank lat rows (to make sure we have all the blank specimens rows, then make the data frame with just 'sample' and site' columns. Then we can merge it with the spec_df dataframe. "]}, {"block": 159, "type": "code", "linesLength": 4, "startIndex": 814, "lines": ["samp_df=samp_df.dropna(subset=['specimens'])\n", "samp_df=samp_df[['sample','site']]\n", "spec_df=pd.merge(spec_df,samp_df,on='sample')\n", "spec_df"]}, {"block": 160, "type": "code", "linesLength": 3, "startIndex": 818, "lines": ["# get the site names\n", "sites=spec_df.site.unique()\n", "sites"]}, {"block": 161, "type": "markdown", "linesLength": 1, "startIndex": 821, "lines": ["Let's plot up the first 10 or so."]}, {"block": 162, "type": "code", "linesLength": 1, "startIndex": 822, "lines": ["help(pmag.dolnp)"]}, {"block": 163, "type": "code", "linesLength": 1, "startIndex": 823, "lines": ["help(pmagplotlib.plot_lnp)"]}, {"block": 164, "type": "code", "linesLength": 7, "startIndex": 824, "lines": ["cnt=1\n", "for site in sites[0:10]:\n", "    pmagplotlib.plot_init(cnt, 5, 5)\n", "    site_data=spec_df[spec_df.site==site].to_dict('records')\n", "    fpars=pmag.dolnp(site_data,'specimen_direction_type')\n", "    pmagplotlib.plot_lnp(cnt,site,site_data,fpars,'specimen_direction_type')\n", "    cnt+=1\n"]}, {"block": 165, "type": "markdown", "linesLength": 7, "startIndex": 831, "lines": ["### lowes\n", "\n", "[\\[Essentials Chapter 2\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch2.html#x15-156000813)\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#lowes.py)\n", "\n", "\n", "This program generates a Lowes (1974, doi: 10.1111/j.1365-246X.1974.tb00622.x)  spectrum from igrf-like field models.  It will take a specified date, get the gauss coefficients from [**pmag.doigrf()**](#igrf), unpack them into a usable format with **pmag.unpack()** and calculate the spectrum with **pmag.lowes()**.  "]}, {"block": 166, "type": "code", "linesLength": 1, "startIndex": 838, "lines": ["help(pmag.unpack)"]}, {"block": 167, "type": "code", "linesLength": 1, "startIndex": 839, "lines": ["help(pmag.lowes)"]}, {"block": 168, "type": "markdown", "linesLength": 1, "startIndex": 840, "lines": ["So let's do it!"]}, {"block": 169, "type": "code", "linesLength": 4, "startIndex": 841, "lines": ["date=1956 # pick a date and what better one than my birth year?  \n", "coeffs=pmag.doigrf(0,0,0,date,coeffs=1) # get the gauss coefficients\n", "data=pmag.unpack(coeffs) # unpack them into the form that lowes likes\n", "Ls,Rs=pmag.lowes(data) # get the power spectrum\n"]}, {"block": 170, "type": "code", "linesLength": 6, "startIndex": 845, "lines": ["plt.plot(Ls,Rs,linewidth=2,label=str(date)) # make the plot\n", "plt.semilogy() # semi log it\n", "plt.xlabel('Degree (l)')\n", "plt.ylabel('Power ($\\mu$T$^2$)')\n", "plt.legend();\n", "\n"]}, {"block": 171, "type": "markdown", "linesLength": 13, "startIndex": 851, "lines": ["### lowrie and lowrie_magic\n", "\n", "[\\[Essentials Chapter 8\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch8.html#x15-156000813)\n", "[\\[command line versions\\]](http://pmagpy.github.io/PmagPy-cli.html#lowrie.py)\n", "\n", " Someone (Saiko Sugisaki) subjected a number of specimens from IODP Expedition 318 Site U1361 specimens to a Lowrie (1990, doi: 10.1029/GL017i002p00159) 3-D IRM experiment (published as Tauxe et al., 2015, doi:10.1016/j.epsl.2014.12.034). **lowrie** makes plots of blocking temperature for the three coercivity fractions.\n", "\n", "\n", "Both **lowrie** and **lowrie_magic**   take specimen level 3D-IRM data, break them into the cartesian coordinates  of the three IRM field directions and plot the different components versus demagnetizing temperature.  We can  do this with our powerful **Pandas** and **matplotlib**.  \n", "The relevent MagIC database method code is 'LP-IRM-3D', magnetization code is one of the usual, but in this example it is 'magn_moment' and the temperature step is the usual data model 3.0 ('treat_temp') in kelvin.\n", "\n", "\n", "We will use **pmag.dir2cart()** for the heavy lifting.  I also happen to know (because I wrote the original paper), that the X direction was the 1.0 tesla step, Y was 0.5 tesla and Z was .1 tesla, so we can put these in the legend. "]}, {"block": 172, "type": "code", "linesLength": 1, "startIndex": 864, "lines": ["help(pmag.dir2cart)"]}, {"block": 173, "type": "code", "linesLength": 25, "startIndex": 865, "lines": ["# read in the data file\n", "meas_df=pd.read_csv('data_files/lowrie_magic/measurements.txt',sep='\\t',header=1)\n", "# pick out the 3d-IRM data\n", "meas_df=meas_df[meas_df.method_codes.str.contains('LP-IRM-3D')]\n", "# get a list of specimen names\n", "specimens=meas_df.specimen.unique()\n", "cnt=1 # set figure counter\n", "for specimen in specimens[0:10]: # step through first 10\n", "    spec_df=meas_df[meas_df.specimen==specimen] # collect this specimen's data    \n", "    dirs=np.array(spec_df[['dir_dec','dir_inc','magn_moment']])\n", "    norm=dirs[0][2] # let's normalize to the initial intensity\n", "    carts=np.absolute((pmag.dir2cart(dirs)/norm)).transpose() # get the X,Y,Z data\n", "    temps=spec_df['treat_temp']-273 # convert to Celcius\n", "    plt.figure(cnt,(6,6))\n", "    plt.plot(temps,carts[0],'ro',label='1 T')\n", "    plt.plot(temps,carts[0],'r-')\n", "    plt.plot(temps,carts[1],'cs',label='0.5 T')\n", "    plt.plot(temps,carts[1],'c-')\n", "    plt.plot(temps,carts[2],'k^',label='0.1 T')\n", "    plt.plot(temps,carts[2],'k-')\n", "    plt.title(specimen+' : Lowrie 3-D IRM')\n", "    plt.legend();\n", "    cnt+=1\n", "\n", "        "]}, {"block": 174, "type": "markdown", "linesLength": 3, "startIndex": 890, "lines": ["### plotXY\n", "\n", "This can be done directly with matplotlib."]}, {"block": 175, "type": "markdown", "linesLength": 5, "startIndex": 893, "lines": ["### plot_cdf\n", "\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#plot_cdf.py)\n", "\n", "This program reads in a data file, sorts it and plots the data as a cumulative distribution function (using **pmagplotlib.plot_cdf()**.  But we can do this directly from within the notebook without much fuss. And for plot_2cdfs, just do this twice.  \n"]}, {"block": 176, "type": "code", "linesLength": 10, "startIndex": 898, "lines": ["# read the data in\n", "data=np.loadtxt('data_files/plot_cdf/gaussian.out')\n", "# sort the data\n", "x=np.sort(data)\n", "# create a y array\n", "y=np.linspace(0,1,data.shape[0])\n", "plt.plot(x,y,'r-')\n", "# label\n", "plt.xlabel('Data')\n", "plt.ylabel('Cumulative Distribution');"]}, {"block": 177, "type": "markdown", "linesLength": 7, "startIndex": 908, "lines": ["### plot_geomagia\n", "\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#plot_geomagia.py)\n", "\n", "Geomagia is a database specially designed for archaeomagnetic and volcanic data for the last 50 kyr with a friendly search interface.   **plot_geomagia**   is meant to plot data from files downloaded from the geomagia website: http://geomagia.gfz-potsdam.de/geomagiav3/AAquery.php.  We can do this within the notebook.  The example used here  was for Sicily so if we felt like it, we could combine it with the **ipmag.igrf()** using one of the data models (which are in large part based on data in the geomagia database.  \n", "\n", "Here we want to plot inclination as a function of age.  "]}, {"block": 178, "type": "code", "linesLength": 2, "startIndex": 915, "lines": ["geomagia=pd.read_csv('data_files/geomagia/geomagia_sel.txt',header=1)\n", "geomagia.head()"]}, {"block": 179, "type": "markdown", "linesLength": 1, "startIndex": 917, "lines": ["We have to 'clean' the dataset by getting rid of the records with no inclinations (-999)  We can use Panda's filtering power for that: "]}, {"block": 180, "type": "code", "linesLength": 2, "startIndex": 918, "lines": ["geomagia_incs=geomagia[geomagia['Inc[deg.]']>-90]\n", "geomagia_incs['Inc[deg.]']"]}, {"block": 181, "type": "code", "linesLength": 3, "startIndex": 920, "lines": ["plt.plot(geomagia_incs['Age[yr.AD]'],geomagia_incs['Inc[deg.]'],'ro')\n", "plt.xlabel('Age (CE)')\n", "plt.ylabel('Inclination');"]}, {"block": 182, "type": "markdown", "linesLength": 6, "startIndex": 923, "lines": ["### plot_mag_map\n", "\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#plot_mag_map.py)\n", "\n", "This program was designed to make color contour maps of geomagnetic field elements drawn from various IGRF-like field models (see also [igrf](#igrf)).  \n", "It calls **pmag.do_mag_map())** to generate arrays for plotting with the **pmagplotlib.plot_mag_map()** function.   We can do that from within this notebook.  NB: The cartopy version of this is still a bit buggy and functions best with the PlateCarree projection.  "]}, {"block": 183, "type": "code", "linesLength": 1, "startIndex": 929, "lines": ["help(pmag.do_mag_map)"]}, {"block": 184, "type": "code", "linesLength": 3, "startIndex": 930, "lines": ["# define some useful parameters\n", "date,mod,lon_0,alt,ghfile=1956.0725,'cals10k.2',0,0,\"\" # only date is required\n", "Ds,Is,Bs,Brs,lons,lats=pmag.do_mag_map(date,mod=mod,lon_0=lon_0,alt=alt,file=ghfile)"]}, {"block": 185, "type": "code", "linesLength": 1, "startIndex": 933, "lines": ["help(ipmag.igrf)"]}, {"block": 186, "type": "code", "linesLength": 1, "startIndex": 934, "lines": ["help(pmagplotlib.plot_mag_map)"]}, {"block": 187, "type": "code", "linesLength": 10, "startIndex": 935, "lines": ["cmap='RdYlBu' # nice color map for contourf\n", "if has_cartopy:\n", "    pmagplotlib.plot_mag_map(1,Bs,lons,lats,'B',date=date,proj='Mollweide',contours=True) # plot the field strength\n", "    pmagplotlib.plot_mag_map(2,Is,lons,lats,'I',date=date,proj='Mollweide',contours=True)# plot the inclination\n", "    pmagplotlib.plot_mag_map(3,Ds,lons,lats,'D',date=date,contours=True)# plot the declination    \n", "elif has_basemap:\n", "    pmagplotlib.plot_mag_map_basemap(1,Bs,lons,lats,'B',date=date) # plot the field strength\n", "    pmagplotlib.plot_mag_map_basemap(2,Is,lons,lats,'I',date=date)# plot the inclination\n", "    pmagplotlib.plot_mag_map_basemap(3,Ds,lons,lats,'D',date=date)# plot the declination\n", "    "]}, {"block": 188, "type": "markdown", "linesLength": 7, "startIndex": 945, "lines": ["### plot_map_pts\n", "\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#plot_map_pts.py)\n", "\n", "This program will generate a simple map of the data points read from a file (lon lat) on the desired projection. If you want to use high resolution or the etopo20 meshgrid with basemap, you must install the etopo20 data files (run  **install_etopo.py** from the command line).\n", "\n", "This program sets  a bunch of options and calls **pmagplotlib.plot_map()**.  Note, if Basemap is  installed, you can use **pmagplotlib.plot_map_basemap()** instead which uses the older (but less buggy) and soon to be deprecated **Basemap** plotting package.   \n"]}, {"block": 189, "type": "code", "linesLength": 1, "startIndex": 952, "lines": ["help(pmagplotlib.plot_map)"]}, {"block": 190, "type": "code", "linesLength": 18, "startIndex": 953, "lines": ["# read in some data: \n", "# this is the cartopy version\n", "data=np.loadtxt('data_files/plot_map_pts/uniform.out').transpose()\n", "lons=data[0] # longitudes array\n", "lats=data[1] # latitudes array\n", "# set some options \n", "Opts={}\n", "Opts['sym']='bo' # sets the symbol to white dots\n", "Opts['symsize']=3 # sets symbol size to 3 pts\n", "Opts['proj']='robin' # Robinson projection\n", "Opts['details']={}\n", "Opts['details']['coasts']=True\n", "plt.figure(1,(10,10)) # optional - make a map\n", "if has_cartopy:\n", "    pmagplotlib.plot_map(1, lats, lons, Opts)\n", "elif has_basemap:\n", "    pmagplotlib.plot_map_basemap(1, lats, lons, Opts)\n", "    "]}, {"block": 191, "type": "code", "linesLength": 19, "startIndex": 971, "lines": ["# read in some data: \n", "data=np.loadtxt('data_files/plot_map_pts/uniform.out').transpose()\n", "lons=data[0] # longitudes array\n", "lats=data[1] # latitudes array\n", "# set some options \n", "Opts={}\n", "Opts['sym']='wo' # sets the symbol to white dots\n", "Opts['symsize']=3 # sets symbol size to 10 pts\n", "Opts['proj']='pc' # Platecarre projection\n", "Opts['edge']='black'\n", "Opts['details']={}\n", "Opts['details']['fancy']=True # this option takes a while....   \n", "if has_cartopy:\n", "    plt.figure(1,(8,8)) # optional - make a map\n", "    pmagplotlib.plot_map(1, lats, lons, Opts)   \n", "elif has_basemap: # this only works if you have basemap installed\n", "    plt.figure(1,(6,6)) # optional - make a map\n", "    pmagplotlib.plot_map_basemap(1, lats, lons, Opts)\n", "    "]}, {"block": 192, "type": "markdown", "linesLength": 1, "startIndex": 990, "lines": ["Here's an example with a simple site location."]}, {"block": 193, "type": "code", "linesLength": 25, "startIndex": 991, "lines": ["Opts={}\n", "Opts['sym']='r*' # sets the symbol to white dots\n", "Opts['symsize']=100 # sets symbol size to 3 pts\n", "Opts['proj']='lcc' # Lambert Conformal projection\n", "Opts['pltgrid']=True\n", "Opts['lat_0']=33\n", "Opts['lon_0']=260\n", "Opts['latmin']=20\n", "Opts['latmax']=52\n", "Opts['lonmin']=-130\n", "Opts['lonmax']=-70\n", "Opts['gridspace']=10\n", "Opts['details']={}\n", "Opts['details']['coasts']=True\n", "Opts['details']['ocean']=True\n", "Opts['details']['countries']=True\n", "Opts['global']=False\n", "lats,lons=[33],[-117]\n", "plt.figure(1,(10,10)) # optional - make a map\n", "if has_cartopy:\n", "    pmagplotlib.plot_map(1, lats, lons, Opts)\n", "elif has_basemap:\n", "    pmagplotlib.plot_map_basemap(1, lats, lons, Opts)\n", "\n", "    \n"]}, {"block": 194, "type": "markdown", "linesLength": 8, "startIndex": 1016, "lines": ["### plotdi_a\n", "\n", "[\\[Essentials Chapter 11\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch11.html) [\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#plotdi_a.py)\n", "\n", "\n", "**plotdi_a** reads in a data file with declination, inclination and $\\alpha_{95}$ data in it and plots the directions along with the confidence circles.  \n", "\n", "We can use the function **ipmag.plot_di_mean()** for this.  \n"]}, {"block": 195, "type": "code", "linesLength": 1, "startIndex": 1024, "lines": ["help(ipmag.plot_di_mean)"]}, {"block": 196, "type": "code", "linesLength": 11, "startIndex": 1025, "lines": ["# read in some data\n", "data=np.loadtxt('data_files/plotdi_a/plotdi_a_example.dat').transpose()\n", "decs=data[0] # array of declinations\n", "incs=data[1] # array of inclinations\n", "a95s=data[2] # array of alpha95s\n", "# make the plots\n", "fignum=1\n", "plt.figure(num=fignum,figsize=(3,3)) # make a figure object\n", "ipmag.plot_net(fignum) # plot the equal area net\n", "for pt in range(decs.shape[0]): # step through the data\n", "    ipmag.plot_di_mean(dec=decs[pt],inc=incs[pt],a95=a95s[pt],color='blue')\n"]}, {"block": 197, "type": "markdown", "linesLength": 10, "startIndex": 1036, "lines": ["### polemap_magic\n", "\n", "\n", "[\\[Essentials Chapter 16\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch16.html) \n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#polemap_magic.py)\n", "\n", "**polemap_magic** plots poles from a MagIC formatted **locations.txt** file.  Alternatively, we \n", " can use **ipmag.plot_vgp()** for this, but substituting paleomagnetic poles for VGPs (the math is the same).  We'll try this out on a set of poles downloaded from the MagIC database for the Cretaceous of Europe.   \n", " \n", " Let's try it both ways, first with **ipmag.plot_vgp( )**:\n"]}, {"block": 198, "type": "code", "linesLength": 1, "startIndex": 1046, "lines": ["help(ipmag.plot_vgp)"]}, {"block": 199, "type": "code", "linesLength": 1, "startIndex": 1047, "lines": ["help(ipmag.make_orthographic_map)"]}, {"block": 200, "type": "code", "linesLength": 18, "startIndex": 1048, "lines": ["data=pd.read_csv('data_files/polemap_magic/locations.txt',sep='\\t',header=1)\n", "lats=data['pole_lat'].values\n", "lons=data['pole_lon'].values\n", "if has_cartopy:\n", "    map_axis =ipmag.make_orthographic_map(central_latitude=90,figsize=(6,6),land_color='bisque')\n", "    ipmag.plot_vgp(map_axis, vgp_lon=lons, vgp_lat=lats,\\\n", "                   markersize=20, legend='no')    \n", "    \n", "elif has_basemap:\n", "    m = Basemap(projection='ortho',lat_0=90,lon_0=0)\n", "    plt.figure(figsize=(6, 6))\n", "    m.drawcoastlines(linewidth=0.25)\n", "    m.fillcontinents(color='bisque',lake_color='white',zorder=1)\n", "    m.drawmapboundary(fill_color='white')\n", "    m.drawmeridians(np.arange(0,360,30))\n", "    m.drawparallels(np.arange(-90,90,30))\n", "    ipmag.plot_vgp_basemap(m, vgp_lon=lons, vgp_lat=lats, color='k', marker='o', \\\n", "                   markersize=20, legend='no')"]}, {"block": 201, "type": "markdown", "linesLength": 1, "startIndex": 1066, "lines": ["Alternatively, you can use the function **ipmag.polemap_magic**."]}, {"block": 202, "type": "code", "linesLength": 1, "startIndex": 1067, "lines": ["help(ipmag.polemap_magic)"]}, {"block": 203, "type": "code", "linesLength": 1, "startIndex": 1068, "lines": ["ipmag.polemap_magic('data_files/polemap_magic/locations.txt', save_plots=False)"]}, {"block": 204, "type": "markdown", "linesLength": 3, "startIndex": 1069, "lines": ["### Plotting poles with A_{95} ellipse\n", "\n", "**ipmag.plot_pole()** can be used to plot a poles with a A_{95} uncertainty ellipse."]}, {"block": 205, "type": "code", "linesLength": 1, "startIndex": 1072, "lines": ["help(ipmag.plot_pole)"]}, {"block": 206, "type": "code", "linesLength": 7, "startIndex": 1073, "lines": ["plon = 200\n", "plat = 60\n", "A95 = 6\n", "\n", "if has_cartopy:\n", "    map_axis = ipmag.make_orthographic_map(central_longitude=200,central_latitude=30)\n", "    ipmag.plot_pole(map_axis, plon, plat, A95 ,color='red',markersize=40)"]}, {"block": 207, "type": "markdown", "linesLength": 3, "startIndex": 1080, "lines": ["### plot_ts\n", "\n", "**pmagplotlib.plot_ts( )** makes a plot of the Geomagnetic Reversal Time Scale (your choice of several) between specified age points.  "]}, {"block": 208, "type": "code", "linesLength": 1, "startIndex": 1083, "lines": ["help(pmagplotlib.plot_ts)"]}, {"block": 209, "type": "code", "linesLength": 5, "startIndex": 1084, "lines": ["fig=plt.figure(1,(3,12))\n", "ax=fig.add_subplot(111)\n", "agemin,agemax=0,10\n", "pmagplotlib.plot_ts(ax,agemin,agemax)\n", "\n"]}, {"block": 210, "type": "markdown", "linesLength": 6, "startIndex": 1089, "lines": ["### qqplot\n", "\n", "[\\[Essentials Appendix B.1.5\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ap2.html)\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#qqplot.py)\n", "\n", "**qqplot** makes  a quantile-quantile plot of the input data file against a normal distribution. The plot has the mean, standard deviation and the $D$ statistic as well as the $D_c$ statistic expected from a normal distribution. We can read in a data file and then call **pmagplotlib.plot_qq_norm()**. Let's reprise the [**gaussian**](#gaussian) example from before and test if the data are in fact likely to be normally distributed.    \n"]}, {"block": 211, "type": "code", "linesLength": 1, "startIndex": 1095, "lines": ["data=list(pmag.gaussdev(10,3,100))"]}, {"block": 212, "type": "code", "linesLength": 1, "startIndex": 1096, "lines": ["help(pmagplotlib.plot_qq_norm)"]}, {"block": 213, "type": "code", "linesLength": 2, "startIndex": 1097, "lines": ["D,Dc=pmagplotlib.plot_qq_norm(1,data,'')\n", "print (D,Dc)"]}, {"block": 214, "type": "markdown", "linesLength": 1, "startIndex": 1099, "lines": ["Whew!  it worked this time.  It will fail about 5% of the time.  "]}, {"block": 215, "type": "markdown", "linesLength": 7, "startIndex": 1100, "lines": ["### qqunf\n", "\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#qqunf.py)\n", "\n", "This program is very much like [**qqplot**](#qqplot) and [**fishqq**](#fishqq) which plot data against a normal and Fisherian distributions respectively.  In fact **fishqq** plots the declination values against a uniform distribution just like **qqunf**. \n", "\n", "**qqunf.py** (the command line version) calls **pmagplotlib.plot_qq_unf()**.  To demonstrate the functionality of **qqplot**, we can generate a simulated data set with **random.uniform()**, inspect it with a histogram and then test whether it is likely to actually have been drawn from a uniform distribution (95% confidence) using **pmagplotlib.plot_qq_unf()**."]}, {"block": 216, "type": "code", "linesLength": 3, "startIndex": 1107, "lines": ["import numpy.random as random\n", "uniform=random.uniform(0,100,size=100)\n", "plt.hist(uniform,histtype='step',color='blue',density=True,facecolor='white')"]}, {"block": 217, "type": "code", "linesLength": 1, "startIndex": 1110, "lines": ["Mu,Mu_0=pmagplotlib.plot_qq_unf(1,uniform,\"\",degrees=False)"]}, {"block": 218, "type": "markdown", "linesLength": 2, "startIndex": 1111, "lines": ["### quick_hyst\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#quick_hyst.py)\n"]}, {"block": 219, "type": "code", "linesLength": 4, "startIndex": 1113, "lines": ["from importlib import reload\n", "reload(ipmag)\n", "\n", "ipmag.quick_hyst(\"data_files/3_0/McMurdo\")#, save_plots=False)"]}, {"block": 220, "type": "markdown", "linesLength": 6, "startIndex": 1117, "lines": ["### revtest\n", "\n", "[\\[Essentials Chapter 12\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch12.html)\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#revtest.py)\n", "\n", "**revtest** uses the boostrap reversals test described in detail in [\\[Chapter 12\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch12.html) of the online text book \"Essentials of Paleomagnetism\".  It splits the data into two polarity groups, flips the \"reverse\" mode to its antipodes and does the test for [common_mean](#common_mean) on the two groups.   It has been implemented for notebooks as **ipmag.reversal_test_bootstrap())**.  "]}, {"block": 221, "type": "code", "linesLength": 1, "startIndex": 1123, "lines": ["help(ipmag.reversal_test_bootstrap)"]}, {"block": 222, "type": "code", "linesLength": 2, "startIndex": 1124, "lines": ["di_block=np.loadtxt('data_files/revtest/revtest_example.txt')\n", "ipmag.reversal_test_bootstrap(di_block=di_block,plot_stereo=True)"]}, {"block": 223, "type": "markdown", "linesLength": 8, "startIndex": 1126, "lines": ["### revtest_magic\n", "\n", "[\\[Essentials Chapter 12\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch12.html)\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#revtest_magic.py)\n", "\n", "\n", "This is the same idea as **revtest** but reads in MagIC formatted data files.  We will do this the **Pandas** way.  "]}, {"block": 224, "type": "code", "linesLength": 4, "startIndex": 1134, "lines": ["data=pd.read_csv('data_files/revtest_magic/sites.txt',sep='\\t',header=1)\n", "decs=data.dir_dec.values\n", "incs=data.dir_inc.values\n", "ipmag.reversal_test_bootstrap(dec=decs,inc=incs,plot_stereo=True)"]}, {"block": 225, "type": "markdown", "linesLength": 3, "startIndex": 1138, "lines": ["### revtest_mm1990\n", "\n", "This program has been deprecated as it  is the same as [watsons_v](#watons_v) - check that one out. "]}, {"block": 226, "type": "markdown", "linesLength": 13, "startIndex": 1141, "lines": ["### thellier_magic\n", "\n", "[\\[Essentials Chapter 10\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch10.html) \n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#thellier_magic.py)\n", "\n", "**thellier_magic** makes plots for Thellier-Thellier (Thellier E and Thellier O, 1959, Annales de Geophysique 15: 285\u2013378) type experimental data.   \n", "It reads in MagIC formatted data, sorts the data into datablocks for plotting as Arai (Nagata et al., 1963, doi: 10.1029/JZ068i018p05277) or  Zijderveld (Zijderveld, J. D. A. (1967). A.C. demagnetization of rocks: analysis of results. In D. Collinson, K. Creer, & S. Runcorn (Eds.), Methods in Paleomagnetism (pp. 254\u2013286). Amsterdam: Elsevier) as well as equal area projections and de (re) magnetization plots. \n", "\n", "For full functionality, you should use the Thellier GUI program (in **pmag_gui.py** from the command line), but within a notebook you can take a quick look using **ipmag.thellier_magic()**.  \n", "\n", "Here we will look at some data from Shaar et al. (2011, doi: 10.1016/j.epsl.2010.11.013).   \n", "\n"]}, {"block": 227, "type": "code", "linesLength": 3, "startIndex": 1154, "lines": ["# plot the first five specimens\n", "ipmag.thellier_magic(input_dir_path='data_files/thellier_magic/', \n", "                     n_specs=5, save_plots=False, fmt=\"png\") # s2s0-05 "]}, {"block": 228, "type": "markdown", "linesLength": 10, "startIndex": 1157, "lines": ["### vgpmap_magic\n", "\n", "[\\[Essentials Chapter 2\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch2.html) \n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#vgpmap_magic.py)\n", "\n", "Plotting distributions of Virtual Geomagnetic Poles on many desired map projections is a frequent need in paleomagnetism.  **vgpmap_magic** reads in MagIC formatted files and has a number of plotting options.  It has been implemented into the **ipmag** module by Nick Swanson-Hysell as **ipmag.plot_vgp()**.  \n", "We cam use  **ipmag.plot_vgp()** after reading in a MagIC formatted sites.txt file. \n", "\n", "NB: you could also use **pmagplotlib.plot_map()** (see [**plot_map_pts**](#plot_map_pts)) if more options are desired. "]}, {"block": 229, "type": "code", "linesLength": 1, "startIndex": 1167, "lines": ["help(ipmag.plot_vgp)"]}, {"block": 230, "type": "code", "linesLength": 2, "startIndex": 1168, "lines": ["data=pd.read_csv('data_files/vgpmap_magic/sites.txt',sep='\\t',header=1)\n", "data.columns"]}, {"block": 231, "type": "code", "linesLength": 1, "startIndex": 1170, "lines": ["help(ipmag.make_orthographic_map)"]}, {"block": 232, "type": "code", "linesLength": 18, "startIndex": 1171, "lines": ["lats=data['vgp_lat'].values\n", "lons=data['vgp_lon'].values\n", "if has_cartopy:\n", "    map_axis =ipmag.make_orthographic_map(central_latitude=60,figsize=(6,6),land_color='bisque',\\\n", "                                          add_ocean=True,ocean_color='azure')\n", "    ipmag.plot_vgp(map_axis, vgp_lon=lons, vgp_lat=lats,\\\n", "                   markersize=50, legend='no',color='red')    \n", "    \n", "elif has_basemap:\n", "    m = Basemap(projection='ortho',lat_0=60,lon_0=0)\n", "    plt.figure(figsize=(6, 6))\n", "    m.drawcoastlines(linewidth=0.25)\n", "    m.fillcontinents(color='bisque',lake_color='azure',zorder=1)\n", "    m.drawmapboundary(fill_color='azure')\n", "    m.drawmeridians(np.arange(0,360,30))\n", "    m.drawparallels(np.arange(-90,90,30))\n", "    ipmag.plot_vgp_basemap(m, vgp_lon=lons, vgp_lat=lats, color='r', marker='o', \\\n", "                   markersize=50, legend='no')"]}, {"block": 233, "type": "markdown", "linesLength": 1, "startIndex": 1189, "lines": ["Or, you can run ipmag.vgpmap_magic:"]}, {"block": 234, "type": "code", "linesLength": 1, "startIndex": 1190, "lines": ["help(ipmag.vgpmap_magic)"]}, {"block": 235, "type": "code", "linesLength": 1, "startIndex": 1191, "lines": ["ipmag.vgpmap_magic('data_files/vgpmap_magic', lat_0=60, save_plots=False)"]}, {"block": 236, "type": "markdown", "linesLength": 7, "startIndex": 1192, "lines": ["### watsons_v\n", "\n", "[\\[Essentials Chapter 11\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch11.html) \n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#watsons_v.py)\n", "\n", "Watson (1983, doi: 10.1016/0378-3758(83)90043-5) proposed a clever Monte Carlo type test for a common mean direction for two data sets.  This was implemented as \n", " **ipmag.common_mean_watson()**. \n"]}, {"block": 237, "type": "code", "linesLength": 1, "startIndex": 1199, "lines": ["help(ipmag.common_mean_watson)"]}, {"block": 238, "type": "code", "linesLength": 6, "startIndex": 1200, "lines": ["# use the same data as for watsons_f\n", "DI1=np.loadtxt('data_files/watsons_f/watsons_f_example_file1.dat')\n", "DI2=np.loadtxt('data_files/watsons_f/watsons_f_example_file2.dat')\n", "\n", "plt.figure(1,(5,5))\n", "ipmag.common_mean_watson(DI1,DI2,plot='yes')\n"]}, {"block": 239, "type": "markdown", "linesLength": 9, "startIndex": 1206, "lines": ["### zeq \n", "\n", "[\\[Essentials Chapter 9\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch9.html) \n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#zeq.py)\n", "\n", "**zeq** is a quick and dirty plotter for Zijderveld (Zijderveld, J. D. A. (1967). A.C. demagnetization of rocks: analysis of results. In D. Collinson, K. Creer, & S. Runcorn (Eds.), Methods in Paleomagnetism (pp. 254\u2013286). Amsterdam: Elsevier) diagrams.  It calls **pmagplotlib.plot_zed()** to do the plotting. \n", "\n", "This example plots the data in specimen coordinates = if other coordinate systems are desired, perform [**di_geo**](#di_geo) and [**di_tilt**](#di_tilt) steps first.  \n", "\n"]}, {"block": 240, "type": "code", "linesLength": 1, "startIndex": 1215, "lines": ["help(pmagplotlib.plot_zed)"]}, {"block": 241, "type": "code", "linesLength": 21, "startIndex": 1216, "lines": ["# we can make the figure dictionary that pmagplotlib likes:\n", "ZED={'eqarea':1,'zijd':2, 'demag':3}# make datablock\n", " # read in data\n", "data=pd.read_csv('data_files/zeq/zeq_example.dat',delim_whitespace=True,header=None)\n", "data.columns=['specimen','step','m (emu)','dec','inc']\n", "data['m SI']=data['m (emu)']*1e-3 # convert to SI units from lab (emu) units\n", "data['quality']='g' # add in default \"good\" quality designation\n", "data['step SI']=data['step']*1e-3 # convert to tesla \n", "data['blank']=\"\" # this is a dummy variable expected by plotZED\n", "specimens=data.specimen.unique()\n", "angle=0\n", "units='T' # these are AF data\n", "cnt=1\n", "for s in specimens:\n", "    # we can make the figure dictionary that pmagplotlib likes:\n", "    ZED={'eqarea':cnt,'zijd':cnt+1, 'demag':cnt+2}# make datablock\n", "    cnt+=3\n", "    spec_df=data[data.specimen==s]\n", "    datablock=spec_df[['step SI','dec','inc','m SI','blank','quality']].values.tolist()\n", "    pmagplotlib.plot_zed(ZED,datablock,angle,s,units)\n", "    \n"]}, {"block": 242, "type": "markdown", "linesLength": 8, "startIndex": 1237, "lines": ["### zeq_magic\n", "\n", "[\\[Essentials Chapter 9\\]](https://earthref.org/MagIC/books/Tauxe/Essentials/WebBook3ch9.html) \n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)\n", "[\\[command line version\\]](http://pmagpy.github.io/PmagPy-cli.html#zeq_magic.py)\n", "\n", "This program is the same as [**zeq**](#zeq) but for MagIC formatted input files.  This example plots the data in specimen coordinates = if other coordinate systems are desired, perform [**di_geo**](#di_geo) and [**di_tilt**](#di_tilt) steps first.\n", "\n"]}, {"block": 243, "type": "code", "linesLength": 3, "startIndex": 1245, "lines": [" # read in MagIC foramatted data\n", "dir_path='data_files/zeq_magic/'\n", "ipmag.zeq_magic(input_dir_path=dir_path, save_plots=False)"]}, {"block": 244, "type": "markdown", "linesLength": 1, "startIndex": 1248, "lines": ["## Clean up"]}, {"block": 245, "type": "code", "linesLength": 62, "startIndex": 1249, "lines": ["import glob\n", "import os\n", "# remove some individual files\n", "\n", "filenames = ['chart.txt',\n", "            'data_files/azdip_magic/samples.txt', 'data_files/download_magic/criteria.txt', \n", "            'data_files/orientation_magic/samples.txt', 'data_files/orientation_magic/sites.txt',\n", "            'data_files/download_magic/ages.txt', 'data_files/download_magic/contribution.txt', \n", "            'data_files/download_magic/measurements.txt', 'data_files/download_magic/samples.txt',\n", "            'data_files/download_magic/specimens.txt', 'data_files/download_magic/locations.txt']\n", "\n", "\n", "for fname in filenames:\n", "    try:\n", "        os.remove(fname)\n", "    except FileNotFoundError:\n", "        pass\n", "  \n", "\n", "# remove all MagIC-generated files from a given directory\n", "\n", "def remove_magic_files(directory):\n", "    magic_files = ['specimens.txt', 'samples.txt', 'sites.txt', 'locations.txt', 'measurements.txt', \n", "                   'contribution.txt', 'ages.txt']\n", "    dir_files = os.listdir(directory)\n", "    for dtype in magic_files:\n", "        try:\n", "            os.remove(dtype)\n", "        except FileNotFoundError:\n", "            pass\n", "        for fname in dir_files:\n", "            if fname.endswith(dtype):\n", "                try:\n", "                    os.remove(os.path.join(directory, fname))\n", "                except FileNotFoundError:\n", "                    pass\n", "    for full_fname in glob.glob(os.path.join(directory, '*.magic')):\n", "        os.remove(full_fname)\n", "        \n", "        \n", "        \n", "# not convert_2_magic/jr6_magic\n", "\n", "for directory in ['.', 'data_files/convert_2_magic/2g_bin_magic/mn1', 'data_files/convert_2_magic/pmd_magic/PMD/',\n", "                  'data_files', 'data_files/k15_s', 'data_files/convert_2_magic/agm_magic', \n", "                  'data_files/convert_2_magic/huji_magic', 'data_files/convert_2_magic/bgc_magic',\n", "                  'data_files/convert_2_magic/kly4s_magic', 'data_files/convert_2_magic/mst_magic',\n", "                  'data_files/convert_ages', 'data_files/convert_2_magic/cit_magic/MIT/7325B',\n", "                  'data_files/convert_2_magic/cit_magic/USGS/bl9-1', 'data_files/convert_2_magic/tdt_magic',\n", "                  'data_files/convert_2_magic/ldeo_magic', 'data_files/convert_2_magic/k15_magic',\n", "                  'data_files/convert_2_magic/generic_magic']:\n", "    remove_magic_files(directory)\n", "\n", "\n", "lst = ['*.png', './data_files/convert_2_magic/jr6_magic/SML*.txt', './data_files/download_magic/Snake*',\n", "      './data_files/convert_2_magic/jr6_magic/AP12_*.txt', \n", "      './data_files/convert_2_magic/jr6_magic/*_measurements.txt', './data_files/convert_2_magic/jr6_magic/*.magic',\n", "      './data_files/3_0/McMurdo/*.tex', './data_files/3_0/McMurdo/*.xls', './data_files/3_0/Megiddo/*.tex',\n", "      'data_files/3_0/Megiddo/*.xls']\n", "for directory in lst:\n", "    for fname in glob.glob(directory):\n", "        os.remove(fname)  "]}, {"block": 246, "type": "code", "linesLength": 0, "startIndex": 1311, "lines": []}]