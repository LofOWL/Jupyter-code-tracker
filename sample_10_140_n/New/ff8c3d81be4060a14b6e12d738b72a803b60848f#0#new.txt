[{"block": 0, "type": "markdown", "linesLength": 1, "startIndex": 0, "lines": ["## The data block API"]}, {"block": 1, "type": "code", "linesLength": 3, "startIndex": 1, "lines": ["from fastai.gen_doc.nbdoc import *\n", "from fastai.basics import *\n", "np.random.seed(42)"]}, {"block": 2, "type": "markdown", "linesLength": 15, "startIndex": 4, "lines": ["The data block API lets you customize the creation of a [`DataBunch`](/basic_data.html#DataBunch) by isolating the underlying parts of that process in separate blocks, mainly:\n", "  1. Where are the inputs and how to create them?\n", "  1. How to split the data into a training and validation sets?\n", "  1. How to label the inputs?\n", "  1. What transforms to apply?\n", "  1. How to add a test set?\n", "  1. How to wrap in dataloaders and create the [`DataBunch`](/basic_data.html#DataBunch)?\n", "  \n", "Each of these may be addressed with a specific block designed for your unique setup. Your inputs might be in a folder, a csv file, or a dataframe. You may want to split them randomly, by certain indices or depending on the folder they are in. You can have your labels in your csv file or your dataframe, but it may come from folders or a specific function of the input. You may choose to add data augmentation or not. A test set is optional too. Finally you have to set the arguments to put the data together in a [`DataBunch`](/basic_data.html#DataBunch) (batch size, collate function...)\n", "\n", "The data block API is called as such because you can mix and match each one of those blocks with the others, allowing for a total flexibility to create your customized [`DataBunch`](/basic_data.html#DataBunch) for training, validation and testing. The factory methods of the various [`DataBunch`](/basic_data.html#DataBunch) are great for beginners but you can't always make your data fit in the tracks they require.\n", "\n", "<img src=\"imgs/mix_match.png\" alt=\"Mix and match\" width=\"200\">\n", "\n", "As usual, we'll begin with end-to-end examples, then switch to the details of each of those parts."]}, {"block": 3, "type": "markdown", "linesLength": 1, "startIndex": 19, "lines": ["## Examples of use"]}, {"block": 4, "type": "markdown", "linesLength": 1, "startIndex": 20, "lines": ["Let's begin with our traditional MNIST example."]}, {"block": 5, "type": "code", "linesLength": 1, "startIndex": 21, "lines": ["from fastai.vision import *"]}, {"block": 6, "type": "code", "linesLength": 3, "startIndex": 22, "lines": ["path = untar_data(URLs.MNIST_TINY)\n", "tfms = get_transforms(do_flip=False)\n", "path.ls()"]}, {"block": 7, "type": "code", "linesLength": 1, "startIndex": 25, "lines": ["(path/'train').ls()"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 26, "lines": ["In [`vision.data`](/vision.data.html#vision.data), we can create a [`DataBunch`](/basic_data.html#DataBunch) suitable for image classification by simply typing:"]}, {"block": 9, "type": "code", "linesLength": 1, "startIndex": 27, "lines": ["data = ImageDataBunch.from_folder(path, ds_tfms=tfms, size=64)"]}, {"block": 10, "type": "markdown", "linesLength": 3, "startIndex": 28, "lines": ["This is a shortcut method which is aimed at data that is in folders following an ImageNet style, with the [`train`](/train.html#train) and `valid` directories, each containing one subdirectory per class, where all the labelled pictures are. There is also a `test` directory containing unlabelled pictures. \n", "\n", "Here is the same code, but this time using the data block API, which can work with any style of a dataset. All the stages, which will be explained below, can be grouped together like this:"]}, {"block": 11, "type": "code", "linesLength": 6, "startIndex": 31, "lines": ["data = (ImageList.from_folder(path) #Where to find the data? -> in path and its subfolders\n", "        .split_by_folder()              #How to split in train/valid? -> use the folders\n", "        .label_from_folder()            #How to label? -> depending on the folder of the filenames\n", "        .add_test_folder()              #Optionally add a test set (here default name is test)\n", "        .transform(tfms, size=64)       #Data augmentation? -> use tfms with a size of 64\n", "        .databunch())                   #Finally? -> use the defaults for conversion to ImageDataBunch"]}, {"block": 12, "type": "markdown", "linesLength": 1, "startIndex": 37, "lines": ["Now we can look at the created DataBunch:"]}, {"block": 13, "type": "code", "linesLength": 1, "startIndex": 38, "lines": ["data.show_batch(3, figsize=(6,6), hide_axis=False)"]}, {"block": 14, "type": "markdown", "linesLength": 1, "startIndex": 39, "lines": ["Let's look at another example from [`vision.data`](/vision.data.html#vision.data) with the planet dataset. This time, it's a multiclassification problem with the labels in a csv file and no given split between valid and train data, so we use a random split. The factory method is:"]}, {"block": 15, "type": "code", "linesLength": 2, "startIndex": 40, "lines": ["planet = untar_data(URLs.PLANET_TINY)\n", "planet_tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)"]}, {"block": 16, "type": "code", "linesLength": 1, "startIndex": 42, "lines": ["pd.read_csv(planet/\"labels.csv\").head()"]}, {"block": 17, "type": "code", "linesLength": 1, "startIndex": 43, "lines": ["data = ImageDataBunch.from_csv(planet, folder='train', size=128, suffix='.jpg', label_delim = ' ', ds_tfms=planet_tfms)"]}, {"block": 18, "type": "markdown", "linesLength": 1, "startIndex": 44, "lines": ["With the data block API we can rewrite this like that:"]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 45, "lines": ["planet.ls()"]}, {"block": 20, "type": "code", "linesLength": 1, "startIndex": 46, "lines": ["pd.read_csv(planet/\"labels.csv\").head()"]}, {"block": 21, "type": "code", "linesLength": 10, "startIndex": 47, "lines": ["data = (ImageList.from_csv(planet, 'labels.csv', folder='train', suffix='.jpg')\n", "        #Where to find the data? -> in planet 'train' folder\n", "        .split_by_rand_pct()\n", "        #How to split in train/valid? -> randomly with the default 20% in valid\n", "        .label_from_df(label_delim=' ')\n", "        #How to label? -> use the second column of the csv file and split the tags by ' '\n", "        .transform(planet_tfms, size=128)\n", "        #Data augmentation? -> use tfms with a size of 128\n", "        .databunch())                          \n", "        #Finally -> use the defaults for conversion to databunch"]}, {"block": 22, "type": "code", "linesLength": 1, "startIndex": 57, "lines": ["data.show_batch(rows=2, figsize=(9,7))"]}, {"block": 23, "type": "markdown", "linesLength": 1, "startIndex": 58, "lines": ["The data block API also allows you to get your data together in problems for which there is no direct [`ImageDataBunch`](/vision.data.html#ImageDataBunch) factory method. For a segmentation task, for instance, we can use it to quickly get a [`DataBunch`](/basic_data.html#DataBunch). Let's take the example of the [camvid dataset](http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/). The images are in an 'images' folder and their corresponding mask is in a 'labels' folder."]}, {"block": 24, "type": "code", "linesLength": 3, "startIndex": 59, "lines": ["camvid = untar_data(URLs.CAMVID_TINY)\n", "path_lbl = camvid/'labels'\n", "path_img = camvid/'images'"]}, {"block": 25, "type": "markdown", "linesLength": 1, "startIndex": 62, "lines": ["We have a file that gives us the names of the classes (what each code inside the masks corresponds to: a pedestrian, a tree, a road...)"]}, {"block": 26, "type": "code", "linesLength": 1, "startIndex": 63, "lines": ["codes = np.loadtxt(camvid/'codes.txt', dtype=str); codes"]}, {"block": 27, "type": "markdown", "linesLength": 1, "startIndex": 64, "lines": ["And we define the following function that infers the mask filename from the image filename."]}, {"block": 28, "type": "code", "linesLength": 1, "startIndex": 65, "lines": ["get_y_fn = lambda x: path_lbl/f'{x.stem}_P{x.suffix}'"]}, {"block": 29, "type": "markdown", "linesLength": 1, "startIndex": 66, "lines": ["Then we can easily define a [`DataBunch`](/basic_data.html#DataBunch) using the data block API. Here we need to use `tfm_y=True` in the transform call because we need the same transforms to be applied to the target mask as were applied to the image. Side note: For further control over which transformations are used on the target, each transformation has a `use_on_y` parameter"]}, {"block": 30, "type": "code", "linesLength": 10, "startIndex": 67, "lines": ["data = (SegmentationItemList.from_folder(path_img)\n", "        #Where to find the data? -> in path_img and its subfolders\n", "        .split_by_rand_pct()\n", "        #How to split in train/valid? -> randomly with the default 20% in valid\n", "        .label_from_func(get_y_fn, classes=codes)\n", "        #How to label? -> use the label function on the file name of the data\n", "        .transform(get_transforms(), tfm_y=True, size=128)\n", "        #Data augmentation? -> use tfms with a size of 128, also transform the label images\n", "        .databunch())\n", "        #Finally -> use the defaults for conversion to databunch"]}, {"block": 31, "type": "code", "linesLength": 1, "startIndex": 77, "lines": ["data.show_batch(rows=2, figsize=(7,5))"]}, {"block": 32, "type": "markdown", "linesLength": 1, "startIndex": 78, "lines": ["Another example for object detection. We use our tiny sample of the [COCO dataset](http://cocodataset.org/#home) here. There is a helper function in the library that reads the annotation file and returns the list of images names with the list of labelled bboxes associated to it. We convert it to a dictionary that maps image names with their bboxes and then write the function that will give us the target for each image filename."]}, {"block": 33, "type": "code", "linesLength": 4, "startIndex": 79, "lines": ["coco = untar_data(URLs.COCO_TINY)\n", "images, lbl_bbox = get_annotations(coco/'train.json')\n", "img2bbox = dict(zip(images, lbl_bbox))\n", "get_y_func = lambda o:img2bbox[o.name]"]}, {"block": 34, "type": "markdown", "linesLength": 1, "startIndex": 83, "lines": ["The following code is very similar to what we saw before. The only new addition is the use of a special function to collate the samples in batches. This comes from the fact that our images may have multiple bounding boxes, so we need to pad them to the largest number of bounding boxes."]}, {"block": 35, "type": "code", "linesLength": 11, "startIndex": 84, "lines": ["data = (ObjectItemList.from_folder(coco)\n", "        #Where are the images? -> in coco and its subfolders\n", "        .split_by_rand_pct()                          \n", "        #How to split in train/valid? -> randomly with the default 20% in valid\n", "        .label_from_func(get_y_func)\n", "        #How to find the labels? -> use get_y_func on the file name of the data\n", "        .transform(get_transforms(), tfm_y=True)\n", "        #Data augmentation? -> Standard transforms; also transform the label images\n", "        .databunch(bs=16, collate_fn=bb_pad_collate))   \n", "        #Finally we convert to a DataBunch, use a batch size of 16,\n", "        # and we use bb_pad_collate to collate the data into a mini-batch"]}, {"block": 36, "type": "code", "linesLength": 1, "startIndex": 95, "lines": ["data.show_batch(rows=2, ds_type=DatasetType.Valid, figsize=(6,6))"]}, {"block": 37, "type": "markdown", "linesLength": 1, "startIndex": 96, "lines": ["But vision isn't the only application where the data block API works. It can also be used for text and tabular data. With our sample of the IMDB dataset (labelled texts in a csv file), here is how to get the data together for a language model."]}, {"block": 38, "type": "code", "linesLength": 1, "startIndex": 97, "lines": ["from fastai.text import *"]}, {"block": 39, "type": "code", "linesLength": 1, "startIndex": 98, "lines": ["imdb = untar_data(URLs.IMDB_SAMPLE)"]}, {"block": 40, "type": "code", "linesLength": 9, "startIndex": 99, "lines": ["data_lm = (TextList\n", "           .from_csv(imdb, 'texts.csv', cols='text')\n", "           #Where are the text? Column 'text' of texts.csv\n", "           .split_by_rand_pct()\n", "           #How to split it? Randomly with the default 20% in valid\n", "           .label_for_lm()\n", "           #Label it for a language model\n", "           .databunch())\n", "           #Finally we convert to a DataBunch"]}, {"block": 41, "type": "code", "linesLength": 1, "startIndex": 108, "lines": ["data_lm.show_batch()"]}, {"block": 42, "type": "markdown", "linesLength": 1, "startIndex": 109, "lines": ["For a classification problem, we just have to change the way labeling is done. Here we use the csv column `label`."]}, {"block": 43, "type": "code", "linesLength": 4, "startIndex": 110, "lines": ["data_clas = (TextList.from_csv(imdb, 'texts.csv', cols='text')\n", "                   .split_from_df(col='is_valid')\n", "                   .label_from_df(cols='label')\n", "                   .databunch())"]}, {"block": 44, "type": "code", "linesLength": 1, "startIndex": 114, "lines": ["data_clas.show_batch()"]}, {"block": 45, "type": "markdown", "linesLength": 1, "startIndex": 115, "lines": ["Lastly, for tabular data, we just have to pass the name of our categorical and continuous variables as an extra argument. We also add some [`PreProcessor`](/data_block.html#PreProcessor)s that are going to be applied to our data once the splitting and labelling is done."]}, {"block": 46, "type": "code", "linesLength": 1, "startIndex": 116, "lines": ["from fastai.tabular import *"]}, {"block": 47, "type": "code", "linesLength": 6, "startIndex": 117, "lines": ["adult = untar_data(URLs.ADULT_SAMPLE)\n", "df = pd.read_csv(adult/'adult.csv')\n", "dep_var = 'salary'\n", "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n", "cont_names = ['education-num', 'hours-per-week', 'age', 'capital-loss', 'fnlwgt', 'capital-gain']\n", "procs = [FillMissing, Categorify, Normalize]"]}, {"block": 48, "type": "code", "linesLength": 4, "startIndex": 123, "lines": ["data = (TabularList.from_df(df, path=adult, cat_names=cat_names, cont_names=cont_names, procs=procs)\n", "                           .split_by_idx(valid_idx=range(800,1000))\n", "                           .label_from_df(cols=dep_var)\n", "                           .databunch())"]}, {"block": 49, "type": "code", "linesLength": 1, "startIndex": 127, "lines": ["data.show_batch()"]}, {"block": 50, "type": "markdown", "linesLength": 1, "startIndex": 128, "lines": ["## Step 1: Provide inputs"]}, {"block": 51, "type": "markdown", "linesLength": 1, "startIndex": 129, "lines": ["The basic class to get your inputs into is the following one. It's also the same class that will contain all of your labels (hence the name [`ItemList`](/data_block.html#ItemList))."]}, {"block": 52, "type": "code", "linesLength": 1, "startIndex": 130, "lines": ["show_doc(ItemList, title_level=3)"]}, {"block": 53, "type": "markdown", "linesLength": 1, "startIndex": 131, "lines": ["This class regroups the inputs for our model in `items` and saves a `path` attribute which is where it will look for any files (image files, csv file with labels...). `label_cls` will be called to create the labels from the result of the label function, `inner_df` is an underlying dataframe, and `processor` is to be applied to the inputs after the splitting and labeling."]}, {"block": 54, "type": "markdown", "linesLength": 15, "startIndex": 132, "lines": ["It has multiple subclasses depending on the type of data you're handling. Here is a quick list:\n", "  - [`CategoryList`](/data_block.html#CategoryList) for labels in classification\n", "  - [`MultiCategoryList`](/data_block.html#MultiCategoryList) for labels in a multi classification problem\n", "  - [`FloatList`](/data_block.html#FloatList) for float labels in a regression problem\n", "  - [`ImageList`](/vision.data.html#ImageList) for data that are images\n", "  - [`SegmentationItemList`](/vision.data.html#SegmentationItemList) like [`ImageList`](/vision.data.html#ImageList) but will default labels to [`SegmentationLabelList`](/vision.data.html#SegmentationLabelList)\n", "  - [`SegmentationLabelList`](/vision.data.html#SegmentationLabelList) for segmentation masks\n", "  - [`ObjectItemList`](/vision.data.html#ObjectItemList) like [`ImageList`](/vision.data.html#ImageList) but will default labels to `ObjectLabelList`\n", "  - `ObjectLabelList` for object detection\n", "  - [`PointsItemList`](/vision.data.html#PointsItemList) for points (of the type [`ImagePoints`](/vision.image.html#ImagePoints))\n", "  - [`ImageImageList`](/vision.data.html#ImageImageList) for image to image tasks\n", "  - [`TextList`](/text.data.html#TextList) for text data\n", "  - [`TextList`](/text.data.html#TextList) for text data stored in files\n", "  - [`TabularList`](/tabular.data.html#TabularList) for tabular data\n", "  - [`CollabList`](/collab.html#CollabList) for collaborative filtering"]}, {"block": 55, "type": "markdown", "linesLength": 1, "startIndex": 147, "lines": ["We can get a little glimpse of how [`ItemList`](/data_block.html#ItemList)'s basic attributes and methods behave with the following code examples."]}, {"block": 56, "type": "code", "linesLength": 4, "startIndex": 148, "lines": ["from fastai.vision import *\n", "path_data = untar_data(URLs.MNIST_TINY)\n", "il_data = ItemList.from_folder(path_data, extensions=['.csv'])\n", "il_data"]}, {"block": 57, "type": "markdown", "linesLength": 1, "startIndex": 152, "lines": ["Here is how to access the path of [`ItemList`](/data_block.html#ItemList) and the actual `items` (here files) in the path."]}, {"block": 58, "type": "code", "linesLength": 1, "startIndex": 153, "lines": ["il_data.path"]}, {"block": 59, "type": "code", "linesLength": 1, "startIndex": 154, "lines": ["il_data.items"]}, {"block": 60, "type": "markdown", "linesLength": 1, "startIndex": 155, "lines": ["`len(il_data)` gives you the count of files inside `il_data` and you can access individual items using index. "]}, {"block": 61, "type": "code", "linesLength": 1, "startIndex": 156, "lines": ["len(il_data)"]}, {"block": 62, "type": "markdown", "linesLength": 1, "startIndex": 157, "lines": ["`ItemList` returns a single item with a single index, but returns an `ItemList` if given a list of indexes."]}, {"block": 63, "type": "code", "linesLength": 1, "startIndex": 158, "lines": ["il_data[1]"]}, {"block": 64, "type": "code", "linesLength": 1, "startIndex": 159, "lines": ["il_data[:1]"]}, {"block": 65, "type": "markdown", "linesLength": 1, "startIndex": 160, "lines": ["With `il_data.add` we can perform in_place concatenate another [`ItemList`](/data_block.html#ItemList) object."]}, {"block": 66, "type": "code", "linesLength": 1, "startIndex": 161, "lines": ["il_data.add(il_data); il_data"]}, {"block": 67, "type": "code", "linesLength": 1, "startIndex": 162, "lines": ["from fastai.vision import *"]}, {"block": 68, "type": "code", "linesLength": 1, "startIndex": 163, "lines": ["path_data = untar_data(URLs.MNIST_TINY); path_data.ls()"]}, {"block": 69, "type": "code", "linesLength": 2, "startIndex": 164, "lines": ["itemlist = ItemList.from_folder(path_data/'test')\n", "itemlist"]}, {"block": 70, "type": "markdown", "linesLength": 3, "startIndex": 166, "lines": ["How does such output above is generated?\n", "\n", "behind the scenes, executing `itemlist` calls `ItemList.__repr__` which basically prints out `itemlist[0]` to `itemlist[4]`"]}, {"block": 71, "type": "code", "linesLength": 1, "startIndex": 169, "lines": ["itemlist[0]"]}, {"block": 72, "type": "markdown", "linesLength": 1, "startIndex": 170, "lines": ["and `itemlist[0]` basically calls `itemlist.get(0)` which returns `itemlist.items[0]`. That's why we have outputs like above."]}, {"block": 73, "type": "code", "linesLength": 0, "startIndex": 171, "lines": []}, {"block": 74, "type": "markdown", "linesLength": 1, "startIndex": 171, "lines": ["Once you have selected the class that is suitable, you can instantiate it with one of the following factory methods"]}, {"block": 75, "type": "code", "linesLength": 1, "startIndex": 172, "lines": ["show_doc(ItemList.from_folder)"]}, {"block": 76, "type": "code", "linesLength": 2, "startIndex": 173, "lines": ["path = untar_data(URLs.MNIST_TINY)\n", "path.ls()"]}, {"block": 77, "type": "code", "linesLength": 1, "startIndex": 175, "lines": ["ImageList.from_folder(path)"]}, {"block": 78, "type": "markdown", "linesLength": 3, "startIndex": 176, "lines": ["`path` is your root data folder. In the `path` directory you have _train_ and _valid_ folders which would contain your images. For the below example, _train_ folder contains two folders/classes _cat_ and _dog_.\n", "\n", "<img src=\"imgs/from_folder.png\" alt=\"from_folder\">"]}, {"block": 79, "type": "code", "linesLength": 1, "startIndex": 179, "lines": ["show_doc(ItemList.from_df)"]}, {"block": 80, "type": "markdown", "linesLength": 5, "startIndex": 180, "lines": ["Dataframe has 2 columns. The first column is the path to the image and the second column contains label id for that image. In case you have multi-labels (i.e more than one label for a single image), you will have a space(as determined by `label_delim` argument of `label_from_df`) seperated string in the labels column.\n", "\n", "`from_df` and `from_csv` can be used in a more general way. In cases you are not able to figure out how to get your ImageList, it is very easy to make a csv file with the above format.\n", "\n", "How to set `path`? `path` refers to your root data directory. So the paths in your csv file should be relative to `path` and not absolute paths. In the below example, in _labels.csv_ the paths to the images are __path + train/3/7463.png__"]}, {"block": 81, "type": "code", "linesLength": 2, "startIndex": 185, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "path.ls()"]}, {"block": 82, "type": "code", "linesLength": 2, "startIndex": 187, "lines": ["df = pd.read_csv(path/'labels.csv')\n", "df.head()"]}, {"block": 83, "type": "code", "linesLength": 1, "startIndex": 189, "lines": ["ImageList.from_df(df, path)"]}, {"block": 84, "type": "code", "linesLength": 1, "startIndex": 190, "lines": ["show_doc(ItemList.from_csv)"]}, {"block": 85, "type": "code", "linesLength": 2, "startIndex": 191, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "path.ls()"]}, {"block": 86, "type": "code", "linesLength": 1, "startIndex": 193, "lines": ["ImageList.from_csv(path, 'labels.csv')"]}, {"block": 87, "type": "markdown", "linesLength": 1, "startIndex": 194, "lines": ["### Optional step: filter your data"]}, {"block": 88, "type": "markdown", "linesLength": 1, "startIndex": 195, "lines": ["The factory method may have grabbed too many items. For instance, if you were searching sub folders with the `from_folder` method, you may have gotten files you don't want. To remove those, you can use one of the following methods."]}, {"block": 89, "type": "code", "linesLength": 1, "startIndex": 196, "lines": ["show_doc(ItemList.filter_by_func)"]}, {"block": 90, "type": "code", "linesLength": 3, "startIndex": 197, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "df = pd.read_csv(path/'labels.csv')\n", "df.head()"]}, {"block": 91, "type": "markdown", "linesLength": 1, "startIndex": 200, "lines": ["Suppose that you only want to keep images with a suffix \".png\". Well, this method will do magic for you."]}, {"block": 92, "type": "code", "linesLength": 1, "startIndex": 201, "lines": ["Path(df.name[0]).suffix"]}, {"block": 93, "type": "code", "linesLength": 1, "startIndex": 202, "lines": ["ImageList.from_df(df, path).filter_by_func(lambda fname: Path(fname).suffix == '.png')"]}, {"block": 94, "type": "code", "linesLength": 1, "startIndex": 203, "lines": ["show_doc(ItemList.filter_by_folder)"]}, {"block": 95, "type": "code", "linesLength": 1, "startIndex": 204, "lines": ["show_doc(ItemList.filter_by_rand)"]}, {"block": 96, "type": "code", "linesLength": 2, "startIndex": 205, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "ImageList.from_folder(path).filter_by_rand(0.5)"]}, {"block": 97, "type": "markdown", "linesLength": 1, "startIndex": 207, "lines": ["Contrast the number of items with the list created without the filter."]}, {"block": 98, "type": "code", "linesLength": 1, "startIndex": 208, "lines": ["ImageList.from_folder(path)"]}, {"block": 99, "type": "code", "linesLength": 1, "startIndex": 209, "lines": ["show_doc(ItemList.to_text)"]}, {"block": 100, "type": "code", "linesLength": 2, "startIndex": 210, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "pd.read_csv(path/'labels.csv').head()"]}, {"block": 101, "type": "code", "linesLength": 2, "startIndex": 212, "lines": ["file_name = \"item_list.txt\"\n", "ImageList.from_folder(path).to_text(file_name)"]}, {"block": 102, "type": "code", "linesLength": 1, "startIndex": 214, "lines": ["! cat {path/file_name} | head"]}, {"block": 103, "type": "code", "linesLength": 1, "startIndex": 215, "lines": ["show_doc(ItemList.use_partial_data)"]}, {"block": 104, "type": "code", "linesLength": 2, "startIndex": 216, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "ImageList.from_folder(path).use_partial_data(0.5)"]}, {"block": 105, "type": "markdown", "linesLength": 1, "startIndex": 218, "lines": ["Contrast the number of items with the list created without the filter."]}, {"block": 106, "type": "code", "linesLength": 1, "startIndex": 219, "lines": ["ImageList.from_folder(path)"]}, {"block": 107, "type": "markdown", "linesLength": 1, "startIndex": 220, "lines": ["### Writing your own [`ItemList`](/data_block.html#ItemList)"]}, {"block": 108, "type": "markdown", "linesLength": 7, "startIndex": 221, "lines": ["First check if you can't easily customize one of the existing subclass by:\n", "- subclassing an existing one and replacing the `get` method (or the `open` method if you're dealing with images)\n", "- applying a custom `processor` (see step 4)\n", "- changing the default `label_cls` for the label creation\n", "- adding a default [`PreProcessor`](/data_block.html#PreProcessor) with the `_processor` class variable\n", "\n", "If this isn't the case and you really need to write your own class, there is a [full tutorial](/tutorial.itemlist) that explains how to proceed."]}, {"block": 109, "type": "code", "linesLength": 1, "startIndex": 228, "lines": ["show_doc(ItemList.analyze_pred)"]}, {"block": 110, "type": "code", "linesLength": 1, "startIndex": 229, "lines": ["show_doc(ItemList.get)"]}, {"block": 111, "type": "markdown", "linesLength": 1, "startIndex": 230, "lines": ["We will have a glimpse of how `get` work with the following demo. "]}, {"block": 112, "type": "code", "linesLength": 1, "startIndex": 231, "lines": ["from fastai.vision import *"]}, {"block": 113, "type": "code", "linesLength": 1, "startIndex": 232, "lines": ["path_data = untar_data(URLs.MNIST_TINY); path_data.ls()"]}, {"block": 114, "type": "code", "linesLength": 2, "startIndex": 233, "lines": ["il_data_base = ItemList.from_folder(path=path_data, extensions=['.png'], include=['test'])\n", "il_data_base"]}, {"block": 115, "type": "markdown", "linesLength": 1, "startIndex": 235, "lines": ["`get` is used inexplicitly within `il_data_base[15]`. `il_data_base.get(15)` gives the same result here, because its defulat it's to return that."]}, {"block": 116, "type": "code", "linesLength": 1, "startIndex": 236, "lines": ["il_data_base[15]"]}, {"block": 117, "type": "markdown", "linesLength": 1, "startIndex": 237, "lines": ["While creating your custom [`ItemList`](/data_block.html#ItemList) however, you can override this function to do some things to your item (like opening an image)."]}, {"block": 118, "type": "code", "linesLength": 2, "startIndex": 238, "lines": ["il_data_image = ImageList.from_folder(path=path_data, extensions=['.png'], include=['test'])\n", "il_data_image"]}, {"block": 119, "type": "markdown", "linesLength": 1, "startIndex": 240, "lines": ["Again, normally `get` is used inexplicitly within `il_data_image[15]`."]}, {"block": 120, "type": "code", "linesLength": 1, "startIndex": 241, "lines": ["il_data_image[15]"]}, {"block": 121, "type": "markdown", "linesLength": 1, "startIndex": 242, "lines": ["The reason why an image is printed out instead of a FilePath object, is [`ImageList.get`](/vision.data.html#ImageList.get) overwrites [`ItemList.get`](/data_block.html#ItemList.get) and use [`ImageList.open`](/vision.data.html#ImageList.open) to print an image."]}, {"block": 122, "type": "code", "linesLength": 1, "startIndex": 243, "lines": ["show_doc(ItemList.new)"]}, {"block": 123, "type": "markdown", "linesLength": 1, "startIndex": 244, "lines": ["You'll never need to subclass this normally, just don't forget to add to `self.copy_new` the names of the arguments that needs to be copied each time `new` is called in `__init__`."]}, {"block": 124, "type": "markdown", "linesLength": 1, "startIndex": 245, "lines": ["We will get a feel of how `new` works with the following examples."]}, {"block": 125, "type": "code", "linesLength": 1, "startIndex": 246, "lines": ["from fastai.vision import *"]}, {"block": 126, "type": "code", "linesLength": 1, "startIndex": 247, "lines": ["path_data = untar_data(URLs.MNIST_TINY); path_data.ls()"]}, {"block": 127, "type": "code", "linesLength": 2, "startIndex": 248, "lines": ["itemlist1 = ItemList.from_folder(path=path_data/'valid', extensions=['.png'])\n", "itemlist1"]}, {"block": 128, "type": "markdown", "linesLength": 1, "startIndex": 250, "lines": ["As you will see below, `copy_new` allows use to borrow any argument and its value from `itemlist1`, and `itemlist1.new(itemlist1.items)` allows us to use `items` and arguments inside `copy_new` to create another [`ItemList`](/data_block.html#ItemList) by calling [`ItemList.__init__`](/data_block.html#ItemList.__init__)."]}, {"block": 129, "type": "code", "linesLength": 1, "startIndex": 251, "lines": ["itemlist1.copy_new == ['x', 'label_cls', 'path']"]}, {"block": 130, "type": "code", "linesLength": 2, "startIndex": 252, "lines": ["((itemlist1.x == itemlist1.label_cls == itemlist1.inner_df == None) \n", " and (itemlist1.path == Path('/Users/Natsume/.fastai/data/mnist_tiny/valid')))\n"]}, {"block": 131, "type": "markdown", "linesLength": 1, "startIndex": 254, "lines": ["You can select any argument from [`ItemList.__init__`](/data_block.html#ItemList.__init__)'s signature and change their values. "]}, {"block": 132, "type": "code", "linesLength": 3, "startIndex": 255, "lines": ["itemlist1.copy_new = ['x', 'label_cls', 'path', 'inner_df']\n", "itemlist1.x = itemlist1.label_cls = itemlist1.path = itemlist1.inner_df = 'test'\n", "itemlist2 = itemlist1.new(items=itemlist1.items)"]}, {"block": 133, "type": "code", "linesLength": 2, "startIndex": 258, "lines": ["(itemlist2.inner_df == itemlist2.x == itemlist2.label_cls == 'test' \n", " and itemlist2.path == Path('test'))"]}, {"block": 134, "type": "code", "linesLength": 1, "startIndex": 260, "lines": ["show_doc(ItemList.reconstruct)"]}, {"block": 135, "type": "markdown", "linesLength": 1, "startIndex": 261, "lines": ["## Step 2: Split the data between the training and the validation set"]}, {"block": 136, "type": "markdown", "linesLength": 1, "startIndex": 262, "lines": ["This step is normally straightforward, you just have to pick oe of the following functions depending on what you need."]}, {"block": 137, "type": "code", "linesLength": 1, "startIndex": 263, "lines": ["show_doc(ItemList.split_none)"]}, {"block": 138, "type": "code", "linesLength": 1, "startIndex": 264, "lines": ["show_doc(ItemList.split_by_rand_pct)"]}, {"block": 139, "type": "code", "linesLength": 1, "startIndex": 265, "lines": ["show_doc(ItemList.split_subsets)"]}, {"block": 140, "type": "markdown", "linesLength": 1, "startIndex": 266, "lines": ["This function is handy if you want to work with subsets of specific sizes, e.g., you want to use 20% of the data for the validation dataset, but you only want to train on a small subset of the rest of the data: `split_subsets(train_size=0.08, valid_size=0.2)`."]}, {"block": 141, "type": "code", "linesLength": 1, "startIndex": 267, "lines": ["show_doc(ItemList.split_by_files)"]}, {"block": 142, "type": "markdown", "linesLength": 3, "startIndex": 268, "lines": ["Let's try this functions for cifar-10. In every folder, we have our image files that are named as 0001.png, 0002.png. So we have 10 images of 0001.png (one for each class) in the train folder. `valid_names` can be a list containing names of your images that you want to place in your validation set. \n", "\n", "__Note__ :- Here in `valid_names` you need to specify the image name and not the image path. So for `/path/to/image.png`, we only need to add `image.png` in our valid_names. "]}, {"block": 143, "type": "code", "linesLength": 2, "startIndex": 271, "lines": ["path = untar_data(URLs.CIFAR)\n", "path.ls()"]}, {"block": 144, "type": "code", "linesLength": 3, "startIndex": 273, "lines": ["data = (ImageList.from_folder(path)\n", "                 .split_by_files(valid_names=['0001.png', '0002.png']))\n", "data"]}, {"block": 145, "type": "markdown", "linesLength": 1, "startIndex": 276, "lines": ["In the Valid we can see 40 images (20 images of 0001.png, 20 images of 0002.png from both train and valid folders)"]}, {"block": 146, "type": "code", "linesLength": 1, "startIndex": 277, "lines": ["show_doc(ItemList.split_by_fname_file)"]}, {"block": 147, "type": "markdown", "linesLength": 1, "startIndex": 278, "lines": ["Internally makes a call to `split_by_files`. `fname` contains your image file names like 0001.png."]}, {"block": 148, "type": "code", "linesLength": 1, "startIndex": 279, "lines": ["show_doc(ItemList.split_by_folder)"]}, {"block": 149, "type": "code", "linesLength": 1, "startIndex": 280, "lines": ["jekyll_note(\"This method looks at the folder immediately after `self.path` for `valid` and `train`.\")"]}, {"block": 150, "type": "markdown", "linesLength": 1, "startIndex": 281, "lines": ["In other words, `split_by_folder` splits a large `ItemList` (or any of `ItemList`'s subclass) object created with data from a main folder, into two `ItemList` objects corresponding to data of two subfolders."]}, {"block": 151, "type": "code", "linesLength": 1, "startIndex": 282, "lines": ["from fastai.vision import *"]}, {"block": 152, "type": "code", "linesLength": 1, "startIndex": 283, "lines": ["path_data = untar_data(URLs.MNIST_TINY); path_data.ls()"]}, {"block": 153, "type": "code", "linesLength": 1, "startIndex": 284, "lines": ["il = ItemList.from_folder(path=path_data); il"]}, {"block": 154, "type": "code", "linesLength": 1, "startIndex": 285, "lines": ["sd = il.split_by_folder(train='train', valid='valid'); sd"]}, {"block": 155, "type": "markdown", "linesLength": 1, "startIndex": 286, "lines": ["Behind the scenes `split_by_folder` utilizes `_get_by_folder(name)` creates a list of idxs for all the items of the large `ItemList` which are corresponding to data files of a subfolder named 'tranining' if set `name='training'`."]}, {"block": 156, "type": "code", "linesLength": 2, "startIndex": 287, "lines": ["idx_train = il._get_by_folder(name='train')\n", "idx_train[:5], idx_train[-5:], len(idx_train)"]}, {"block": 157, "type": "code", "linesLength": 2, "startIndex": 289, "lines": ["idx_valid = il._get_by_folder(name='valid') \n", "idx_valid[:5], idx_valid[-5:],len(idx_valid)"]}, {"block": 158, "type": "code", "linesLength": 1, "startIndex": 291, "lines": ["show_doc(ItemList.split_by_idx)"]}, {"block": 159, "type": "code", "linesLength": 3, "startIndex": 292, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "df = pd.read_csv(path/'labels.csv')\n", "df.head()"]}, {"block": 160, "type": "markdown", "linesLength": 1, "startIndex": 295, "lines": ["You can pass a list of indices that you want to put in the validation set like [1, 3, 10]. Or you can pass a contiguous list like `list(range(1000))`"]}, {"block": 161, "type": "code", "linesLength": 3, "startIndex": 296, "lines": ["data = (ImageList.from_df(df, path)\n", "                 .split_by_idx(list(range(1000))))\n", "data"]}, {"block": 162, "type": "code", "linesLength": 1, "startIndex": 299, "lines": ["show_doc(ItemList.split_by_idxs)"]}, {"block": 163, "type": "markdown", "linesLength": 1, "startIndex": 300, "lines": ["Behind the scenes, `split_by_idxs` uses a list of indexes assigned to the name `train_idx` and a list of indexes assigned to the name `valid_idx`, to split a large `ItemList` object into two `ItemList` objects attached to an `ItemLists` object."]}, {"block": 164, "type": "code", "linesLength": 1, "startIndex": 301, "lines": ["sd = il.split_by_idxs(train_idx=idx_train, valid_idx=idx_valid); sd"]}, {"block": 165, "type": "code", "linesLength": 1, "startIndex": 302, "lines": ["show_doc(ItemList.split_by_list)"]}, {"block": 166, "type": "markdown", "linesLength": 1, "startIndex": 303, "lines": ["In fact, `split_by_list` uses `_split` (behind the scene, it is `ItemLists.__init__`) to attach two `ItemList` objects or any of `ItemList`'s subclass objects to an `ItemLists` object."]}, {"block": 167, "type": "code", "linesLength": 1, "startIndex": 304, "lines": ["sd = il.split_by_list(train=il[idx_train], valid=il[idx_valid]); sd"]}, {"block": 168, "type": "markdown", "linesLength": 1, "startIndex": 305, "lines": ["This is more of an internal method, you should be using `split_by_files` if you want to pass a list of filenames for the validation set."]}, {"block": 169, "type": "code", "linesLength": 1, "startIndex": 306, "lines": ["show_doc(ItemList.split_by_valid_func)"]}, {"block": 170, "type": "code", "linesLength": 1, "startIndex": 307, "lines": ["show_doc(ItemList.split_from_df)"]}, {"block": 171, "type": "markdown", "linesLength": 1, "startIndex": 308, "lines": ["To use this function, you need a boolean column `is_valid`. If `is_valid[index] = True`, then that example is put in the validation set and if `is_valid[index] = False` the example is put in the training set."]}, {"block": 172, "type": "code", "linesLength": 10, "startIndex": 309, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "df = pd.read_csv(path/'labels.csv')\n", "\n", "# Create a new column for is_valid\n", "df['is_valid'] = [True]*(df.shape[0]//2) + [False]*(df.shape[0]//2)\n", "\n", "# Randomly shuffle dataframe\n", "df = df.reindex(np.random.permutation(df.index))\n", "print(df.shape)\n", "df.head()"]}, {"block": 173, "type": "code", "linesLength": 3, "startIndex": 319, "lines": ["data = (ImageList.from_df(df, path)\n", "                 .split_from_df())\n", "data"]}, {"block": 174, "type": "code", "linesLength": 1, "startIndex": 322, "lines": ["jekyll_warn(\"This method assumes the data has been created from a csv file or a dataframe.\")"]}, {"block": 175, "type": "markdown", "linesLength": 1, "startIndex": 323, "lines": ["## Step 3: Label the inputs"]}, {"block": 176, "type": "markdown", "linesLength": 1, "startIndex": 324, "lines": ["To label your inputs, use one of the following functions. Note that even if it's not in the documented arguments, you can always pass a `label_cls` that will be used to create those labels (the default is the one from your input [`ItemList`](/data_block.html#ItemList), and if there is none, it will go to [`CategoryList`](/data_block.html#CategoryList),  [`MultiCategoryList`](/data_block.html#MultiCategoryList) or [`FloatList`](/data_block.html#FloatList) depending on the type of the labels). This is implemented in the following function:"]}, {"block": 177, "type": "code", "linesLength": 1, "startIndex": 325, "lines": ["show_doc(ItemList.get_label_cls)"]}, {"block": 178, "type": "markdown", "linesLength": 1, "startIndex": 326, "lines": ["If no `label_cls` argument is passed, the correct labeling type can usually be inferred based on the data (for classification or regression). If you have multiple regression targets (e.g. predict 5 different numbers from a single image/text), be aware that arrays of floats are by default considered to be targets for one-hot encoded classification. If your task is regression, be sure the pass `label_cls = FloatList` so that learners created from your databunch initialize correctly."]}, {"block": 179, "type": "markdown", "linesLength": 1, "startIndex": 327, "lines": ["The first example in these docs created labels as follows:"]}, {"block": 180, "type": "code", "linesLength": 2, "startIndex": 328, "lines": ["path = untar_data(URLs.MNIST_TINY)\n", "ll = ImageList.from_folder(path).split_by_folder().label_from_folder().train"]}, {"block": 181, "type": "markdown", "linesLength": 7, "startIndex": 330, "lines": ["If you want to save the data necessary to recreate your [`LabelList`](/data_block.html#LabelList) (not including saving the actual image/text/etc files), you can use `to_df` or `to_csv`:\n", "\n", "```python\n", "ll.train.to_csv('tmp.csv')\n", "```\n", "\n", "Or just grab a `pd.DataFrame` directly:"]}, {"block": 182, "type": "code", "linesLength": 1, "startIndex": 337, "lines": ["ll.to_df().head()"]}, {"block": 183, "type": "code", "linesLength": 1, "startIndex": 338, "lines": ["show_doc(ItemList.label_empty)"]}, {"block": 184, "type": "code", "linesLength": 1, "startIndex": 339, "lines": ["show_doc(ItemList.label_from_df)"]}, {"block": 185, "type": "code", "linesLength": 1, "startIndex": 340, "lines": ["jekyll_warn(\"This method only works with data objects created with either `from_csv` or `from_df` methods.\")"]}, {"block": 186, "type": "code", "linesLength": 1, "startIndex": 341, "lines": ["show_doc(ItemList.label_const)"]}, {"block": 187, "type": "code", "linesLength": 1, "startIndex": 342, "lines": ["show_doc(ItemList.label_from_folder)"]}, {"block": 188, "type": "code", "linesLength": 1, "startIndex": 343, "lines": ["jekyll_note(\"This method looks at the last subfolder in the path to determine the classes.\")"]}, {"block": 189, "type": "code", "linesLength": 1, "startIndex": 344, "lines": ["show_doc(ItemList.label_from_func)"]}, {"block": 190, "type": "code", "linesLength": 1, "startIndex": 345, "lines": ["show_doc(ItemList.label_from_re)"]}, {"block": 191, "type": "code", "linesLength": 1, "startIndex": 346, "lines": ["show_doc(CategoryList, title_level=3)"]}, {"block": 192, "type": "markdown", "linesLength": 1, "startIndex": 347, "lines": ["[`ItemList`](/data_block.html#ItemList) suitable for storing labels in `items` belonging to `classes`. If `None` are passed, `classes` will be determined by the unique different labels. `processor` will default to [`CategoryProcessor`](/data_block.html#CategoryProcessor)."]}, {"block": 193, "type": "code", "linesLength": 1, "startIndex": 348, "lines": ["show_doc(MultiCategoryList, title_level=3)"]}, {"block": 194, "type": "markdown", "linesLength": 3, "startIndex": 349, "lines": ["It will store list of labels in `items` belonging to `classes`. If `None` are passed, `classes` will be determined by the unique different labels. `sep` is used to split the content of `items` in a list of tags.\n", "\n", "If `one_hot=True`, the items contain the labels one-hot encoded. In this case, it is mandatory to pass a list of `classes` (as we can't use the different labels)."]}, {"block": 195, "type": "code", "linesLength": 1, "startIndex": 352, "lines": ["show_doc(FloatList, title_level=3)"]}, {"block": 196, "type": "code", "linesLength": 1, "startIndex": 353, "lines": ["show_doc(EmptyLabelList, title_level=3)"]}, {"block": 197, "type": "markdown", "linesLength": 1, "startIndex": 354, "lines": ["## Invisible step: preprocessing"]}, {"block": 198, "type": "markdown", "linesLength": 7, "startIndex": 355, "lines": ["This isn't seen here in the API, but if you passed a `processor` (or a list of them) in your initial [`ItemList`](/data_block.html#ItemList) during step 1, it will be applied here. If you didn't pass any processor, a list of them might still be created depending on what is in the `_processor` variable of your class of items (this can be a list of [`PreProcessor`](/data_block.html#PreProcessor) classes).\n", "\n", "A processor is a transformation that is applied to all the inputs once at initialization, with a state computed on the training set that is then applied without modification on the validation set (and maybe the test set). For instance, it can be processing texts to tokenize then numericalize them. In that case we want the validation set to be numericalized with exactly the same vocabulary as the training set.\n", "\n", "Another example is in tabular data, where we fill missing values with (for instance) the median computed on the training set. That statistic is stored in the inner state of the [`PreProcessor`](/data_block.html#PreProcessor) and applied on the validation set.\n", "\n", "This is the generic class for all processors."]}, {"block": 199, "type": "code", "linesLength": 1, "startIndex": 362, "lines": ["show_doc(PreProcessor, title_level=3)"]}, {"block": 200, "type": "code", "linesLength": 1, "startIndex": 363, "lines": ["show_doc(PreProcessor.process_one)"]}, {"block": 201, "type": "markdown", "linesLength": 1, "startIndex": 364, "lines": ["Process one `item`. This method needs to be written in any subclass."]}, {"block": 202, "type": "code", "linesLength": 1, "startIndex": 365, "lines": ["show_doc(PreProcessor.process)"]}, {"block": 203, "type": "markdown", "linesLength": 1, "startIndex": 366, "lines": ["Process a dataset. This default to apply `process_one` on every `item` of `ds`."]}, {"block": 204, "type": "code", "linesLength": 1, "startIndex": 367, "lines": ["show_doc(CategoryProcessor, title_level=3)"]}, {"block": 205, "type": "code", "linesLength": 1, "startIndex": 368, "lines": ["show_doc(CategoryProcessor.generate_classes)"]}, {"block": 206, "type": "code", "linesLength": 1, "startIndex": 369, "lines": ["show_doc(MultiCategoryProcessor, title_level=3)"]}, {"block": 207, "type": "code", "linesLength": 1, "startIndex": 370, "lines": ["show_doc(MultiCategoryProcessor.generate_classes)"]}, {"block": 208, "type": "markdown", "linesLength": 1, "startIndex": 371, "lines": ["## Optional steps"]}, {"block": 209, "type": "markdown", "linesLength": 1, "startIndex": 372, "lines": ["### Add transforms"]}, {"block": 210, "type": "markdown", "linesLength": 1, "startIndex": 373, "lines": ["Transforms differ from processors in the sense they are applied on the fly when we grab one item. They also may change each time we ask for the same item in the case of random transforms."]}, {"block": 211, "type": "code", "linesLength": 1, "startIndex": 374, "lines": ["show_doc(LabelLists.transform)"]}, {"block": 212, "type": "markdown", "linesLength": 3, "startIndex": 375, "lines": ["This is primary for the vision application. The `kwargs` arguments are the ones expected by the type of transforms you pass. `tfm_y` is among them and if set to `True`, the transforms will be applied to input and target.\n", "\n", "For examples see: [vision.transforms](vision.transform.html)."]}, {"block": 213, "type": "markdown", "linesLength": 1, "startIndex": 378, "lines": ["### Add a test set"]}, {"block": 214, "type": "markdown", "linesLength": 1, "startIndex": 379, "lines": ["To add a test set, you can use one of the two following methods."]}, {"block": 215, "type": "code", "linesLength": 1, "startIndex": 380, "lines": ["show_doc(LabelLists.add_test)"]}, {"block": 216, "type": "code", "linesLength": 1, "startIndex": 381, "lines": ["jekyll_note(\"Here `items` can be an `ItemList` or a collection.\")"]}, {"block": 217, "type": "code", "linesLength": 1, "startIndex": 382, "lines": ["show_doc(LabelLists.add_test_folder)"]}, {"block": 218, "type": "code", "linesLength": 1, "startIndex": 383, "lines": ["jekyll_warn(\"In fastai the test set is unlabeled! No labels will be collected even if they are available.\")"]}, {"block": 219, "type": "markdown", "linesLength": 38, "startIndex": 384, "lines": ["Instead, either the passed `label` argument or an empty label will be used for all entries of this dataset (this is required by the internal pipeline of fastai). \n", "\n", "In the `fastai` framework `test` datasets have no labels - this is the unknown data to be predicted. If you want to validate your model on a `test` dataset with labels, you probably need to use it as a validation set, as in:\n", "\n", "```\n", "data_test = (ImageList.from_folder(path)\n", "        .split_by_folder(train='train', valid='test')\n", "        .label_from_folder()\n", "        ...)\n", "```\n", "\n", "Another approach, where you do use a normal validation set, and then when the training is over, you just want to validate the test set w/ labels as a validation set, you can do this:\n", "\n", "```\n", "tfms = []\n", "path = Path('data').resolve()\n", "data = (ImageList.from_folder(path)\n", "        .split_by_pct()\n", "        .label_from_folder()\n", "        .transform(tfms)\n", "        .databunch()\n", "        .normalize() ) \n", "learn = cnn_learner(data, models.resnet50, metrics=accuracy)\n", "learn.fit_one_cycle(5,1e-2)\n", "\n", "# now replace the validation dataset entry with the test dataset as a new validation dataset: \n", "# everything is exactly the same, except replacing `split_by_pct` w/ `split_by_folder` \n", "# (or perhaps you were already using the latter, so simply switch to valid='test')\n", "data_test = (ImageList.from_folder(path)\n", "        .split_by_folder(train='train', valid='test')\n", "        .label_from_folder()\n", "        .transform(tfms)\n", "        .databunch()\n", "        .normalize()\n", "       ) \n", "learn.validate(data_test.valid_dl)\n", "```\n", "Of course, your data block can be totally different, this is just an example."]}, {"block": 220, "type": "markdown", "linesLength": 1, "startIndex": 422, "lines": ["## Step 4: convert to a [`DataBunch`](/basic_data.html#DataBunch)"]}, {"block": 221, "type": "markdown", "linesLength": 1, "startIndex": 423, "lines": ["This last step is usually pretty straightforward. You just have to include all the arguments we pass to [`DataBunch.create`](/basic_data.html#DataBunch.create) (`bs`, `num_workers`,  `collate_fn`). The class called to create a [`DataBunch`](/basic_data.html#DataBunch) is set in the `_bunch` attribute of the inputs of the training set if you need to modify it. Normally, the various subclasses we showed before handle that for you."]}, {"block": 222, "type": "code", "linesLength": 1, "startIndex": 424, "lines": ["show_doc(LabelLists.databunch)"]}, {"block": 223, "type": "markdown", "linesLength": 1, "startIndex": 425, "lines": ["## Inner classes"]}, {"block": 224, "type": "code", "linesLength": 1, "startIndex": 426, "lines": ["show_doc(LabelList, title_level=3)"]}, {"block": 225, "type": "markdown", "linesLength": 1, "startIndex": 427, "lines": ["Optionally apply `tfms` to `y` if `tfm_y` is `True`. "]}, {"block": 226, "type": "code", "linesLength": 1, "startIndex": 428, "lines": ["show_doc(LabelList.export)"]}, {"block": 227, "type": "code", "linesLength": 1, "startIndex": 429, "lines": ["show_doc(LabelList.transform_y)"]}, {"block": 228, "type": "code", "linesLength": 1, "startIndex": 430, "lines": ["show_doc(LabelList.get_state)"]}, {"block": 229, "type": "code", "linesLength": 1, "startIndex": 431, "lines": ["show_doc(LabelList.load_empty)"]}, {"block": 230, "type": "code", "linesLength": 1, "startIndex": 432, "lines": ["show_doc(LabelList.load_state)"]}, {"block": 231, "type": "code", "linesLength": 1, "startIndex": 433, "lines": ["show_doc(LabelList.process)"]}, {"block": 232, "type": "code", "linesLength": 1, "startIndex": 434, "lines": ["show_doc(LabelList.set_item)"]}, {"block": 233, "type": "code", "linesLength": 1, "startIndex": 435, "lines": ["show_doc(LabelList.to_df)"]}, {"block": 234, "type": "code", "linesLength": 1, "startIndex": 436, "lines": ["show_doc(LabelList.to_csv)"]}, {"block": 235, "type": "code", "linesLength": 1, "startIndex": 437, "lines": ["show_doc(LabelList.transform)"]}, {"block": 236, "type": "code", "linesLength": 1, "startIndex": 438, "lines": ["show_doc(ItemLists, title_level=3)"]}, {"block": 237, "type": "code", "linesLength": 1, "startIndex": 439, "lines": ["show_doc(ItemLists.label_from_lists)"]}, {"block": 238, "type": "code", "linesLength": 1, "startIndex": 440, "lines": ["show_doc(ItemLists.transform)"]}, {"block": 239, "type": "code", "linesLength": 1, "startIndex": 441, "lines": ["show_doc(ItemLists.transform_y)"]}, {"block": 240, "type": "code", "linesLength": 1, "startIndex": 442, "lines": ["show_doc(LabelLists, title_level=3)"]}, {"block": 241, "type": "code", "linesLength": 1, "startIndex": 443, "lines": ["show_doc(LabelLists.get_processors)"]}, {"block": 242, "type": "code", "linesLength": 1, "startIndex": 444, "lines": ["show_doc(LabelLists.load_empty)"]}, {"block": 243, "type": "code", "linesLength": 1, "startIndex": 445, "lines": ["show_doc(LabelLists.load_state)"]}, {"block": 244, "type": "code", "linesLength": 1, "startIndex": 446, "lines": ["show_doc(LabelLists.process)"]}, {"block": 245, "type": "markdown", "linesLength": 1, "startIndex": 447, "lines": ["## Helper functions"]}, {"block": 246, "type": "code", "linesLength": 1, "startIndex": 448, "lines": ["show_doc(get_files)"]}, {"block": 247, "type": "markdown", "linesLength": 3, "startIndex": 449, "lines": ["To to more precise, this function returns list of FilePath objects using files in `path` that must have a suffix in `extensions`, and hidden folders and files are ignored. If `recurse=True`, all files in subfolders will be applied; `include` is used to select particular folders to apply.\n", "\n", "Inside [`get_files`](/data_block.html#get_files), there is [`_get_files`](/data_block.html#_get_files) which turns all filenames inside `f` from directory `parent/p` into a list of FilePath objects. All filenames must have a suffix in `extensions`. All hidden files are ignored."]}, {"block": 248, "type": "code", "linesLength": 1, "startIndex": 452, "lines": ["path_data = untar_data(URLs.MNIST_TINY) "]}, {"block": 249, "type": "code", "linesLength": 1, "startIndex": 453, "lines": ["path_data.ls()"]}, {"block": 250, "type": "markdown", "linesLength": 1, "startIndex": 454, "lines": ["With `recurse=False`, no subfolder files are made available."]}, {"block": 251, "type": "code", "linesLength": 2, "startIndex": 455, "lines": ["list_FilePath_noRecurse = get_files(path_data) \n", "list_FilePath_noRecurse"]}, {"block": 252, "type": "markdown", "linesLength": 1, "startIndex": 457, "lines": ["With `recurse=True`, all subfolder files are made available, except hidden files."]}, {"block": 253, "type": "code", "linesLength": 2, "startIndex": 458, "lines": ["list_FilePath_recurse = get_files(path_data, recurse=True)\n", "list_FilePath_recurse[:3]"]}, {"block": 254, "type": "code", "linesLength": 1, "startIndex": 460, "lines": ["list_FilePath_recurse[-2:]"]}, {"block": 255, "type": "markdown", "linesLength": 1, "startIndex": 461, "lines": ["With `extensions=['.csv']`, only files with the suffix of `.csv` are made available."]}, {"block": 256, "type": "code", "linesLength": 2, "startIndex": 462, "lines": ["list_FilePath_recurse_csv = get_files(path_data, recurse=True, extensions=['.csv'])\n", "list_FilePath_recurse_csv"]}, {"block": 257, "type": "markdown", "linesLength": 1, "startIndex": 464, "lines": ["With `include=['test']`, only files in `path_data` and its subfolder `test` are made available."]}, {"block": 258, "type": "code", "linesLength": 3, "startIndex": 465, "lines": ["list_FilePath_include = get_files(path_data, recurse=True, extensions=['.png','.jpg','.jpeg'],\n", "                                  include=['test'])\n", "list_FilePath_include[:3]"]}, {"block": 259, "type": "code", "linesLength": 1, "startIndex": 468, "lines": ["list_FilePath_include[-3:]"]}, {"block": 260, "type": "markdown", "linesLength": 1, "startIndex": 469, "lines": ["## Undocumented Methods - Methods moved below this line will intentionally be hidden"]}, {"block": 261, "type": "code", "linesLength": 1, "startIndex": 470, "lines": ["show_doc(CategoryList.new)"]}, {"block": 262, "type": "code", "linesLength": 1, "startIndex": 471, "lines": ["show_doc(LabelList.new)"]}, {"block": 263, "type": "code", "linesLength": 1, "startIndex": 472, "lines": ["show_doc(CategoryList.get)"]}, {"block": 264, "type": "code", "linesLength": 1, "startIndex": 473, "lines": ["show_doc(LabelList.predict)"]}, {"block": 265, "type": "code", "linesLength": 1, "startIndex": 474, "lines": ["show_doc(ItemList.new)"]}, {"block": 266, "type": "code", "linesLength": 1, "startIndex": 475, "lines": ["show_doc(ItemList.process_one)"]}, {"block": 267, "type": "code", "linesLength": 1, "startIndex": 476, "lines": ["show_doc(ItemList.process)"]}, {"block": 268, "type": "code", "linesLength": 1, "startIndex": 477, "lines": ["show_doc(MultiCategoryProcessor.process_one)"]}, {"block": 269, "type": "code", "linesLength": 1, "startIndex": 478, "lines": ["show_doc(FloatList.get)"]}, {"block": 270, "type": "code", "linesLength": 1, "startIndex": 479, "lines": ["show_doc(CategoryProcessor.process_one)"]}, {"block": 271, "type": "code", "linesLength": 1, "startIndex": 480, "lines": ["show_doc(CategoryProcessor.create_classes)"]}, {"block": 272, "type": "code", "linesLength": 1, "startIndex": 481, "lines": ["show_doc(CategoryProcessor.process)"]}, {"block": 273, "type": "code", "linesLength": 1, "startIndex": 482, "lines": ["show_doc(MultiCategoryList.get)"]}, {"block": 274, "type": "code", "linesLength": 1, "startIndex": 483, "lines": ["show_doc(FloatList.new)"]}, {"block": 275, "type": "code", "linesLength": 1, "startIndex": 484, "lines": ["show_doc(FloatList.reconstruct)"]}, {"block": 276, "type": "code", "linesLength": 1, "startIndex": 485, "lines": ["show_doc(MultiCategoryList.analyze_pred)"]}, {"block": 277, "type": "code", "linesLength": 1, "startIndex": 486, "lines": ["show_doc(MultiCategoryList.reconstruct)"]}, {"block": 278, "type": "code", "linesLength": 1, "startIndex": 487, "lines": ["show_doc(CategoryList.reconstruct)"]}, {"block": 279, "type": "code", "linesLength": 1, "startIndex": 488, "lines": ["show_doc(CategoryList.analyze_pred)"]}, {"block": 280, "type": "code", "linesLength": 1, "startIndex": 489, "lines": ["show_doc(EmptyLabelList.reconstruct)"]}, {"block": 281, "type": "code", "linesLength": 1, "startIndex": 490, "lines": ["show_doc(EmptyLabelList.get)"]}, {"block": 282, "type": "code", "linesLength": 1, "startIndex": 491, "lines": ["show_doc(LabelList.databunch)"]}, {"block": 283, "type": "markdown", "linesLength": 1, "startIndex": 492, "lines": ["## New Methods - Please document or move to the undocumented section"]}, {"block": 284, "type": "code", "linesLength": 1, "startIndex": 493, "lines": ["show_doc(ItemList.add)"]}, {"block": 285, "type": "markdown", "linesLength": 0, "startIndex": 494, "lines": []}]