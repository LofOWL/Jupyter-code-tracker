[{"block": 0, "type": "markdown", "linesLength": 3, "startIndex": 0, "lines": ["# Introduction: Prediction Intervals with Scikit-Learn\n", "\n", "In this notebook, we'll use the Gradient Boosting Regressor in Scikit-Learn to produce prediction intervals in addition to a single estimate of the target. Prediction intervals are useful when we want to show the uncertainty inherent in any prediction."]}, {"block": 1, "type": "markdown", "linesLength": 3, "startIndex": 3, "lines": ["## Imports \n", "\n", "We're using a pretty typical data science stack plus a few visualization and interact tools for making interactive visualizations. "]}, {"block": 2, "type": "code", "linesLength": 22, "startIndex": 6, "lines": ["# Data Manipulation\n", "import pandas as pd\n", "import numpy as np\n", "\n", "\n", "# Modeling\n", "from sklearn.base import BaseEstimator\n", "from sklearn.ensemble import GradientBoostingRegressor\n", "\n", "# File finding\n", "import glob\n", "files = glob.glob('data/*_energy_data.csv')\n", "\n", "# Interactivity\n", "from ipywidgets import interact, widgets\n", "\n", "# Visualization\n", "import cufflinks as cf\n", "cf.go_offline(connected=True)\n", "import plotly.graph_objs as go\n", "from plotly.offline import iplot, plot, init_notebook_mode\n", "init_notebook_mode(connected=True)"]}, {"block": 3, "type": "markdown", "linesLength": 7, "startIndex": 28, "lines": ["## Explore Data\n", "\n", "For our modeling, we're going to be prediction building energy consumption. This is an important problem that we at Cortex Building Intelligence work on every day and it provides a good supervised, regression machine learning task. The energy data is measured every 15 minutes and includes 3 weather variables related to energy consumption: temperature, irradiance, and relative humidity. \n", "\n", "Although in a real application, we'd be using data from a database (study up on SQL), here we'll just load in the data from a csv. This is data from the DrivenData Energy Forecasting competition. You can find the original data [at DrivenData](https://www.drivendata.org/competitions/51/electricity-prediction-machine-learning/). I've cleaned up the datasets and extracted 8 features that allow us to predict the energy consumption fairly accurately. \n", "\n", "We're not going to spend any time on feature engineering or investigating the data, but know that should be a part of a data science pipeline."]}, {"block": 4, "type": "code", "linesLength": 2, "startIndex": 35, "lines": ["data = pd.read_csv(files[2], parse_dates=['timestamp'], index_col='timestamp').sort_index()\n", "data.head()"]}, {"block": 5, "type": "markdown", "linesLength": 3, "startIndex": 37, "lines": ["## Interactive Plot\n", "\n", "With `ipywidgets` and `plotly` (through `cufflinks`), it's easy to create an interact plot in a few lines of code. We can take a look at the energy consumption on different timescales."]}, {"block": 6, "type": "code", "linesLength": 41, "startIndex": 40, "lines": ["# Create a subset of data for plotting\n", "data_to_plot = data.loc[\"2015\"].copy()\n", "\n", "\n", "def plot_timescale(timescale, selection, theme):\n", "    \"\"\"\n", "    Plot the energy consumption on different timescales (day, week, month).\n", "    \n", "    :param timescale: the timescale to use\n", "    :param selection: the numeric value of the timescale selection (for example the 15th day\n", "    of the year or the 1st week of the year)\n", "    :param theme: aesthetics of plot\n", "    \"\"\"\n", "    # Subset based on timescale and selection\n", "    subset = data_to_plot.loc[\n", "        getattr(data_to_plot.index, timescale) == selection, \"energy\"\n", "    ].copy()\n", "\n", "    if subset.empty:\n", "        print(\"Choose another selection\")\n", "        return\n", "    \n", "    # Make an interactive plot\n", "    fig = subset.iplot(\n", "            title=f\"Energy for {selection} {timescale.title()}\", theme=theme, asFigure=True\n", "    )\n", "    fig['layout']['height'] = 900\n", "    fig['layout']['width'] = 1400\n", "    iplot(fig)\n", "    \n", "\n", "\n", "_ = interact(\n", "    plot_timescale,\n", "    timescale=widgets.RadioButtons(\n", "        options=[\"dayofyear\", \"week\", \"month\"], value=\"dayofyear\"\n", "    ),\n", "    # Selection \n", "    selection=widgets.IntSlider(value=16, min=0, max=365),\n", "    theme=widgets.Select(options=cf.themes.THEMES.keys(), value='ggplot')\n", ")"]}, {"block": 7, "type": "markdown", "linesLength": 1, "startIndex": 81, "lines": ["Clearly, there are different patterns in energy usage over the course of a day, week, and month. We can also look at longer timescales."]}, {"block": 8, "type": "code", "linesLength": 1, "startIndex": 82, "lines": ["data.loc['2015', 'energy'].iplot(layout=dict(title='2015 Energy Consumption', height=800))"]}, {"block": 9, "type": "markdown", "linesLength": 1, "startIndex": 83, "lines": ["Plotting this much data can make the notebook slow. Instead, we can resample the data and plot to see any long term trends."]}, {"block": 10, "type": "code", "linesLength": 1, "startIndex": 84, "lines": ["data.resample('12 H')['energy'].mean().iplot(layout=dict(title='Energy Data Resampled at 12 Hours', height=800))"]}, {"block": 11, "type": "markdown", "linesLength": 13, "startIndex": 85, "lines": ["# Predicting Intervals with the Gradient Boosting Regressor\n", "\n", "If this was a real application, we'd problem want to spend more time understanding the data and checking for outliers. However, the main focus here is to predict intervals so let's dive into the modeling.\n", "\n", "This code is based on an [example from Scikit-Learn](https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_quantile.html). The basic idea is straightforward:\n", "\n", "* For the lower prediction, use the `GradientBoostingRegressor` with `loss='quantile'` and `alpha=lower_quantile` (for example, 0.1)\n", "* For the upper prediction, use the `GradientBoostingRegressor` with `loss='quantile'` and `alpha=upper_quantile` (for example, 0.9)\n", "* For the middle prediction (generally taken to be the median), we have several options. We can use `GradientBoostingRegressor` with `loss='quantile'` and `alpha=0.5` or, we can use the same model with the default `loss=ls` (for least squares) which optimizes for the median.\n", "\n", "The loss refers to the metric which is optimized by the model. We won't get into the details right here (see Quantile Loss Explained below), but for more information on the quantile loss and regression, this article is probably the best place to start: https://towardsdatascience.com/quantile-regression-from-linear-models-to-trees-to-deep-learning-af3738b527c3. [The Wikipedia page on Quantile Regression](https://en.wikipedia.org/wiki/Quantile_regression) gets into slightly more detail. For the original explanation of the Gradient Boosting model, see [Friedman's 1999 paper](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf) \"Greedy Function Approximation: A Gradient Boosting Machine\". \n", "\n", "You don't need to know the details to implement the prediction intervals, although it can be useful to tuning the model. Now, let's make the predictions, and later in the notebook we'll take a high-level look at the loss function."]}, {"block": 12, "type": "code", "linesLength": 8, "startIndex": 98, "lines": ["# Train and test sets\n", "X_train = data.loc[\"2015\":\"2016\"].copy()\n", "X_test = data.loc[\"2017\":].copy()\n", "y_train = X_train.pop(\"energy\")\n", "y_test = X_test.pop(\"energy\")\n", "\n", "X_train.tail()\n", "X_test.head()"]}, {"block": 13, "type": "markdown", "linesLength": 1, "startIndex": 106, "lines": ["We're assuming we know all the weather in the test set, which isn't entirely realistic, but we'll use it for now!"]}, {"block": 14, "type": "markdown", "linesLength": 1, "startIndex": 107, "lines": ["### Build Models for Lower, Upper Quantile and Median"]}, {"block": 15, "type": "code", "linesLength": 18, "startIndex": 108, "lines": ["# Set lower and upper quantile\n", "LOWER_ALPHA = 0.15\n", "UPPER_ALPHA = 0.85\n", "\n", "N_ESTIMATORS = 100\n", "MAX_DEPTH = 5\n", "\n", "# Each model has to be separate\n", "\n", "lower_model = GradientBoostingRegressor(\n", "    loss=\"quantile\", alpha=LOWER_ALPHA, n_estimators=N_ESTIMATORS, max_depth=MAX_DEPTH\n", ")\n", "# The mid model will use the default\n", "mid_model = GradientBoostingRegressor(loss=\"ls\", n_estimators=N_ESTIMATORS, max_depth=MAX_DEPTH)\n", "\n", "upper_model = GradientBoostingRegressor(\n", "    loss=\"quantile\", alpha=UPPER_ALPHA, n_estimators=N_ESTIMATORS, max_depth=MAX_DEPTH\n", ")"]}, {"block": 16, "type": "markdown", "linesLength": 3, "startIndex": 126, "lines": ["### Train Models\n", "\n", "The models are trained based on optimizing for the specific loss function. This means __we have to build 3 separate models to predict the different objectives.__ A downside of this method is that it's a little slow, particularly because we can't parallelize training on the Scikit-Learn Gradient Boosting Regresssor. If you wanted, you could re-write this code to train each model on a separate processor (using `multiprocessing`.)"]}, {"block": 17, "type": "code", "linesLength": 3, "startIndex": 129, "lines": ["_ = lower_model.fit(X_train, y_train)\n", "_ = mid_model.fit(X_train, y_train)\n", "_ = upper_model.fit(X_train, y_train)"]}, {"block": 18, "type": "markdown", "linesLength": 3, "startIndex": 132, "lines": ["### Make Predictions\n", "\n", "With the models all trained, we now make predictions and record them with the true values."]}, {"block": 19, "type": "code", "linesLength": 6, "startIndex": 135, "lines": ["predictions = pd.DataFrame(y_test)\n", "predictions['lower'] = lower_model.predict(X_test)\n", "predictions['mid'] = mid_model.predict(X_test)\n", "predictions['upper'] = upper_model.predict(X_test)\n", "\n", "predictions.tail()"]}, {"block": 20, "type": "markdown", "linesLength": 3, "startIndex": 141, "lines": ["## Prediction Intervals Plot\n", "\n", "The best way to inspect these results is visually. Here we use plotly to make a filled area chart showing the prediction intervals."]}, {"block": 21, "type": "code", "linesLength": 88, "startIndex": 144, "lines": ["def plot_intervals(predictions, start=None, stop=None, title=None):\n", "    \"\"\"\n", "    Function for plotting prediction intervals as filled area chart.\n", "    \n", "    :param predictions: dataframe of predictions with lower, upper, and actual columns (named for the target)\n", "    :param start: optional parameter for subsetting start of predictions\n", "    :param stop: optional parameter for subsetting end of predictions\n", "    :param title: optional string title\n", "    \n", "    :return fig: plotly figure\n", "    \"\"\"\n", "    # Subset if required\n", "    predictions = (\n", "        predictions.loc[start:stop].copy()\n", "        if start is not None or stop is not None\n", "        else predictions.copy()\n", "    )\n", "    data = []\n", "\n", "    # Lower trace will fill to the upper trace\n", "    trace_low = go.Scatter(\n", "        x=predictions.index,\n", "        y=predictions[\"lower\"],\n", "        fill=\"tonexty\",\n", "        line=dict(color=\"darkblue\"),\n", "        fillcolor=\"lightblue\",\n", "        showlegend=True,\n", "        name=\"lower\",\n", "    )\n", "    # Upper trace has no fill\n", "    trace_high = go.Scatter(\n", "        x=predictions.index,\n", "        y=predictions[\"upper\"],\n", "        fill=None,\n", "        line=dict(color=\"orange\"),\n", "        showlegend=True,\n", "        name=\"upper\",\n", "    )\n", "\n", "    # Must append high trace first so low trace fills to the high trace\n", "    data.append(trace_high)\n", "    data.append(trace_low)\n", "\n", "    # Trace of actual values\n", "    trace_actual = go.Scatter(\n", "        x=predictions.index,\n", "        y=predictions[\"energy\"],\n", "        fill=None,\n", "        line=dict(color=\"black\"),\n", "        showlegend=True,\n", "        name=\"actual\",\n", "    )\n", "    data.append(trace_actual)\n", "\n", "    # Layout with some customization\n", "    layout = go.Layout(\n", "        height=900,\n", "        width=1400,\n", "        title=dict(text=\"Prediction Intervals\" if title is None else title),\n", "        yaxis=dict(title=dict(text=\"kWh\")),\n", "        xaxis=dict(\n", "            rangeselector=dict(\n", "                buttons=list(\n", "                    [\n", "                        dict(count=1, label=\"1d\", step=\"day\", stepmode=\"backward\"),\n", "                        dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n", "                        dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n", "                        dict(count=1, label=\"YTD\", step=\"year\", stepmode=\"todate\"),\n", "                        dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n", "                        dict(step=\"all\"),\n", "                    ]\n", "                )\n", "            ),\n", "            rangeslider=dict(visible=True),\n", "            type=\"date\",\n", "        ),\n", "    )\n", "\n", "    fig = go.Figure(data=data, layout=layout)\n", "\n", "    # Make sure font is readable\n", "    fig[\"layout\"][\"font\"] = dict(size=20)\n", "    fig.layout.template = \"plotly_white\"\n", "    return fig\n", "\n", "\n", "# Example plot subsetted to one week\n", "fig = plot_intervals(predictions, start=\"2017-03-01\", stop=\"2017-03-08\")"]}, {"block": 22, "type": "code", "linesLength": 1, "startIndex": 232, "lines": ["iplot(fig)"]}, {"block": 23, "type": "code", "linesLength": 1, "startIndex": 233, "lines": ["iplot(plot_intervals(predictions))"]}, {"block": 24, "type": "markdown", "linesLength": 1, "startIndex": 234, "lines": ["Not too bad for a first try! Play around with the model parameters and the `alpha` parameters to see how it affects the plot."]}, {"block": 25, "type": "markdown", "linesLength": 5, "startIndex": 235, "lines": ["### Calculate Error\n", "\n", "With any machine learning model, we want to make predictions of the error. Quantifying the error of a prediction range can be tricky. We'll start off with the percentage of the time that the actual value falls in the range. However, one way to maximize this metric would be to just use extremely wide prediction intervals. Therefore, we want to penalize the model for making too wide prediction intervals. As a simple example (let me know ideas for a better metric) we can calculate the absolute error of the bottom and top lines, and divide by two to get an absolute error. We then take the average for the mean absolute error. We can also calculate the absolute error of the mid predictions.\n", "\n", "These are likely not the best metrics for all cases, so think about what your objective is before selecting a metric. For instance, you may want wide prediction intervals in which case you value the percent in bounds more than the error, but other times, you might want a narrow range of estimates."]}, {"block": 26, "type": "code", "linesLength": 16, "startIndex": 240, "lines": ["def calculate_error(predictions):\n", "    \"\"\"\n", "    Calculate the absolute error associated with prediction intervals\n", "    \n", "    :param predictions: dataframe of predictions\n", "    :return: None, modifies the prediction dataframe\n", "    \n", "    \"\"\"\n", "    \n", "    predictions['absolute_error_lower'] = (predictions['lower'] - predictions['energy']).abs()\n", "    predictions['absolute_error_upper'] = (predictions['upper'] - predictions['energy']).abs()\n", "    \n", "    predictions['absolute_error_interval'] = (predictions['absolute_error_lower'] + predictions['absolute_error_upper']) / 2\n", "    predictions['absolute_error_mid'] = (predictions['mid'] - predictions['energy']).abs()\n", "    \n", "    predictions['in_bounds'] = predictions['energy'].between(left=predictions['lower'], right=predictions['upper'])"]}, {"block": 27, "type": "code", "linesLength": 3, "startIndex": 256, "lines": ["calculate_error(predictions)\n", "metrics = predictions[['absolute_error_lower', 'absolute_error_upper', 'absolute_error_interval', 'absolute_error_mid', 'in_bounds']].copy()\n", "metrics.describe()"]}, {"block": 28, "type": "code", "linesLength": 2, "startIndex": 259, "lines": ["import plotly_express as px\n", "px.bar(metrics.melt(var_name='metric'), x='metric', y='value', title='Error Metrics Boxplots', height=800, width=1600)"]}, {"block": 29, "type": "markdown", "linesLength": 3, "startIndex": 261, "lines": ["# Prediction Interval Class\n", "\n", "To make this process repeatable, we can build our own estimator with a Scikit-Learn interface that fits and predicts all 3 models in one call each. This is a very simple class but can be extended based on your needs (feel free to show me ways to improve)."]}, {"block": 30, "type": "code", "linesLength": 76, "startIndex": 264, "lines": ["class GradientBoostingPredictionIntervals(BaseEstimator):\n", "    \"\"\"\n", "    Model that produces prediction intervals with a Scikit-Learn inteface\n", "    \n", "    :param lower_alpha: lower quantile for prediction, default=0.1\n", "    :param upper_alpha: upper quantile for prediction, default=0.9\n", "    :param **kwargs: additional keyword arguments for creating a GradientBoostingRegressor model\n", "    \"\"\"\n", "\n", "    def __init__(self, lower_alpha=0.1, upper_alpha=0.9, **kwargs):\n", "        self.lower_alpha = lower_alpha\n", "        self.upper_alpha = upper_alpha\n", "\n", "        # Three separate models\n", "        self.lower_model = GradientBoostingRegressor(\n", "            loss=\"quantile\", alpha=self.lower_alpha, **kwargs\n", "        )\n", "        self.mid_model = GradientBoostingRegressor(loss=\"ls\", **kwargs)\n", "        self.upper_model = GradientBoostingRegressor(\n", "            loss=\"quantile\", alpha=self.upper_alpha, **kwargs\n", "        )\n", "        self.predictions = None\n", "\n", "    def fit(self, X, y):\n", "        \"\"\"\n", "        Fit all three models\n", "            \n", "        :param X: train features\n", "        :param y: train targets\n", "        \n", "        TODO: parallelize this code across processors\n", "        \"\"\"\n", "        self.lower_model.fit(X_train, y_train)\n", "        self.mid_model.fit(X_train, y_train)\n", "        self.upper_model.fit(X_train, y_train)\n", "\n", "    def predict(self, X, y):\n", "        \"\"\"\n", "        Predict with all 3 models \n", "        \n", "        :param X: test features\n", "        :param y: test targets\n", "        :return predictions: dataframe of predictions\n", "        \n", "        TODO: parallelize this code across processors\n", "        \"\"\"\n", "        predictions = pd.DataFrame(y)\n", "        predictions[\"lower\"] = self.lower_model.predict(X)\n", "        predictions[\"mid\"] = self.mid_model.predict(X)\n", "        predictions[\"upper\"] = self.upper_model.predict(X)\n", "        self.predictions = predictions\n", "\n", "        return predictions\n", "\n", "    def plot_intervals(self, start=None, stop=None):\n", "        \"\"\"\n", "        Plot the prediction intervals\n", "        \n", "        :param start: optional parameter for subsetting start of predictions\n", "        :param stop: optional parameter for subsetting end of predictions\n", "    \n", "        :return fig: plotly figure\n", "        \"\"\"\n", "\n", "        if self.predictions is None:\n", "            raise ValueError(\"This model has not yet made predictions.\")\n", "            return\n", "\n", "        # Subset if required\n", "        predictions = (\n", "            self.predictions.loc[start:stop].copy()\n", "            if start is not None or stop is not None\n", "            else self.predictions.copy()\n", "        )\n", "        fig = plot_intervals(predictions)\n", "        return fig"]}, {"block": 31, "type": "markdown", "linesLength": 1, "startIndex": 340, "lines": ["To use the model, we just fit and predict like any Scikit-Learn model. This time though, the predictions are a dataframe with intervals."]}, {"block": 32, "type": "code", "linesLength": 5, "startIndex": 341, "lines": ["model = GradientBoostingPredictionIntervals(lower_alpha=0.1, upper_alpha=0.9, n_estimators=50, max_depth=3)\n", "\n", "# Fit and make predictions\n", "_ = model.fit(X_train, y_train)\n", "predictions = model.predict(X_test, y_test)"]}, {"block": 33, "type": "code", "linesLength": 3, "startIndex": 346, "lines": ["fig = model.plot_intervals(start='2017-05-01', \n", "                           stop='2017-06-01')\n", "iplot(fig)"]}]