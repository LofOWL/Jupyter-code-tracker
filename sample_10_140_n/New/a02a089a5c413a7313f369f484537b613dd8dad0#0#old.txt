[{"block": 0, "type": "markdown", "linesLength": 3, "startIndex": 0, "lines": ["<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n", "\n", "<i>Licensed under the MIT License.</i>"]}, {"block": 1, "type": "markdown", "linesLength": 8, "startIndex": 3, "lines": ["# Wide and Deep Model for Movie Recommendation\n", "<br>\n", "\n", "This notebook shows how to build and test [**wide-and-deep model**](https://arxiv.org/abs/1606.07792)--linear combination of linear and deep NN models--using [TensorFlow high-level Estimator API](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNLinearCombinedRegressor).\n", "\n", "On the [movie recommendation dataset](https://grouplens.org/datasets/movielens/), we quickly demonstrate how to prepare features, build the model, use log-hook to estimate performance while training, export model, and load the saved model.\n", "\n", "We use a preset of hyper-parameters optimized for *MovieLens 1M* dataset we found by utilizing **Azure Machine Learning service**([AzureML or AML](https://azure.microsoft.com/en-us/services/machine-learning-service/)). You can find more details about hyperparameter tuning of wide-and-deep model via AML from [our notebook](../04_model_select_and_optimize/aml_hyperparameter_tuning.ipynb)."]}, {"block": 2, "type": "markdown", "linesLength": 2, "startIndex": 11, "lines": ["### Prerequisite\n", "* TensorFlow (version 1.8 or higher) - GPU version is preferable. To easily setup a conda environment with `tensorflow-gpu` package, please follow [SETUP].(https://github.com/Microsoft/Recommenders/blob/master/SETUP.md) "]}, {"block": 3, "type": "code", "linesLength": 20, "startIndex": 13, "lines": ["import sys\n", "sys.path.append(\"../../\")\n", "\n", "import os\n", "import shutil\n", "import itertools\n", "\n", "import tensorflow as tf\n", "import pandas as pd\n", "import numpy as np\n", "import sklearn.preprocessing\n", "\n", "from reco_utils.common import tf_utils\n", "from reco_utils.dataset import movielens\n", "from reco_utils.dataset.pandas_df_utils import user_item_pairs\n", "from reco_utils.dataset.python_splitters import python_random_split\n", "from reco_utils.evaluation.python_evaluation import (\n", "    rmse, mae, rsquared, exp_var,\n", "    map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n", ")"]}, {"block": 4, "type": "code", "linesLength": 6, "startIndex": 33, "lines": ["from tensorflow.python.client import device_lib\n", "\n", "print(\"Tensorflow Version:\", tf.__version__)\n", "\n", "devices = device_lib.list_local_devices()\n", "[x.name for x in devices]"]}, {"block": 5, "type": "markdown", "linesLength": 7, "startIndex": 39, "lines": ["### Data loading\n", "\n", "Download [MovieLens](https://grouplens.org/datasets/movielens/) data and split train / test set.\n", "\n", "MovieLens data have movie genres information where each movie has one or more genres. We do multi-hot-encode to use genres as an item feature. For example:\n", "\n", "*Movie id=2355* has three genres, *Animation | Children's | Comedy*, which are being converted into an integer array of the indicator value for each genre like `[0, 0, 1, 1, 1, 0, 0, 0, ...]`."]}, {"block": 6, "type": "code", "linesLength": 10, "startIndex": 46, "lines": ["# top k items to recommend\n", "TOP_K = 10\n", "\n", "# Select Movielens data size: 100k, 1m, 10m, or 20m\n", "MOVIELENS_DATA_SIZE = '1m'\n", "\n", "USER_COL = 'UserId'\n", "ITEM_COL = 'MovieId'\n", "RATING_COL = 'Rating'\n", "ITEM_FEAT_COL = 'Genres'"]}, {"block": 7, "type": "code", "linesLength": 6, "startIndex": 56, "lines": ["data = movielens.load_pandas_df(\n", "    size=MOVIELENS_DATA_SIZE,\n", "    header=[USER_COL, ITEM_COL, RATING_COL],\n", "    genres_col='Genres_string'\n", ")\n", "data.head()"]}, {"block": 8, "type": "code", "linesLength": 9, "startIndex": 62, "lines": ["# Encode 'genres' into int array (multi-hot representation) to use as item features\n", "genres_encoder = sklearn.preprocessing.MultiLabelBinarizer()\n", "data[ITEM_FEAT_COL] = genres_encoder.fit_transform(\n", "    data['Genres_string'].apply(lambda s: s.split(\"|\"))\n", ").tolist()\n", "print(\"Genres:\", genres_encoder.classes_, \"\\n\")\n", "\n", "_items = data.drop_duplicates(ITEM_COL)[[ITEM_COL, 'Genres_string', ITEM_FEAT_COL]].reset_index(drop=True)\n", "print(_items.head())"]}, {"block": 9, "type": "code", "linesLength": 5, "startIndex": 71, "lines": ["# Unique items and users in the data. Will be used to generate recommendation pool\n", "items = _items.drop('Genres_string', axis=1)\n", "users = data.drop_duplicates(USER_COL)[[USER_COL]].reset_index(drop=True)\n", "\n", "print(\"num items = {}, num users = {}\".format(len(items), len(users)))"]}, {"block": 10, "type": "code", "linesLength": 5, "startIndex": 76, "lines": ["train, test = python_random_split(\n", "    data.drop('Genres_string', axis=1),\n", "    ratio=0.75,\n", "    seed=123\n", ")"]}, {"block": 11, "type": "markdown", "linesLength": 5, "startIndex": 81, "lines": ["### Modeling\n", "\n", "Wide and deep model utilizes two different types of feature sets:\n", "1. Wide / cross-producted features to capture how the co-occurrence of a user-item feature pair correlates with the target label or rating, and\n", "2. Deep / lower-dimensional embedding vectors for every user and item."]}, {"block": 12, "type": "code", "linesLength": 22, "startIndex": 86, "lines": ["\"\"\" Hyper parameters\n", "\"\"\"\n", "BATCH_SIZE = 256\n", "NUM_EPOCHS = int(20000000 / len(train))\n", "print(\"Num epochs: \", NUM_EPOCHS)\n", "\n", "LINEAR_OPTIMIZER = tf.train.FtrlOptimizer(\n", "    learning_rate=0.07,\n", "    l1_regularization_strength=0.015\n", ")\n", "DNN_OPTIMIZER = tf.train.AdagradOptimizer(\n", "    learning_rate=0.018\n", ")\n", "DNN_HIDDEN_UNITS = [64, 128, 32]\n", "DNN_DROPOUT = 0.2\n", "DNN_BATCH_NORM = True\n", "\n", "DNN_USER_DIM = 32\n", "DNN_ITEM_DIM = 16\n", "\n", "print(\"Embedding {} users to {}-dim vector\".format(len(users), DNN_USER_DIM))\n", "print(\"Embedding {} items to {}-dim vector\".format(len(items), DNN_ITEM_DIM))"]}, {"block": 13, "type": "code", "linesLength": 33, "startIndex": 108, "lines": ["\"\"\" Feature columns\n", "\"\"\"\n", "\n", "user_id = tf.feature_column.categorical_column_with_vocabulary_list(USER_COL, users[USER_COL].values)\n", "item_id = tf.feature_column.categorical_column_with_vocabulary_list(ITEM_COL, items[ITEM_COL].values)\n", "\n", "wide_columns = [\n", "    tf.feature_column.crossed_column([user_id, item_id], hash_bucket_size=1000)\n", "]\n", "\n", "deep_columns = [\n", "    # User embedding\n", "    tf.feature_column.embedding_column(\n", "        categorical_column=user_id,\n", "        dimension=DNN_USER_DIM,\n", "        max_norm=DNN_USER_DIM ** .5\n", "    ),\n", "    # Item embedding\n", "    tf.feature_column.embedding_column(\n", "        categorical_column=item_id,\n", "        dimension=DNN_ITEM_DIM,\n", "        max_norm=DNN_ITEM_DIM ** .5\n", "    ),\n", "    # Item feature\n", "    tf.feature_column.numeric_column(\n", "        ITEM_FEAT_COL,\n", "        shape=len(genres_encoder.classes_),\n", "        dtype=tf.float32\n", "    )\n", "]\n", "\n", "for c in wide_columns + deep_columns:\n", "    print(str(c)[:100], \"...\")"]}, {"block": 14, "type": "code", "linesLength": 27, "startIndex": 141, "lines": ["MODEL_DIR = 'model_checkpoints'\n", "\n", "try:\n", "    # Clean-up previous model dir if exists\n", "    shutil.rmtree(MODEL_DIR)\n", "except (PermissionError, FileNotFoundError):\n", "    pass\n", "\n", "# Set logging frequency\n", "LOG_STEP = 1000\n", "run_config = tf.estimator.RunConfig()\n", "run_config = run_config.replace(log_step_count_steps=LOG_STEP)\n", "\n", "# We use regressor for rating prediction\n", "model = tf.estimator.DNNLinearCombinedRegressor(\n", "    model_dir=MODEL_DIR,\n", "    config=run_config,\n", "    # wide model args\n", "    linear_feature_columns=wide_columns,\n", "    linear_optimizer=LINEAR_OPTIMIZER,\n", "    # deep model args\n", "    dnn_feature_columns=deep_columns,\n", "    dnn_hidden_units=DNN_HIDDEN_UNITS,\n", "    dnn_optimizer=DNN_OPTIMIZER,\n", "    dnn_dropout=DNN_DROPOUT,\n", "    batch_norm=DNN_BATCH_NORM\n", ")"]}, {"block": 15, "type": "code", "linesLength": 9, "startIndex": 168, "lines": ["# Add additional metrics 'mae' in addition to the default 'loss'\n", "metrics_fn = (lambda labels, predictions: {\n", "    'mae': tf.metrics.mean_absolute_error(\n", "        tf.cast(labels, tf.float32),\n", "        predictions['predictions']\n", "    )\n", "})\n", "\n", "model = tf.contrib.estimator.add_metrics(model, metrics_fn)"]}, {"block": 16, "type": "markdown", "linesLength": 1, "startIndex": 177, "lines": ["### Training and Evaluation"]}, {"block": 17, "type": "code", "linesLength": 12, "startIndex": 178, "lines": ["# Prepare a recommendation pool for recommending k-item (ranking) scenario\n", "# We also remove seen items (filter out user-item pairs in the training set)\n", "ranking_pool = user_item_pairs(\n", "    user_df=users,\n", "    item_df=items,\n", "    user_col=USER_COL,\n", "    item_col=ITEM_COL,\n", "    user_item_filter_df=train,\n", "    shuffle=True\n", ")\n", "\n", "ranking_pool.head()"]}, {"block": 18, "type": "code", "linesLength": 20, "startIndex": 190, "lines": ["\"\"\" Training hooks\n", "\"\"\"\n", "eval_kwargs = {\n", "    'col_user': USER_COL,\n", "    'col_item': ITEM_COL,\n", "    'col_rating': RATING_COL,\n", "    'col_prediction': 'prediction',\n", "    'k': TOP_K\n", "}\n", "\n", "precision_eval_hook = tf_utils.evaluation_log_hook(\n", "    model,\n", "    true_df=test,\n", "    y_col=RATING_COL,\n", "    eval_df=ranking_pool,\n", "    every_n_iter=LOG_STEP*20,\n", "    model_dir=MODEL_DIR,\n", "    eval_fn=precision_at_k,\n", "    **eval_kwargs\n", ")"]}, {"block": 19, "type": "code", "linesLength": 10, "startIndex": 210, "lines": ["model.train(\n", "    input_fn=tf_utils.pandas_input_fn(\n", "        df=train,\n", "        y_col=RATING_COL,\n", "        batch_size=BATCH_SIZE,\n", "        num_epochs=NUM_EPOCHS,\n", "        shuffle=True\n", "    ),\n", "    hooks=[precision_eval_hook]\n", ")"]}, {"block": 20, "type": "markdown", "linesLength": 3, "startIndex": 220, "lines": ["### Testing\n", "\n", "We predict the ratings by using the wide-deep model we trained. Finally, we also generate top-k movie recommentation for each user and test the performance."]}, {"block": 21, "type": "markdown", "linesLength": 1, "startIndex": 223, "lines": ["1. Item rating prediction"]}, {"block": 22, "type": "code", "linesLength": 11, "startIndex": 224, "lines": ["cols = {\n", "    'col_user': USER_COL,\n", "    'col_item': ITEM_COL,\n", "    'col_rating': RATING_COL,\n", "    'col_prediction': 'prediction'\n", "}\n", "\n", "predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=test)))\n", "prediction_df = test.drop(RATING_COL, axis=1)\n", "prediction_df['prediction'] = [p['predictions'][0] for p in predictions]\n", "prediction_df['prediction'].describe()"]}, {"block": 23, "type": "code", "linesLength": 9, "startIndex": 235, "lines": ["eval_rmse = rmse(test, prediction_df, **cols)\n", "eval_mae = mae(test, prediction_df, **cols)\n", "eval_rsquared = rsquared(test, prediction_df, **cols)\n", "eval_exp_var = exp_var(test, prediction_df, **cols)\n", "\n", "print(\"RMSE:\\t\\t%f\" % eval_rmse,\n", "      \"MAE:\\t\\t%f\" % eval_mae,\n", "      \"rsquared:\\t%f\" % eval_rsquared,\n", "      \"exp var:\\t%f\" % eval_exp_var, sep='\\n')"]}, {"block": 24, "type": "code", "linesLength": 9, "startIndex": 244, "lines": ["eval_results = model.evaluate(\n", "    input_fn=tf_utils.pandas_input_fn(\n", "        df=test,\n", "        y_col=RATING_COL\n", "    ),\n", "    steps=None\n", ")\n", "\n", "print(eval_results)"]}, {"block": 25, "type": "markdown", "linesLength": 1, "startIndex": 253, "lines": ["2. Recommend k items"]}, {"block": 26, "type": "code", "linesLength": 13, "startIndex": 254, "lines": ["predictions = list(model.predict(input_fn=tf_utils.pandas_input_fn(df=ranking_pool)))\n", "prediction_df = ranking_pool.copy()\n", "prediction_df['prediction'] = [p['predictions'][0] for p in predictions]\n", "\n", "eval_map = map_at_k(test, prediction_df, k=TOP_K, **cols)\n", "eval_ndcg = ndcg_at_k(test, prediction_df, k=TOP_K, **cols)\n", "eval_precision = precision_at_k(test, prediction_df, k=TOP_K, **cols)\n", "eval_recall = recall_at_k(test, prediction_df, k=TOP_K, **cols)\n", "\n", "print(\"MAP:\\t%f\" % eval_map,\n", "      \"NDCG:\\t%f\" % eval_ndcg,\n", "      \"Precision@K:\\t%f\" % eval_precision,\n", "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"]}, {"block": 27, "type": "markdown", "linesLength": 3, "startIndex": 267, "lines": ["### Tensorboard\n", "\n", "To see Tensorboard, open a terminal from this notebook folder, run `tensorboard --logdir=model_checkpoints`, and open http://localhost:6006 from a browser."]}, {"block": 28, "type": "markdown", "linesLength": 1, "startIndex": 270, "lines": ["### Export Model"]}, {"block": 29, "type": "code", "linesLength": 2, "startIndex": 271, "lines": ["EXPORT_DIR_BASE = 'saved_model'\n", "os.makedirs(EXPORT_DIR_BASE, exist_ok=True)"]}, {"block": 30, "type": "code", "linesLength": 31, "startIndex": 273, "lines": ["train_rcvr_fn = tf.contrib.estimator.build_supervised_input_receiver_fn_from_input_fn(\n", "    tf_utils.pandas_input_fn(\n", "        df=train,\n", "        y_col=RATING_COL,\n", "        batch_size=BATCH_SIZE,\n", "        num_epochs=NUM_EPOCHS,\n", "        shuffle=True\n", "    )\n", ")\n", "eval_rcvr_fn = tf.contrib.estimator.build_supervised_input_receiver_fn_from_input_fn(\n", "    tf_utils.pandas_input_fn(\n", "        df=test,\n", "        y_col=RATING_COL\n", "    )\n", ")\n", "serve_rcvr_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n", "    tf.feature_column.make_parse_example_spec(wide_columns+deep_columns)\n", ")\n", "rcvr_fn_map = {\n", "    tf.estimator.ModeKeys.TRAIN: train_rcvr_fn,\n", "    tf.estimator.ModeKeys.EVAL: eval_rcvr_fn,\n", "    tf.estimator.ModeKeys.PREDICT: serve_rcvr_fn\n", "}\n", "\n", "export_dir = tf.contrib.estimator.export_all_saved_models(\n", "    model,\n", "    export_dir_base=EXPORT_DIR_BASE,\n", "    input_receiver_fn_map=rcvr_fn_map\n", ")\n", "\n", "print(\"Model exported to\", export_dir)"]}, {"block": 31, "type": "code", "linesLength": 10, "startIndex": 304, "lines": ["saved_model = tf.contrib.estimator.SavedModelEstimator(export_dir)\n", "\n", "result = saved_model.evaluate(\n", "    tf_utils.pandas_input_fn(\n", "        df=test,\n", "        y_col=RATING_COL\n", "    ),\n", "    steps=None\n", ")\n", "print(result)"]}, {"block": 32, "type": "code", "linesLength": 2, "startIndex": 314, "lines": ["test_sample = test.iloc[0]\n", "test_sample"]}, {"block": 33, "type": "code", "linesLength": 9, "startIndex": 316, "lines": ["def predict_input_fn():\n", "    example = tf.train.Example()\n", "    \n", "    example.features.feature[USER_COL].int64_list.value.extend([test_sample[USER_COL]])\n", "    example.features.feature[ITEM_COL].int64_list.value.extend([test_sample[ITEM_COL]])\n", "    example.features.feature[ITEM_FEAT_COL].float_list.value.extend(test_sample[ITEM_FEAT_COL])\n", "    return {'inputs':tf.constant([example.SerializeToString()])}\n", "\n", "print(next(saved_model.predict(predict_input_fn)))"]}, {"block": 34, "type": "code", "linesLength": 2, "startIndex": 325, "lines": ["# Cleanup\n", "shutil.rmtree(EXPORT_DIR_BASE)"]}, {"block": 35, "type": "code", "linesLength": 0, "startIndex": 327, "lines": []}]