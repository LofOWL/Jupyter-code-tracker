[{"block": 0, "type": "code", "linesLength": 3, "startIndex": 0, "lines": ["%matplotlib inline\n", "%reload_ext autoreload\n", "%autoreload 2"]}, {"block": 1, "type": "code", "linesLength": 7, "startIndex": 3, "lines": ["from fastai.conv_learner import *\n", "from fastai.dataset import *\n", "\n", "from pathlib import Path\n", "import json, pdb\n", "from PIL import ImageDraw, ImageFont\n", "from matplotlib import patches, patheffects"]}, {"block": 2, "type": "markdown", "linesLength": 1, "startIndex": 10, "lines": ["## Setup"]}, {"block": 3, "type": "code", "linesLength": 11, "startIndex": 11, "lines": ["PATH = Path('data/pascal')\n", "trn_j = json.load((PATH / 'pascal_train2007.json').open())\n", "IMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', 'categories']\n", "FILE_NAME,ID,IMG_ID,CAT_ID,BBOX = 'file_name','id','image_id','category_id','bbox'\n", "\n", "cats = dict((o[ID], o['name']) for o in trn_j[CATEGORIES])\n", "trn_fns = dict((o[ID], o[FILE_NAME]) for o in trn_j[IMAGES])\n", "trn_ids = [o[ID] for o in trn_j[IMAGES]]\n", "\n", "JPEGS = 'VOC2007/JPEGImages'\n", "IMG_PATH = PATH/JPEGS"]}, {"block": 4, "type": "code", "linesLength": 10, "startIndex": 22, "lines": ["def get_trn_anno():\n", "    trn_anno = collections.defaultdict(lambda:[])\n", "    for o in trn_j[ANNOTATIONS]:\n", "        if not o['ignore']:\n", "            bb = o[BBOX]\n", "            bb = np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n", "            trn_anno[o[IMG_ID]].append((bb,o[CAT_ID]))\n", "    return trn_anno\n", "\n", "trn_anno = get_trn_anno()"]}, {"block": 5, "type": "code", "linesLength": 22, "startIndex": 32, "lines": ["def show_img(im, figsize=None, ax=None):\n", "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n", "    ax.imshow(im)\n", "    ax.set_xticks(np.linspace(0, 224, 8))\n", "    ax.set_yticks(np.linspace(0, 224, 8))\n", "    ax.grid()\n", "    ax.set_yticklabels([])\n", "    ax.set_xticklabels([])\n", "    return ax\n", "\n", "def draw_outline(o, lw):\n", "    o.set_path_effects([patheffects.Stroke(\n", "        linewidth=lw, foreground='black'), patheffects.Normal()])\n", "\n", "def draw_rect(ax, b, color='white'):\n", "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=color, lw=2))\n", "    draw_outline(patch, 4)\n", "\n", "def draw_text(ax, xy, txt, sz=14, color='white'):\n", "    text = ax.text(*xy, txt,\n", "        verticalalignment='top', color=color, fontsize=sz, weight='bold')\n", "    draw_outline(text, 1)"]}, {"block": 6, "type": "code", "linesLength": 13, "startIndex": 54, "lines": ["def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1],a[2]-a[0]])\n", "\n", "def draw_im(im, ann):\n", "    ax = show_img(im, figsize=(16,8))\n", "    for b,c in ann:\n", "        b = bb_hw(b)\n", "        draw_rect(ax, b)\n", "        draw_text(ax, b[:2], cats[c], sz=16)\n", "\n", "def draw_idx(i):\n", "    im_a = trn_anno[i]\n", "    im = open_image(IMG_PATH/trn_fns[i])\n", "    draw_im(im, im_a)"]}, {"block": 7, "type": "markdown", "linesLength": 1, "startIndex": 67, "lines": ["## Multi class"]}, {"block": 8, "type": "code", "linesLength": 1, "startIndex": 68, "lines": ["MC_CSV = PATH/'tmp/mc.csv'"]}, {"block": 9, "type": "code", "linesLength": 1, "startIndex": 69, "lines": ["trn_anno[12]"]}, {"block": 10, "type": "code", "linesLength": 2, "startIndex": 70, "lines": ["mc = [set([cats[p[1]] for p in trn_anno[o]]) for o in trn_ids]\n", "mcs = [' '.join(str(p) for p in o) for o in mc]"]}, {"block": 11, "type": "code", "linesLength": 2, "startIndex": 72, "lines": ["df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids], 'clas': mcs}, columns=['fn','clas'])\n", "df.to_csv(MC_CSV, index=False)"]}, {"block": 12, "type": "code", "linesLength": 3, "startIndex": 74, "lines": ["f_model=resnet34\n", "sz=224\n", "bs=64"]}, {"block": 13, "type": "code", "linesLength": 2, "startIndex": 77, "lines": ["tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO)\n", "md = ImageClassifierData.from_csv(PATH, JPEGS, MC_CSV, tfms=tfms)"]}, {"block": 14, "type": "code", "linesLength": 1, "startIndex": 79, "lines": ["x,y=next(iter(md.val_dl))"]}, {"block": 15, "type": "code", "linesLength": 2, "startIndex": 80, "lines": ["learn = ConvLearner.pretrained(f_model, md)\n", "learn.opt_fn = optim.Adam"]}, {"block": 16, "type": "code", "linesLength": 1, "startIndex": 82, "lines": ["lrf=learn.lr_find(1e-5,100)"]}, {"block": 17, "type": "code", "linesLength": 1, "startIndex": 83, "lines": ["learn.sched.plot(0)"]}, {"block": 18, "type": "code", "linesLength": 1, "startIndex": 84, "lines": ["lr = 1e-2"]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 85, "lines": ["learn.fit(lr, 1, cycle_len=1, use_clr=(32,5))"]}, {"block": 20, "type": "code", "linesLength": 1, "startIndex": 86, "lines": ["learn.fit(lr, 1, cycle_len=3, use_clr=(32,5))"]}, {"block": 21, "type": "code", "linesLength": 1, "startIndex": 87, "lines": ["lrs = np.array([lr/100, lr/10, lr])"]}, {"block": 22, "type": "code", "linesLength": 1, "startIndex": 88, "lines": ["learn.freeze_to(-2)"]}, {"block": 23, "type": "code", "linesLength": 2, "startIndex": 89, "lines": ["learn.lr_find(lrs/1000)\n", "learn.sched.plot(0)"]}, {"block": 24, "type": "code", "linesLength": 1, "startIndex": 91, "lines": ["learn.fit(lrs/15, 1, cycle_len=5, use_clr=(32,10))"]}, {"block": 25, "type": "code", "linesLength": 1, "startIndex": 92, "lines": ["learn.unfreeze()"]}, {"block": 26, "type": "code", "linesLength": 1, "startIndex": 93, "lines": ["learn.fit(lrs/15, 1, cycle_len=3, use_clr=(32,5))"]}, {"block": 27, "type": "code", "linesLength": 1, "startIndex": 94, "lines": ["learn.save('mclas')"]}, {"block": 28, "type": "code", "linesLength": 3, "startIndex": 95, "lines": ["y = learn.predict()\n", "x,_ = next(iter(md.val_dl))\n", "x = to_np(x)"]}, {"block": 29, "type": "code", "linesLength": 7, "startIndex": 98, "lines": ["fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n", "for i,ax in enumerate(axes.flat):\n", "    ima=md.val_ds.denorm(x)[i]\n", "    ya = np.nonzero(y[i]>0.4)[0]\n", "    b = '\\n'.join(md.classes[o] for o in ya)\n", "    ax = show_img(ima, ax=ax)\n", "    draw_text(ax, (0,0), b)"]}, {"block": 30, "type": "markdown", "linesLength": 1, "startIndex": 105, "lines": ["## Bbox per cell"]}, {"block": 31, "type": "markdown", "linesLength": 1, "startIndex": 106, "lines": ["### Set up data"]}, {"block": 32, "type": "code", "linesLength": 6, "startIndex": 107, "lines": ["CLAS_CSV = PATH/'tmp/clas.csv'\n", "MBB_CSV = PATH/'tmp/mbb.csv'\n", "\n", "f_model=resnet34\n", "sz=224\n", "bs=64"]}, {"block": 33, "type": "code", "linesLength": 4, "startIndex": 113, "lines": ["mc = [[cats[p[1]] for p in trn_anno[o]] for o in trn_ids]\n", "id2cat = list(cats.values())\n", "cat2id = {v:k for k,v in enumerate(id2cat)}\n", "mcs = np.array([np.array([cat2id[p] for p in o]) for o in mc]); mcs"]}, {"block": 34, "type": "code", "linesLength": 2, "startIndex": 117, "lines": ["val_idxs = get_cv_idxs(len(trn_fns))\n", "((val_mcs,trn_mcs),) = split_by_idx(val_idxs, mcs)"]}, {"block": 35, "type": "code", "linesLength": 5, "startIndex": 119, "lines": ["mbb = [np.concatenate([p[0] for p in trn_anno[o]]) for o in trn_ids]\n", "mbbs = [' '.join(str(p) for p in o) for o in mbb]\n", "\n", "df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids], 'bbox': mbbs}, columns=['fn','bbox'])\n", "df.to_csv(MBB_CSV, index=False)"]}, {"block": 36, "type": "code", "linesLength": 5, "startIndex": 124, "lines": ["aug_tfms = [RandomRotate(10, tfm_y=TfmType.COORD),\n", "            RandomLighting(0.05, 0.05, tfm_y=TfmType.COORD),\n", "            RandomFlip(tfm_y=TfmType.COORD)]\n", "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=aug_tfms)\n", "md = ImageClassifierData.from_csv(PATH, JPEGS, MBB_CSV, tfms=tfms, continuous=True, num_workers=4)"]}, {"block": 37, "type": "code", "linesLength": 11, "startIndex": 129, "lines": ["import matplotlib.cm as cmx\n", "import matplotlib.colors as mcolors\n", "from cycler import cycler\n", "\n", "def get_cmap(N):\n", "    color_norm  = mcolors.Normalize(vmin=0, vmax=N-1)\n", "    return cmx.ScalarMappable(norm=color_norm, cmap='Set3').to_rgba\n", "\n", "num_colr = 12\n", "cmap = get_cmap(num_colr)\n", "colr_list = [cmap(float(x)) for x in range(num_colr)]"]}, {"block": 38, "type": "code", "linesLength": 12, "startIndex": 140, "lines": ["def show_ground_truth(ax, im, bbox, clas=None, prs=None, thresh=0.3):\n", "    bb = [bb_hw(o) for o in bbox.reshape(-1,4)]\n", "    if prs is None:  prs  = [None]*len(bb)\n", "    if clas is None: clas = [None]*len(bb)\n", "    ax = show_img(im, ax=ax)\n", "    for i,(b,c,pr) in enumerate(zip(bb, clas, prs)):\n", "        if((b[2]>0) and (pr is None or pr > thresh)):\n", "            draw_rect(ax, b, color=colr_list[i%num_colr])\n", "            txt = f'{i}: '\n", "            if c is not None: txt += ('bg' if c==len(id2cat) else id2cat[c])\n", "            if pr is not None: txt += f' {pr:.2f}'\n", "            draw_text(ax, b[:2], txt, color=colr_list[i%num_colr])"]}, {"block": 39, "type": "code", "linesLength": 9, "startIndex": 152, "lines": ["class ConcatLblDataset(Dataset):\n", "    def __init__(self, ds, y2):\n", "        self.ds,self.y2 = ds,y2\n", "        self.sz = ds.sz\n", "    def __len__(self): return len(self.ds)\n", "    \n", "    def __getitem__(self, i):\n", "        x,y = self.ds[i]\n", "        return (x, (y,self.y2[i]))"]}, {"block": 40, "type": "code", "linesLength": 4, "startIndex": 161, "lines": ["trn_ds2 = ConcatLblDataset(md.trn_ds, trn_mcs)\n", "val_ds2 = ConcatLblDataset(md.val_ds, val_mcs)\n", "md.trn_dl.dataset = trn_ds2\n", "md.val_dl.dataset = val_ds2"]}, {"block": 41, "type": "code", "linesLength": 2, "startIndex": 165, "lines": ["x,y=to_np(next(iter(md.val_dl)))\n", "x=md.val_ds.ds.denorm(x)"]}, {"block": 42, "type": "code", "linesLength": 2, "startIndex": 167, "lines": ["x,y=to_np(next(iter(md.trn_dl)))\n", "x=md.trn_ds.ds.denorm(x)"]}, {"block": 43, "type": "code", "linesLength": 4, "startIndex": 169, "lines": ["fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n", "for i,ax in enumerate(axes.flat):\n", "    show_ground_truth(ax, x[i], y[0][i], y[1][i])\n", "plt.tight_layout()"]}, {"block": 44, "type": "markdown", "linesLength": 1, "startIndex": 173, "lines": ["### Set up model"]}, {"block": 45, "type": "code", "linesLength": 10, "startIndex": 174, "lines": ["anc_grid = 2\n", "k = 1\n", "\n", "anc_offset = 1/(anc_grid*2)\n", "anc_x = np.tile(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\n", "anc_y = np.repeat(np.linspace(anc_offset, 1-anc_offset, anc_grid), anc_grid)\n", "\n", "anc_ctrs = np.tile(np.stack([anc_x,anc_y], axis=1), (k,1))\n", "anc_sizes = np.array([[1/anc_grid,1/anc_grid] for i in range(anc_grid*anc_grid)])\n", "anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()"]}, {"block": 46, "type": "code", "linesLength": 1, "startIndex": 184, "lines": ["grid_sizes = V(np.array([1/anc_grid]), requires_grad=False).unsqueeze(1)"]}, {"block": 47, "type": "code", "linesLength": 3, "startIndex": 185, "lines": ["plt.scatter(anc_x, anc_y)\n", "plt.xlim(0, 1)\n", "plt.ylim(0, 1);"]}, {"block": 48, "type": "code", "linesLength": 1, "startIndex": 188, "lines": ["anchors"]}, {"block": 49, "type": "code", "linesLength": 1, "startIndex": 189, "lines": ["def hw2corners(ctr, hw): return torch.cat([ctr-hw/2, ctr+hw/2], dim=1)"]}, {"block": 50, "type": "code", "linesLength": 1, "startIndex": 190, "lines": ["anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])"]}, {"block": 51, "type": "code", "linesLength": 12, "startIndex": 191, "lines": ["def intersect(box_a, box_b):\n", "    max_xy = torch.min(box_a[:, None, 2:], box_b[None, :, 2:])\n", "    min_xy = torch.max(box_a[:, None, :2], box_b[None, :, :2])\n", "    inter = torch.clamp((max_xy - min_xy), min=0)\n", "    return inter[:, :, 0] * inter[:, :, 1]\n", "\n", "def box_sz(b): return ((b[:, 2]-b[:, 0]) * (b[:, 3]-b[:, 1]))\n", "\n", "def jaccard(box_a, box_b):\n", "    inter = intersect(box_a, box_b)\n", "    union = box_sz(box_a).unsqueeze(1) + box_sz(box_b).unsqueeze(0) - inter\n", "    return inter / union"]}, {"block": 52, "type": "code", "linesLength": 1, "startIndex": 203, "lines": ["n_clas = len(id2cat)+1"]}, {"block": 53, "type": "code", "linesLength": 1, "startIndex": 204, "lines": ["n_act = k*(4+n_clas)"]}, {"block": 54, "type": "code", "linesLength": 10, "startIndex": 205, "lines": ["class StdConv(nn.Module):\n", "    def __init__(self, nin, nout, stride=2, drop=0.1):\n", "        super().__init__()\n", "        self.conv = nn.Conv2d(nin, nout, 3, stride=stride, padding=1)\n", "        self.bn = nn.BatchNorm2d(nout)\n", "        self.drop = nn.Dropout(drop)\n", "        \n", "    def forward(self, x): return self.drop(self.bn(F.relu(self.conv(x))))\n", "        \n", "def flatten_conv(x,k): return x.view(x.size(0),x.size(1)//k,-1).transpose(1,2)"]}, {"block": 55, "type": "code", "linesLength": 11, "startIndex": 215, "lines": ["class OutConv(nn.Module):\n", "    def __init__(self, k, nin, bias):\n", "        super().__init__()\n", "        self.k = k\n", "        self.oconv1 = nn.Conv2d(nin, (len(id2cat)+1)*k, 3, padding=1)\n", "        self.oconv2 = nn.Conv2d(nin, 4*k, 3, padding=1)\n", "        self.oconv1.bias.data.zero_().add_(bias)\n", "        \n", "    def forward(self, x):\n", "        return [flatten_conv(self.oconv1(x), self.k),\n", "                flatten_conv(self.oconv2(x), self.k)]"]}, {"block": 56, "type": "code", "linesLength": 21, "startIndex": 226, "lines": ["class SSD_Head(nn.Module):\n", "    def __init__(self, k, bias):\n", "        super().__init__()\n", "        self.drop = nn.Dropout(0.25)\n", "        self.sconv0 = StdConv(512,256, stride=1)\n", "        self.sconv1 = StdConv(256,256)\n", "        self.sconv2 = StdConv(256,256)\n", "        self.out = OutConv(k, 256, bias)\n", "        \n", "    def forward(self, x):\n", "        x = self.drop(F.relu(x))\n", "        x = self.sconv0(x)\n", "        x = self.sconv1(x)\n", "        x = self.sconv2(x)\n", "        return self.out(x)\n", "\n", "head_reg4 = SSD_Head(k, -3.)\n", "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n", "learn = ConvLearner(md, models)\n", "learn.opt_fn = optim.Adam\n", "k"]}, {"block": 57, "type": "markdown", "linesLength": 1, "startIndex": 247, "lines": ["### Testing"]}, {"block": 58, "type": "code", "linesLength": 4, "startIndex": 248, "lines": ["x,y = next(iter(md.val_dl))\n", "x,y = V(x),V(y)\n", "batch = learn.model(V(x))\n", "b_clas,b_bb = batch"]}, {"block": 59, "type": "code", "linesLength": 1, "startIndex": 252, "lines": ["b_clas.size(),b_bb.size()"]}, {"block": 60, "type": "code", "linesLength": 6, "startIndex": 253, "lines": ["idx=7\n", "b_clasi = b_clas[idx]\n", "b_bboxi = b_bb[idx]\n", "ima=md.val_ds.ds.denorm(to_np(x))[idx]\n", "bbox,clas = get_y(y[0][idx], y[1][idx])\n", "bbox,clas"]}, {"block": 61, "type": "code", "linesLength": 3, "startIndex": 259, "lines": ["def torch_gt(ax, ima, bbox, clas, prs=None, thresh=0.4):\n", "    return show_ground_truth(ax, ima, to_np((bbox*224).long()),\n", "         to_np(clas), to_np(prs) if prs is not None else None, thresh)"]}, {"block": 62, "type": "code", "linesLength": 2, "startIndex": 262, "lines": ["fig, ax = plt.subplots(figsize=(7,7))\n", "torch_gt(ax, ima, bbox, clas)"]}, {"block": 63, "type": "code", "linesLength": 1, "startIndex": 264, "lines": ["a_ic = actn_to_bb(b_bboxi, anchors)"]}, {"block": 64, "type": "code", "linesLength": 2, "startIndex": 265, "lines": ["fig, ax = plt.subplots(figsize=(7,7))\n", "torch_gt(ax, ima, anchor_cnr, b_clasi.max(1)[1])"]}, {"block": 65, "type": "code", "linesLength": 2, "startIndex": 267, "lines": ["fig, ax = plt.subplots(figsize=(7,7))\n", "torch_gt(ax, ima, a_ic, b_clasi.max(1)[1], b_clasi.max(1)[0].sigmoid(), thresh=0.0)"]}, {"block": 66, "type": "code", "linesLength": 2, "startIndex": 269, "lines": ["overlaps = jaccard(bbox.data, anchor_cnr.data)\n", "overlaps"]}, {"block": 67, "type": "code", "linesLength": 1, "startIndex": 271, "lines": ["overlaps.max(1)"]}, {"block": 68, "type": "code", "linesLength": 1, "startIndex": 272, "lines": ["overlaps.max(0)"]}, {"block": 69, "type": "code", "linesLength": 2, "startIndex": 273, "lines": ["gt_overlap,gt_idx = map_to_ground_truth(overlaps)\n", "gt_overlap,gt_idx"]}, {"block": 70, "type": "code", "linesLength": 1, "startIndex": 275, "lines": ["gt_clas = clas[gt_idx]; gt_clas"]}, {"block": 71, "type": "code", "linesLength": 5, "startIndex": 276, "lines": ["thresh = 0.35\n", "pos = gt_overlap > thresh\n", "pos_idx = torch.nonzero(pos)[:,0]\n", "neg_idx = torch.nonzero(1-pos)[:,0]\n", "pos_idx"]}, {"block": 72, "type": "code", "linesLength": 1, "startIndex": 281, "lines": ["gt_clas[neg_idx] = len(id2cat); gt_clas"]}, {"block": 73, "type": "code", "linesLength": 4, "startIndex": 282, "lines": ["gt_bbox = bbox[gt_idx]\n", "loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n", "clas_loss  = F.cross_entropy(b_clasi, gt_clas)\n", "loc_loss,clas_loss"]}, {"block": 74, "type": "code", "linesLength": 9, "startIndex": 286, "lines": ["fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n", "for idx,ax in enumerate(axes.flat):\n", "    ima=md.val_ds.ds.denorm(to_np(x))[idx]\n", "    bbox,clas = get_y(y[0][idx], y[1][idx])\n", "    ima=md.val_ds.ds.denorm(to_np(x))[idx]\n", "    bbox,clas = get_y(bbox,clas); bbox,clas\n", "    a_ic = actn_to_bb(b_bb[idx], anchors)\n", "    torch_gt(ax, ima, a_ic, b_clas[idx].max(1)[1], b_clas[idx].max(1)[0].sigmoid(), 0.15)\n", "plt.tight_layout()"]}, {"block": 75, "type": "markdown", "linesLength": 1, "startIndex": 295, "lines": ["### Train"]}, {"block": 76, "type": "code", "linesLength": 18, "startIndex": 296, "lines": ["def one_hot_embedding(labels, num_classes):\n", "    return torch.eye(num_classes)[labels.data.cpu()]\n", "\n", "class BCE_Loss(nn.Module):\n", "    def __init__(self, num_classes):\n", "        super().__init__()\n", "        self.num_classes = num_classes\n", "\n", "    def forward(self, pred, targ):\n", "        t = one_hot_embedding(targ, self.num_classes+1)\n", "        t = V(t[:,:-1].contiguous())\n", "        x = pred[:,:-1]\n", "        w = self.get_weight(x,t)\n", "        return F.binary_cross_entropy_with_logits(x, t, w, size_average=False)/self.num_classes\n", "    \n", "    def get_weight(self,x,t): return None\n", "\n", "loss_f = BCE_Loss(len(id2cat))"]}, {"block": 77, "type": "code", "linesLength": 42, "startIndex": 314, "lines": ["def get_y(bbox,clas):\n", "    bbox = bbox.view(-1,4)/sz\n", "    bb_keep = ((bbox[:,2]-bbox[:,0])>0).nonzero()[:,0]\n", "    return bbox[bb_keep],clas[bb_keep]\n", "\n", "def actn_to_bb(actn, anchors):\n", "    actn_bbs = torch.tanh(actn)\n", "    actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]\n", "    actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\n", "    return hw2corners(actn_centers, actn_hw)\n", "\n", "def map_to_ground_truth(overlaps, print_it=False):\n", "    prior_overlap, prior_idx = overlaps.max(1)\n", "    if print_it: print(prior_overlap)\n", "    gt_overlap, gt_idx = overlaps.max(0)\n", "#     pdb.set_trace()\n", "    gt_overlap[prior_idx] = 1.99\n", "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n", "    return gt_overlap,gt_idx\n", "\n", "def ssd_1_loss(b_c,b_bb,bbox,clas,print_it=False):\n", "    bbox,clas = get_y(bbox,clas)\n", "    a_ic = actn_to_bb(b_bb, anchors)\n", "    overlaps = jaccard(bbox.data, anchor_cnr.data)\n", "    gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it)\n", "    gt_clas = clas[gt_idx]\n", "    pos = gt_overlap > 0.4\n", "    pos_idx = torch.nonzero(pos)[:,0]\n", "    gt_clas[1-pos] = len(id2cat)\n", "    gt_bbox = bbox[gt_idx]\n", "    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n", "    clas_loss  = loss_f(b_c, gt_clas)\n", "    return loc_loss, clas_loss\n", "\n", "def ssd_loss(pred,targ,print_it=False):\n", "    lcs,lls = 0.,0.\n", "    for b_c,b_bb,bbox,clas in zip(*pred,*targ):\n", "        loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,print_it)\n", "        lls += loc_loss\n", "        lcs += clas_loss\n", "    if print_it: print(lls,lcs)\n", "    return lls+lcs"]}, {"block": 78, "type": "code", "linesLength": 3, "startIndex": 356, "lines": ["x,y = next(iter(md.val_dl))\n", "x,y = V(x),V(y)\n", "batch = learn.model(V(x))"]}, {"block": 79, "type": "code", "linesLength": 1, "startIndex": 359, "lines": ["ssd_loss(batch, y, True)"]}, {"block": 80, "type": "code", "linesLength": 3, "startIndex": 360, "lines": ["learn.crit = ssd_loss\n", "lr = 3e-3\n", "lrs = np.array([lr/100,lr/10,lr])"]}, {"block": 81, "type": "code", "linesLength": 2, "startIndex": 363, "lines": ["learn.lr_find(lrs/1000,1.)\n", "learn.sched.plot(1)"]}, {"block": 82, "type": "code", "linesLength": 1, "startIndex": 365, "lines": ["learn.fit(lr, 1, cycle_len=1, use_clr=(20,3))"]}, {"block": 83, "type": "code", "linesLength": 1, "startIndex": 366, "lines": ["learn.fit(lr, 1, cycle_len=5, use_clr=(20,10))"]}, {"block": 84, "type": "code", "linesLength": 1, "startIndex": 367, "lines": ["learn.save('0')"]}, {"block": 85, "type": "markdown", "linesLength": 1, "startIndex": 368, "lines": ["## More anchors!"]}, {"block": 86, "type": "markdown", "linesLength": 1, "startIndex": 369, "lines": ["### Create anchors"]}, {"block": 87, "type": "code", "linesLength": 9, "startIndex": 370, "lines": ["anc_grids = [4,2,1]\n", "# anc_grids = [1]\n", "anc_zooms = [0.75, 1., 1.3]\n", "# anc_zooms = [1.]\n", "anc_ratios = [(1.,1.), (1.,0.5), (0.5,1.)]\n", "# anc_ratios = [(1.,1.)]\n", "anchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n", "k = len(anchor_scales)\n", "anc_offsets = [1/(o*2) for o in anc_grids]"]}, {"block": 88, "type": "code", "linesLength": 5, "startIndex": 379, "lines": ["anc_x = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n", "                        for ao,ag in zip(anc_offsets,anc_grids)])\n", "anc_y = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n", "                        for ao,ag in zip(anc_offsets,anc_grids)])\n", "anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)"]}, {"block": 89, "type": "code", "linesLength": 6, "startIndex": 384, "lines": ["anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n", "               for ag in anc_grids])\n", "grid_sizes = V(np.concatenate([np.array([ 1/ag       for i in range(ag*ag) for o,p in anchor_scales])\n", "               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\n", "anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\n", "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])"]}, {"block": 90, "type": "code", "linesLength": 2, "startIndex": 390, "lines": ["x,y=to_np(next(iter(md.val_dl)))\n", "x=md.val_ds.ds.denorm(x)"]}, {"block": 91, "type": "code", "linesLength": 1, "startIndex": 392, "lines": ["a=np.reshape((to_np(anchor_cnr) + to_np(torch.randn(*anchor_cnr.size()))*0.01)*224, -1)"]}, {"block": 92, "type": "code", "linesLength": 2, "startIndex": 393, "lines": ["fig, ax = plt.subplots(figsize=(7,7))\n", "show_ground_truth(ax, x[0], a)"]}, {"block": 93, "type": "markdown", "linesLength": 1, "startIndex": 395, "lines": ["### Model"]}, {"block": 94, "type": "code", "linesLength": 33, "startIndex": 396, "lines": ["drop=0.4\n", "\n", "class SSD_MultiHead(nn.Module):\n", "    def __init__(self, k, bias):\n", "        super().__init__()\n", "        self.drop = nn.Dropout(drop)\n", "        self.sconv1 = StdConv(512,256, drop=drop)\n", "        self.sconv2 = StdConv(256,256, drop=drop)\n", "        self.sconv3 = StdConv(256,256, drop=drop)\n", "        self.out0 = OutConv(k, 256, bias)\n", "        self.out1 = OutConv(k, 256, bias)\n", "        self.out2 = OutConv(k, 256, bias)\n", "        self.out3 = OutConv(k, 256, bias)\n", "\n", "    def forward(self, x):\n", "        x = self.drop(F.relu(x))\n", "        x = self.sconv1(x)\n", "        o1c,o1l = self.out1(x)\n", "        x = self.sconv2(x)\n", "        o2c,o2l = self.out2(x)\n", "        x = self.sconv3(x)\n", "        o3c,o3l = self.out3(x)\n", "        return [torch.cat([o1c,o2c,o3c], dim=1),\n", "                torch.cat([o1l,o2l,o3l], dim=1)]\n", "\n", "head_reg4 = SSD_MultiHead(k, -4.)\n", "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n", "learn = ConvLearner(md, models)\n", "learn.opt_fn = optim.Adam\n", "\n", "learn.crit = ssd_loss\n", "lr = 2e-3\n", "lrs = np.array([lr/100,lr/10,lr])"]}, {"block": 95, "type": "code", "linesLength": 3, "startIndex": 429, "lines": ["x,y = next(iter(md.val_dl))\n", "x,y = V(x),V(y)\n", "batch = learn.model(V(x))"]}, {"block": 96, "type": "code", "linesLength": 1, "startIndex": 432, "lines": ["batch[0].size(),batch[1].size()"]}, {"block": 97, "type": "code", "linesLength": 1, "startIndex": 433, "lines": ["ssd_loss(batch, y, True)"]}, {"block": 98, "type": "code", "linesLength": 1, "startIndex": 434, "lines": ["learn.lr_find(lrs/1000,1.)"]}, {"block": 99, "type": "code", "linesLength": 1, "startIndex": 435, "lines": ["learn.sched.plot()"]}, {"block": 100, "type": "code", "linesLength": 1, "startIndex": 436, "lines": ["learn.fit(lrs, 1, cycle_len=1, use_clr=(10,2))"]}, {"block": 101, "type": "code", "linesLength": 1, "startIndex": 437, "lines": ["learn.fit(lrs, 1, cycle_len=8, use_clr=(20,10))"]}, {"block": 102, "type": "code", "linesLength": 1, "startIndex": 438, "lines": ["learn.save('tmp')"]}, {"block": 103, "type": "code", "linesLength": 2, "startIndex": 439, "lines": ["learn.freeze_to(-2)\n", "learn.fit(lr, 1, cycle_len=10, use_clr=(10,10))"]}, {"block": 104, "type": "code", "linesLength": 13, "startIndex": 441, "lines": ["x,y = next(iter(md.val_dl))\n", "y = V(y)\n", "batch = learn.model(V(x))\n", "b_clas,b_bb = batch\n", "x = to_np(x)\n", "\n", "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n", "for idx,ax in enumerate(axes.flat):\n", "    ima=md.val_ds.ds.denorm(x)[idx]\n", "    bbox,clas = get_y(y[0][idx], y[1][idx])\n", "    a_ic = actn_to_bb(b_bb[idx], anchors)\n", "    torch_gt(ax, ima, a_ic, b_clas[idx].max(1)[1], b_clas[idx].max(1)[0].sigmoid(), 0.2)\n", "plt.tight_layout()"]}, {"block": 105, "type": "markdown", "linesLength": 1, "startIndex": 454, "lines": ["### Focal loss"]}, {"block": 106, "type": "code", "linesLength": 16, "startIndex": 455, "lines": ["def plot_results(thresh):\n", "    x,y = next(iter(md.val_dl))\n", "    y = V(y)\n", "    batch = learn.model(V(x))\n", "    b_clas,b_bb = batch\n", "\n", "    x = to_np(x)\n", "    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n", "    for idx,ax in enumerate(axes.flat):\n", "        ima=md.val_ds.ds.denorm(x)[idx]\n", "        bbox,clas = get_y(y[0][idx], y[1][idx])\n", "        a_ic = actn_to_bb(b_bb[idx], anchors)\n", "        clas_pr, clas_ids = b_clas[idx].max(1)\n", "        clas_pr = clas_pr.sigmoid()\n", "        torch_gt(ax, ima, a_ic, clas_ids, clas_pr, clas_pr.max().data[0]*thresh)\n", "    plt.tight_layout()"]}, {"block": 107, "type": "code", "linesLength": 9, "startIndex": 471, "lines": ["class FocalLoss(BCE_Loss):\n", "    def get_weight(self,x,t):\n", "        alpha,gamma = 0.25,2.\n", "        p = x.sigmoid()\n", "        pt = p*t + (1-p)*(1-t)\n", "        w = alpha*t + (1-alpha)*(1-t)\n", "        return w * (1-pt).pow(gamma)\n", "\n", "loss_f = FocalLoss(len(id2cat))"]}, {"block": 108, "type": "code", "linesLength": 4, "startIndex": 480, "lines": ["x,y = next(iter(md.val_dl))\n", "x,y = V(x),V(y)\n", "batch = learn.model(x)\n", "ssd_loss(batch, y, True)"]}, {"block": 109, "type": "code", "linesLength": 1, "startIndex": 484, "lines": ["learn.fit(lrs, 1, cycle_len=1, use_clr=(20,3))"]}, {"block": 110, "type": "code", "linesLength": 1, "startIndex": 485, "lines": ["learn.fit(lrs, 1, cycle_len=8, use_clr=(20,10))"]}, {"block": 111, "type": "code", "linesLength": 1, "startIndex": 486, "lines": ["learn.save('fl0')"]}, {"block": 112, "type": "code", "linesLength": 1, "startIndex": 487, "lines": ["plot_results(0.8)"]}, {"block": 113, "type": "code", "linesLength": 2, "startIndex": 488, "lines": ["learn.freeze_to(-2)\n", "learn.fit(lrs/2, 1, cycle_len=10, use_clr=(20,10))"]}, {"block": 114, "type": "code", "linesLength": 2, "startIndex": 490, "lines": ["learn.freeze_to(-2)\n", "learn.fit(lrs/4, 1, cycle_len=10, use_clr=(20,10))"]}, {"block": 115, "type": "code", "linesLength": 1, "startIndex": 492, "lines": ["learn.save('drop4')"]}, {"block": 116, "type": "code", "linesLength": 1, "startIndex": 493, "lines": ["learn.load('drop4')"]}, {"block": 117, "type": "code", "linesLength": 2, "startIndex": 494, "lines": ["learn.unfreeze()\n", "learn.fit(lrs/4, 1, cycle_len=10, use_clr=(20,10))"]}, {"block": 118, "type": "code", "linesLength": 1, "startIndex": 496, "lines": ["plot_results(0.8)"]}, {"block": 119, "type": "markdown", "linesLength": 1, "startIndex": 497, "lines": ["### NMS"]}, {"block": 120, "type": "code", "linesLength": 49, "startIndex": 498, "lines": ["def nms(boxes, scores, overlap=0.5, top_k=100):\n", "    keep = scores.new(scores.size(0)).zero_().long()\n", "    if boxes.numel() == 0: return keep\n", "    x1 = boxes[:, 0]\n", "    y1 = boxes[:, 1]\n", "    x2 = boxes[:, 2]\n", "    y2 = boxes[:, 3]\n", "    area = torch.mul(x2 - x1, y2 - y1)\n", "    v, idx = scores.sort(0)  # sort in ascending order\n", "    idx = idx[-top_k:]  # indices of the top-k largest vals\n", "    xx1 = boxes.new()\n", "    yy1 = boxes.new()\n", "    xx2 = boxes.new()\n", "    yy2 = boxes.new()\n", "    w = boxes.new()\n", "    h = boxes.new()\n", "\n", "    count = 0\n", "    while idx.numel() > 0:\n", "        i = idx[-1]  # index of current largest val\n", "        keep[count] = i\n", "        count += 1\n", "        if idx.size(0) == 1: break\n", "        idx = idx[:-1]  # remove kept element from view\n", "        # load bboxes of next highest vals\n", "        torch.index_select(x1, 0, idx, out=xx1)\n", "        torch.index_select(y1, 0, idx, out=yy1)\n", "        torch.index_select(x2, 0, idx, out=xx2)\n", "        torch.index_select(y2, 0, idx, out=yy2)\n", "        # store element-wise max with next highest score\n", "        xx1 = torch.clamp(xx1, min=x1[i])\n", "        yy1 = torch.clamp(yy1, min=y1[i])\n", "        xx2 = torch.clamp(xx2, max=x2[i])\n", "        yy2 = torch.clamp(yy2, max=y2[i])\n", "        w.resize_as_(xx2)\n", "        h.resize_as_(yy2)\n", "        w = xx2 - xx1\n", "        h = yy2 - yy1\n", "        # check sizes of xx1 and xx2.. after each iteration\n", "        w = torch.clamp(w, min=0.0)\n", "        h = torch.clamp(h, min=0.0)\n", "        inter = w*h\n", "        # IoU = i / (area(a) + area(b) - i)\n", "        rem_areas = torch.index_select(area, 0, idx)  # load remaining areas)\n", "        union = (rem_areas - inter) + area[i]\n", "        IoU = inter/union  # store result in iou\n", "        # keep only elements with an IoU <= overlap\n", "        idx = idx[IoU.le(overlap)]\n", "    return keep, count"]}, {"block": 121, "type": "code", "linesLength": 5, "startIndex": 547, "lines": ["x,y = next(iter(md.val_dl))\n", "y = V(y)\n", "batch = learn.model(V(x))\n", "b_clas,b_bb = batch\n", "x = to_np(x)"]}, {"block": 122, "type": "code", "linesLength": 8, "startIndex": 552, "lines": ["idx=1\n", "ima=md.val_ds.ds.denorm(x)[idx]\n", "bbox,clas = get_y(y[0][idx], y[1][idx])\n", "a_ic = actn_to_bb(b_bb[idx], anchors)\n", "clas_pr, clas_ids = b_clas[idx].max(1)\n", "clas_pr = clas_pr.sigmoid()\n", "\n", "conf_scores = b_clas[idx].sigmoid().t().data"]}, {"block": 123, "type": "code", "linesLength": 15, "startIndex": 560, "lines": ["out1,out2,cc = [],[],[]\n", "for cl in range(0, len(conf_scores)-1):\n", "    c_mask = conf_scores[cl] > 0.25\n", "    if c_mask.sum() == 0: continue\n", "    scores = conf_scores[cl][c_mask]\n", "    l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n", "    boxes = a_ic[l_mask].view(-1, 4)\n", "    ids, count = nms(boxes.data, scores, 0.4, 50)\n", "    ids = ids[:count]\n", "    out1.append(scores[ids])\n", "    out2.append(boxes.data[ids])\n", "    cc.append([cl]*count)\n", "cc = T(np.concatenate(cc))\n", "out1 = torch.cat(out1)\n", "out2 = torch.cat(out2)"]}, {"block": 124, "type": "code", "linesLength": 2, "startIndex": 575, "lines": ["fig, ax = plt.subplots(figsize=(8,8))\n", "torch_gt(ax, ima, out2, cc, out1, 0.1)"]}, {"block": 125, "type": "markdown", "linesLength": 1, "startIndex": 577, "lines": ["## End"]}, {"block": 126, "type": "code", "linesLength": 0, "startIndex": 578, "lines": []}]