[{"block": 0, "type": "markdown", "linesLength": 1, "startIndex": 0, "lines": ["## Image Cleaner Widget"]}, {"block": 1, "type": "markdown", "linesLength": 1, "startIndex": 1, "lines": ["fastai offers several widgets to support the workflow of a deep learning practitioner. The purpose of the widgets are to help you organize, clean, and prepare your data for your model. Widgets are separated by data type."]}, {"block": 2, "type": "code", "linesLength": 3, "startIndex": 2, "lines": ["from fastai.vision import *\n", "from fastai.widgets import *\n", "from fastai.gen_doc.nbdoc import *"]}, {"block": 3, "type": "code", "linesLength": 2, "startIndex": 5, "lines": ["%reload_ext autoreload\n", "%autoreload 2"]}, {"block": 4, "type": "code", "linesLength": 2, "startIndex": 7, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "data = ImageDataBunch.from_folder(path)"]}, {"block": 5, "type": "code", "linesLength": 1, "startIndex": 9, "lines": ["learn = cnn_learner(data, models.resnet18, metrics=error_rate)"]}, {"block": 6, "type": "code", "linesLength": 1, "startIndex": 10, "lines": ["learn.fit_one_cycle(2)"]}, {"block": 7, "type": "code", "linesLength": 1, "startIndex": 11, "lines": ["learn.save('stage-1')"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 12, "lines": ["We create a databunch with all the data in the training set and no validation set (DatasetFormatter uses only the training set)"]}, {"block": 9, "type": "code", "linesLength": 4, "startIndex": 13, "lines": ["db = (ImageList.from_folder(path)\n", "                   .split_none()\n", "                   .label_from_folder()\n", "                   .databunch())"]}, {"block": 10, "type": "code", "linesLength": 2, "startIndex": 17, "lines": ["learn = cnn_learner(db, models.resnet18, metrics=[accuracy])\n", "learn.load('stage-1');"]}, {"block": 11, "type": "code", "linesLength": 1, "startIndex": 19, "lines": ["show_doc(DatasetFormatter)"]}, {"block": 12, "type": "markdown", "linesLength": 1, "startIndex": 20, "lines": ["The [`DatasetFormatter`](/widgets.image_cleaner.html#DatasetFormatter) class prepares your image dataset for widgets by returning a formatted [`DatasetTfm`](/vision.data.html#DatasetTfm) based on the [`DatasetType`](/basic_data.html#DatasetType) specified. Use `from_toplosses` to grab the most problematic images directly from your learner. Optionally, you can restrict the formatted dataset returned to `n_imgs`."]}, {"block": 13, "type": "code", "linesLength": 1, "startIndex": 21, "lines": ["show_doc(DatasetFormatter.from_similars)"]}, {"block": 14, "type": "code", "linesLength": 1, "startIndex": 22, "lines": ["show_doc(DatasetFormatter.from_toplosses)"]}, {"block": 15, "type": "code", "linesLength": 1, "startIndex": 23, "lines": ["show_doc(DatasetFormatter.from_most_unsure)"]}, {"block": 16, "type": "code", "linesLength": 1, "startIndex": 24, "lines": ["show_doc(ImageCleaner)"]}, {"block": 17, "type": "markdown", "linesLength": 1, "startIndex": 25, "lines": ["[`ImageCleaner`](/widgets.image_cleaner.html#ImageCleaner) is for cleaning up images that don't belong in your dataset. It renders images in a row and gives you the opportunity to delete the file from your file system. To use [`ImageCleaner`](/widgets.image_cleaner.html#ImageCleaner) we must first use `DatasetFormatter().from_toplosses` to get the suggested indices for misclassified images."]}, {"block": 18, "type": "code", "linesLength": 1, "startIndex": 26, "lines": ["ds, idxs = DatasetFormatter().from_toplosses(learn)"]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 27, "lines": ["ImageCleaner(ds, idxs, path)"]}, {"block": 20, "type": "markdown", "linesLength": 1, "startIndex": 28, "lines": ["[`ImageCleaner`](/widgets.image_cleaner.html#ImageCleaner) does not change anything on disk (neither labels or existence of images). Instead, it creates a 'cleaned.csv' file in your data path from which you need to load your new databunch for the files to changes to be applied. "]}, {"block": 21, "type": "code", "linesLength": 1, "startIndex": 29, "lines": ["df = pd.read_csv(path/'cleaned.csv', header='infer')"]}, {"block": 22, "type": "code", "linesLength": 6, "startIndex": 30, "lines": ["# We create a databunch from our csv. We include the data in the training set and we don't use a validation set (DatasetFormatter uses only the training set)\n", "np.random.seed(42)\n", "db = (ImageList.from_df(df, path)\n", "                   .split_none()\n", "                   .label_from_df()\n", "                   .databunch(bs=64))"]}, {"block": 23, "type": "code", "linesLength": 2, "startIndex": 36, "lines": ["learn = cnn_learner(db, models.resnet18, metrics=error_rate)\n", "learn = learn.load('stage-1')"]}, {"block": 24, "type": "markdown", "linesLength": 1, "startIndex": 38, "lines": ["You can then use [`ImageCleaner`](/widgets.image_cleaner.html#ImageCleaner) again to find duplicates in the dataset. To do this, you can specify `duplicates=True` while calling ImageCleaner after getting the indices and dataset from `.from_similars`. Note that if you are using a layer's output which has dimensions <code>(n_batches, n_features, 1, 1)</code> then you don't need any pooling (this is the case with the last layer). The suggested use of `.from_similars()` with resnets is using the last layer and no pooling, like in the following cell."]}, {"block": 25, "type": "code", "linesLength": 1, "startIndex": 39, "lines": ["ds, idxs = DatasetFormatter().from_similars(learn, layer_ls=[0,7,1], pool=None)"]}, {"block": 26, "type": "code", "linesLength": 1, "startIndex": 40, "lines": ["ImageCleaner(ds, idxs, path, duplicates=True)"]}, {"block": 27, "type": "code", "linesLength": 1, "startIndex": 41, "lines": ["show_doc(PredictionsCorrector)"]}, {"block": 28, "type": "markdown", "linesLength": 1, "startIndex": 42, "lines": ["In competitions, you need to provide predictions for the test set, for which true labels are unknown. You can slightly improve your score by manually correcting the most egregious misclassifications. Test set in competitions is usually large and cannot be inspected manually in its entirety. A good subset to look at is the images the model is the least sure about, i.e. the difference in probabilities between the most probable and the second most probable classes is minimal."]}, {"block": 29, "type": "markdown", "linesLength": 1, "startIndex": 43, "lines": ["Let's start by creating an artificial test set and training a model:"]}, {"block": 30, "type": "code", "linesLength": 3, "startIndex": 44, "lines": ["db_test = ImageDataBunch.from_folder(path/'train', valid_pct = 0.2, test = '../valid')\n", "learn = cnn_learner(db_test, models.resnet18, metrics=[accuracy])\n", "learn.fit_one_cycle(2)"]}, {"block": 31, "type": "markdown", "linesLength": 1, "startIndex": 47, "lines": ["Now we can take a look at the most unsure images:"]}, {"block": 32, "type": "code", "linesLength": 2, "startIndex": 48, "lines": ["most_unsure = DatasetFormatter.from_most_unsure(learn)\n", "wgt = PredictionsCorrector(*most_unsure)"]}, {"block": 33, "type": "markdown", "linesLength": 1, "startIndex": 50, "lines": ["![PredictionsCorrector](imgs/PredictionsCorrector.gif)"]}, {"block": 34, "type": "code", "linesLength": 1, "startIndex": 51, "lines": ["show_doc(PredictionsCorrector.show_corrections)"]}, {"block": 35, "type": "markdown", "linesLength": 1, "startIndex": 52, "lines": ["When you finished interacting with a widget, you can take a look at the corrections that were made. `show_corrections` displays image's index in the test set, previous label and the new label."]}, {"block": 36, "type": "code", "linesLength": 1, "startIndex": 53, "lines": ["wgt.show_corrections(ncols=6, figsize=(9, 7))"]}, {"block": 37, "type": "code", "linesLength": 1, "startIndex": 54, "lines": ["show_doc(PredictionsCorrector.corrected_labels)"]}, {"block": 38, "type": "code", "linesLength": 1, "startIndex": 55, "lines": ["show_doc(ImageDownloader)"]}, {"block": 39, "type": "markdown", "linesLength": 5, "startIndex": 56, "lines": ["[`ImageDownloader`](/widgets.image_downloader.html#ImageDownloader) widget gives you a way to quickly bootstrap your image dataset without leaving the notebook. It searches and downloads images that match the search criteria and resolution / quality requirements and stores them on your filesystem within the provided `path`.\n", "\n", "Images for each search query (or label) are stored in a separate folder within `path`. For example, if you pupulate `tiger` with a `path` setup to `./data`, you'll get a folder `./data/tiger/` with the tiger images in it.\n", "\n", "[`ImageDownloader`](/widgets.image_downloader.html#ImageDownloader) will automatically clean up and verify the downloaded images with [`verify_images()`](/vision.data.html#verify_images) after downloading them."]}, {"block": 40, "type": "code", "linesLength": 3, "startIndex": 61, "lines": ["path = Config.data_path()/'image_downloader'\n", "os.makedirs(path, exist_ok=True)\n", "ImageDownloader(path)"]}, {"block": 41, "type": "markdown", "linesLength": 1, "startIndex": 64, "lines": ["#### Downloading images in python scripts outside Jupyter notebooks"]}, {"block": 42, "type": "code", "linesLength": 4, "startIndex": 65, "lines": ["path = Config.data_path()/'image_downloader'\n", "files = download_google_images(path, 'aussie shepherd', size='>1024*768', n_images=30)\n", "\n", "len(files)"]}, {"block": 43, "type": "code", "linesLength": 1, "startIndex": 69, "lines": ["show_doc(download_google_images)"]}, {"block": 44, "type": "markdown", "linesLength": 1, "startIndex": 70, "lines": ["After populating images with [`ImageDownloader`](/widgets.image_downloader.html#ImageDownloader), you can get a an [`ImageDataBunch`](/vision.data.html#ImageDataBunch) by calling `ImageDataBunch.from_folder(path, size=size)`, or using the data block API."]}, {"block": 45, "type": "code", "linesLength": 18, "startIndex": 71, "lines": ["# Setup path and labels to search for\n", "path = Config.data_path()/'image_downloader'\n", "labels = ['boston terrier', 'french bulldog']\n", "\n", "# Download images\n", "for label in labels: \n", "    download_google_images(path, label, size='>400*300', n_images=50)\n", "\n", "# Build a databunch and train! \n", "src = (ImageList.from_folder(path)\n", "       .split_by_rand_pct()\n", "       .label_from_folder()\n", "       .transform(get_transforms(), size=224))\n", "\n", "db  = src.databunch(bs=16, num_workers=0)\n", "\n", "learn = cnn_learner(db, models.resnet34, metrics=[accuracy])\n", "learn.fit_one_cycle(3)"]}, {"block": 46, "type": "markdown", "linesLength": 15, "startIndex": 89, "lines": ["#### Downloading more than a hundred images\n", "\n", "To fetch more than a hundred images, [`ImageDownloader`](/widgets.image_downloader.html#ImageDownloader) uses `selenium` and `chromedriver` to scroll through the Google Images search results page and scrape image URLs. They're not required as dependencies by default. If you don't have them installed on your system, the widget will show you an error message.\n", "\n", "To install `selenium`, just `pip install selenium` in your fastai environment.\n", "\n", "**On a mac**, you can install `chromedriver` with `brew cask install chromedriver`.\n", "\n", "**On Ubuntu**\n", "Take a look at the latest Chromedriver version available, then something like:\n", "\n", "```\n", "wget https://chromedriver.storage.googleapis.com/2.45/chromedriver_linux64.zip\n", "unzip chromedriver_linux64.zip\n", "```"]}, {"block": 47, "type": "markdown", "linesLength": 20, "startIndex": 104, "lines": ["Note that downloading under 100 images doesn't require any dependencies other than fastai itself, however downloading more than a hundred images [uses `selenium` and `chromedriver`](/widgets.image_cleaner.html#Downloading-more-than-a-hundred-images).\n", "\n", "`size` can be one of:\n", "\n", "```\n", "'>400*300'\n", "'>640*480'\n", "'>800*600'\n", "'>1024*768'\n", "'>2MP'\n", "'>4MP'\n", "'>6MP'\n", "'>8MP'\n", "'>10MP'\n", "'>12MP'\n", "'>15MP'\n", "'>20MP'\n", "'>40MP'\n", "'>70MP'\n", "```"]}, {"block": 48, "type": "markdown", "linesLength": 1, "startIndex": 124, "lines": ["## Methods"]}, {"block": 49, "type": "markdown", "linesLength": 1, "startIndex": 125, "lines": ["## Undocumented Methods - Methods moved below this line will intentionally be hidden"]}, {"block": 50, "type": "code", "linesLength": 1, "startIndex": 126, "lines": ["show_doc(DatasetFormatter.get_toplosses_idxs)"]}, {"block": 51, "type": "code", "linesLength": 1, "startIndex": 127, "lines": ["show_doc(DatasetFormatter.padded_ds)"]}, {"block": 52, "type": "code", "linesLength": 1, "startIndex": 128, "lines": ["show_doc(DatasetFormatter.get_similars_idxs)"]}, {"block": 53, "type": "code", "linesLength": 1, "startIndex": 129, "lines": ["show_doc(DatasetFormatter.get_actns)"]}, {"block": 54, "type": "code", "linesLength": 1, "startIndex": 130, "lines": ["show_doc(DatasetFormatter.comb_similarity)"]}, {"block": 55, "type": "code", "linesLength": 1, "startIndex": 131, "lines": ["show_doc(DatasetFormatter.largest_indices)"]}, {"block": 56, "type": "code", "linesLength": 1, "startIndex": 132, "lines": ["show_doc(DatasetFormatter.sort_idxs)"]}, {"block": 57, "type": "code", "linesLength": 1, "startIndex": 133, "lines": ["show_doc(ImageCleaner.make_img_widget)"]}, {"block": 58, "type": "code", "linesLength": 1, "startIndex": 134, "lines": ["show_doc(ImageCleaner.make_button_widget)"]}, {"block": 59, "type": "code", "linesLength": 1, "startIndex": 135, "lines": ["show_doc(ImageCleaner.make_dropdown_widget)"]}, {"block": 60, "type": "code", "linesLength": 1, "startIndex": 136, "lines": ["show_doc(ImageCleaner.make_horizontal_box)"]}, {"block": 61, "type": "code", "linesLength": 1, "startIndex": 137, "lines": ["show_doc(ImageCleaner.make_vertical_box)"]}, {"block": 62, "type": "code", "linesLength": 1, "startIndex": 138, "lines": ["show_doc(ImageCleaner.create_image_list)"]}, {"block": 63, "type": "code", "linesLength": 1, "startIndex": 139, "lines": ["show_doc(ImageCleaner.next_batch)"]}, {"block": 64, "type": "code", "linesLength": 1, "startIndex": 140, "lines": ["show_doc(ImageCleaner.make_payload)"]}, {"block": 65, "type": "code", "linesLength": 1, "startIndex": 141, "lines": ["show_doc(ImageCleaner.before_next_batch)"]}, {"block": 66, "type": "code", "linesLength": 1, "startIndex": 142, "lines": ["show_doc(ImageCleaner.get_widgets)"]}, {"block": 67, "type": "code", "linesLength": 1, "startIndex": 143, "lines": ["show_doc(ImageCleaner.relabel)"]}, {"block": 68, "type": "code", "linesLength": 1, "startIndex": 144, "lines": ["show_doc(ImageCleaner.on_delete)"]}, {"block": 69, "type": "code", "linesLength": 1, "startIndex": 145, "lines": ["show_doc(ImageCleaner.delete_image)"]}, {"block": 70, "type": "code", "linesLength": 1, "startIndex": 146, "lines": ["show_doc(ImageCleaner.batch_contains_deleted)"]}, {"block": 71, "type": "code", "linesLength": 1, "startIndex": 147, "lines": ["show_doc(ImageCleaner.write_csv)"]}, {"block": 72, "type": "code", "linesLength": 1, "startIndex": 148, "lines": ["show_doc(ImageCleaner.render)"]}, {"block": 73, "type": "code", "linesLength": 1, "startIndex": 149, "lines": ["show_doc(PredictionsCorrector.make_payload)"]}, {"block": 74, "type": "code", "linesLength": 1, "startIndex": 150, "lines": ["show_doc(PredictionsCorrector.render)"]}, {"block": 75, "type": "code", "linesLength": 1, "startIndex": 151, "lines": ["show_doc(PredictionsCorrector.get_widgets)"]}, {"block": 76, "type": "code", "linesLength": 1, "startIndex": 152, "lines": ["show_doc(PredictionsCorrector.relabel)"]}, {"block": 77, "type": "markdown", "linesLength": 1, "startIndex": 153, "lines": ["## New Methods - Please document or move to the undocumented section"]}]