[{"block": 0, "type": "markdown", "linesLength": 5, "startIndex": 0, "lines": ["# Running SAR on MovieLens (Python)\n", "\n", "SAR is a fast scalable adaptive algorithm for personalized recommendations based on user transaction history and item descriptions. It produces easily explainable / interpretable recommendations and handles \"cold item\" and \"semi-cold user\" scenarios. \n", "\n", "This notebook provides an example of how to utilize and evaluate SAR in Python on a CPU."]}, {"block": 1, "type": "code", "linesLength": 14, "startIndex": 5, "lines": ["# set the environment path to find Recommenders\n", "import sys\n", "sys.path.append(\"../../\")\n", "\n", "from utilities.recommender.sar.sar_singlenode import SARSingleNodeReference\n", "from utilities.dataset.url_utils import maybe_download\n", "from utilities.dataset.python_splitters import python_random_split\n", "from utilities.evaluation.python_evaluation import PythonRatingEvaluation, PythonRankingEvaluation\n", "\n", "import itertools\n", "import pandas as pd\n", "\n", "print(\"System version: {}\".format(sys.version))\n", "print(\"Pandas version: {}\".format(pd.__version__))"]}, {"block": 2, "type": "markdown", "linesLength": 1, "startIndex": 19, "lines": ["### 1. Download the MovieLens dataset"]}, {"block": 3, "type": "code", "linesLength": 1, "startIndex": 20, "lines": ["filepath = maybe_download(\"http://files.grouplens.org/datasets/movielens/ml-100k/u.data\", \"ml-100k.data\")"]}, {"block": 4, "type": "code", "linesLength": 2, "startIndex": 21, "lines": ["data = pd.read_csv(filepath, sep=\"\\t\", names=[\"UserId\", \"MovieId\", \"Rating\", \"Timestamp\"])\n", "data.head()"]}, {"block": 5, "type": "markdown", "linesLength": 1, "startIndex": 23, "lines": ["### 2. Split the data using the python random splitter provided in utilities:"]}, {"block": 6, "type": "code", "linesLength": 1, "startIndex": 24, "lines": ["train, test = python_random_split(data)"]}, {"block": 7, "type": "code", "linesLength": 11, "startIndex": 25, "lines": ["header = {\n", "        \"col_user\": \"UserId\",\n", "        \"col_item\": \"MovieId\",\n", "        \"col_rating\": \"Rating\",\n", "        \"col_timestamp\": \"Timestamp\",\n", "    }\n", "\n", "model = SARSingleNodeReference(\n", "                remove_seen=True, similarity_type=\"jaccard\", \n", "                time_decay_coefficient=30, time_now=None, timedecay_formula=True, **header\n", "            )"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 36, "lines": ["### 3. In order to use SAR, we need to hash users and items"]}, {"block": 9, "type": "code", "linesLength": 2, "startIndex": 37, "lines": ["unique_users = data[\"UserId\"].unique()\n", "unique_items = data[\"MovieId\"].unique()"]}, {"block": 10, "type": "markdown", "linesLength": 3, "startIndex": 39, "lines": ["We will hash users and items to smaller continuous space.\n", "This is an ordered set - it's discrete, but contiguous.\n", "This helps keep the matrices we keep in memory as small as possible."]}, {"block": 11, "type": "code", "linesLength": 4, "startIndex": 42, "lines": ["enumerate_items_1, enumerate_items_2 = itertools.tee(enumerate(unique_items))\n", "enumerate_users_1, enumerate_users_2 = itertools.tee(enumerate(unique_users))\n", "item_map_dict = {x: i for i, x in enumerate_items_1}\n", "user_map_dict = {x: i for i, x in enumerate_users_1}"]}, {"block": 12, "type": "markdown", "linesLength": 1, "startIndex": 46, "lines": ["The reverse of the dictionary above - array index to actual ID\n"]}, {"block": 13, "type": "code", "linesLength": 2, "startIndex": 47, "lines": ["index2user = dict(enumerate_users_2)\n", "index2item = dict(enumerate_items_2)"]}, {"block": 14, "type": "markdown", "linesLength": 1, "startIndex": 49, "lines": ["We need to index the train and test sets for SAR matrix operations to work"]}, {"block": 15, "type": "code", "linesLength": 1, "startIndex": 50, "lines": ["model.set_index(unique_users, unique_items, user_map_dict, item_map_dict, index2user, index2item)"]}, {"block": 16, "type": "markdown", "linesLength": 1, "startIndex": 51, "lines": ["### 4. Train the SAR model on our training data, and get the top-k recommendations for our testing data"]}, {"block": 17, "type": "code", "linesLength": 2, "startIndex": 52, "lines": ["model.fit(train)\n", "top_k = model.recommend_k_items(test)"]}, {"block": 18, "type": "code", "linesLength": 3, "startIndex": 54, "lines": ["# TODO: remove this call when the model returns same type as input\n", "top_k['UserId'] = pd.to_numeric(top_k['UserId'])\n", "top_k['MovieId'] = pd.to_numeric(top_k['MovieId'])"]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 57, "lines": ["display(top_k.head())"]}, {"block": 20, "type": "markdown", "linesLength": 1, "startIndex": 58, "lines": ["### 5. Evaluate how well SAR performs "]}, {"block": 21, "type": "code", "linesLength": 1, "startIndex": 59, "lines": ["test.head()"]}, {"block": 22, "type": "code", "linesLength": 3, "startIndex": 60, "lines": ["rank_eval = PythonRankingEvaluation(test, top_k, col_user=\"UserId\", col_item=\"MovieId\", \n", "                                    col_rating=\"Rating\", col_prediction=\"prediction\", \n", "                                    relevancy_method=\"top_k\")"]}, {"block": 23, "type": "code", "linesLength": 6, "startIndex": 63, "lines": ["print(\"Model:\\t\" + model.model_str,\n", "      \"Top K:\\t%d\" % rank_eval.top_k,\n", "      \"MAP:\\t%f\" % rank_eval.map_at_k(),\n", "      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n", "      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n", "      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n')"]}, {"block": 24, "type": "code", "linesLength": 0, "startIndex": 69, "lines": []}]