[{"block": 0, "type": "markdown", "linesLength": 15, "startIndex": 0, "lines": ["# Movie recommender with multinomial RBM (Tensorflow, GPU)\n", "\n", "A Restricted Boltzmann Machine (RBM) is a generative neural network model typically used to perform unsupervised learning. The main task of an RBM is to learn the joint probability distribution $P(v,h)$, where $v$ are the visible units and $h$ the hidden ones. The hidden units represent latent variables while the visible units are clamped on the input data. Once the joint distribution is learnt, new examples are generated by sampling from it.  \n", "\n", "In this notebook, we provide an example of how to utilize the RBM to perform user/item recommendations. In particular, we use as a case study the [movielens dataset](https://movielens.org), comprising user's ranking of movies on a scale of 1 to 5. \n", "\n", "This notebook provides a quick start, showing the basic steps needed to use and evaluate the algorithm. A detailed discussion of the RBM model together with a deeper analysis of the recommendation task is provided in the [RBM Deep Dive section](../02_model/rbm_deep_dive.ipynb). The RBM implementation presented here is based on the article by Ruslan Salakhutdinov, Andriy Mnih and Geoffrey Hinton [Restricted Boltzmann Machines for Collaborative Filtering](https://www.cs.toronto.edu/~rsalakhu/papers/rbmcf.pdf) with the exception that here we use multinomial units instead of the one-hot encoded used in the paper.  \n", "\n", "### Advantages of RBM: \n", "\n", "The model generates ratings for a user/movie pair using a collaborative filtering based approach. While matrix factorization methods learn how to reproduce an instance of the user/item affinity matrix, the RBM learns the underlying probability distribution. This has several advantages: \n", "\n", "- Generalizability : the model generalize well to new examples.\n", "- Stability in time: if the recommendation task is time-stationary, the model does not need to be trained often to accomodate new ratings/users. \n", "- The tensorflow implementation presented here allows fast training on GPU "]}, {"block": 1, "type": "markdown", "linesLength": 1, "startIndex": 15, "lines": ["## 0 Global Settings and Import"]}, {"block": 2, "type": "code", "linesLength": 32, "startIndex": 16, "lines": ["#load libraries\n", "\n", "from __future__ import print_function\n", "from __future__ import absolute_import\n", "from __future__ import division\n", "\n", "# set the environment path to find Recommenders\n", "import sys\n", "sys.path.append(\"../../\")\n", "\n", "import os\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "import papermill as pm\n", "\n", "from reco_utils.recommender.rbm.rbm import RBM\n", "from reco_utils.dataset.numpy_splitters import numpy_stratified_split\n", "from reco_utils.dataset.sparse import AffinityMatrix\n", "\n", "\n", "from reco_utils.dataset import movielens\n", "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n", "\n", "#For interactive mode only\n", "%load_ext autoreload\n", "%autoreload 2\n", "\n", "print(\"System version: {}\".format(sys.version))\n", "print(\"Pandas version: {}\".format(pd.__version__))"]}, {"block": 3, "type": "markdown", "linesLength": 3, "startIndex": 48, "lines": ["# 1 Load Data \n", "\n", "Here we select the size of the movielens dataset. In this example we consider the 100k ratings datasets, provided by  943 users on 1682 movies. The data are imported in a pandas dataframe including the user ID, the item ID, the ratings and a timestamp denoting when a particular user rated a particular item.  "]}, {"block": 4, "type": "code", "linesLength": 2, "startIndex": 51, "lines": ["# Select Movielens data size: 100k, 1m, 10m, or 20m\n", "MOVIELENS_DATA_SIZE = '100k'"]}, {"block": 5, "type": "code", "linesLength": 9, "startIndex": 53, "lines": ["data = movielens.load_pandas_df(\n", "    size=MOVIELENS_DATA_SIZE,\n", "    header=['userID','movieID','rating','timestamp']\n", ")\n", "\n", "# Convert to 32-bit in order to reduce memory consumption \n", "data.loc[:, 'rating'] = data['rating'].astype(np.int32) \n", "\n", "data.head()"]}, {"block": 6, "type": "markdown", "linesLength": 3, "startIndex": 62, "lines": ["### 1.2 Split the data using the stratified splitter  \n", "\n", "As a second step we generate the user/item affiity matrix and then split the data into train and test set. If you are familiar with training supervised learning model, here you will notice the first difference. In the former case, we cut off a certain proportion of training examples from dataset (e.g. images), here corresponding to users (or items), ending up with two matrices (train and test) having different row dimensions. Here we need to mantain the same matrix size for the train and test set, but the two will contain different amounts of ratings, see the [deep dive notebook](../02_model/rbm_deep_dive.ipynb) for more details. The affinity matrix reads     "]}, {"block": 7, "type": "code", "linesLength": 12, "startIndex": 65, "lines": ["#to use standard names across the analysis \n", "header = {\n", "        \"col_user\": \"userID\",\n", "        \"col_item\": \"movieID\",\n", "        \"col_rating\": \"rating\",\n", "    }\n", "\n", "#instantiate the sparse matrix generation  \n", "am = AffinityMatrix(DF = data, **header)\n", "\n", "#obtain the sparse matrix \n", "X = am.gen_affinity_matrix()"]}, {"block": 8, "type": "markdown", "linesLength": 3, "startIndex": 77, "lines": ["The method also returns informations on the sparsness of the dataset and the size of the user/affinity matrix. The former is given by the ratio between the unrated elements and the total number of matrix elements. This is what makes a recommendation task hard: we try to predict 93% of the missing data with only 7% of information!\n", "\n", "We split the matrix using the default ration of 0.75, i.e. 75% of the ratings will constitute the train set."]}, {"block": 9, "type": "code", "linesLength": 1, "startIndex": 80, "lines": ["Xtr, Xtst = numpy_stratified_split(X)"]}, {"block": 10, "type": "markdown", "linesLength": 6, "startIndex": 81, "lines": ["The splitter returns:\n", "\n", "- Xtr: a matrix containing the train set ratings \n", "- Xtst: a matrix containing the test elements \n", "\n", "Note that the train/test matrices have exactly the same dimension, but different entries as it can be explicitly verified:"]}, {"block": 11, "type": "code", "linesLength": 2, "startIndex": 87, "lines": ["print('train matrix size', Xtr.shape)\n", "print('test matrix size', Xtst.shape)"]}, {"block": 12, "type": "markdown", "linesLength": 9, "startIndex": 89, "lines": ["## 2 Train the RBM model\n", "\n", "The model has been implemented as a Tensorflow (TF) class. TF does not support probabilistic models natively, so the implementation of the algorithm has a different structure than the one you may be used to see in popular supervised models. The class has been implemented in such a way that the TF session is hidden inside the `fit()` method and no explicit call is needed. The algorithm operates in three different steps: \n", "\n", "- Model initialization: This is where we tell TF how to build the computational graph. The main parameters to specify are the number of hidden units, the number of training epochs and the minibatch size. Other parameters can be optionally tweaked for experimentation and to achieve better performance, as explained in the [RBM Deep Dive section](../02_model/rbm_deep_dive.ipynb).\n", "\n", "- Model fit: This is where we train the model on the data. The method takes two arguments: the training and test set matrices. Note that the model is trained **only** on the training set, the test set is used to display the generalization accuracy of the trained model, useful to have an idea of how to fix the hyper parameters. \n", "\n", "- Model prediction: This is where we generate ratings for the unseen items. Once the model has been trained and we are satisfied with its overall accuracy, we sample new ratings from the learned distribution. In particular, we extract the top_k (e.g. 10) most relevant recommendations according to some predefined score. The prediction is then returned in a dataframe format ready to be analysed and deployed.  "]}, {"block": 13, "type": "code", "linesLength": 2, "startIndex": 98, "lines": ["#First we initialize the model class\n", "model = RBM(hidden_units= 600, training_epoch = 30, minibatch_size= 60, keep_prob=0.9,with_metrics =True)"]}, {"block": 14, "type": "markdown", "linesLength": 1, "startIndex": 100, "lines": ["Note that the first time the fit method is called it may take longer to return the result. This is due to the fact that TF needs to initialized the GPU session. You will notice that this is not the case when training the algorithm the second or more times.   "]}, {"block": 15, "type": "code", "linesLength": 2, "startIndex": 101, "lines": ["#Model Fit\n", "train_time= model.fit(Xtr, Xtst)"]}, {"block": 16, "type": "markdown", "linesLength": 3, "startIndex": 103, "lines": ["During training, we can optionlly evauate the root mean squared error to have an idea of how the learning is proceeding. We would generally like to see this quantity decreasing as a function of the learning epochs. To visualise this choose `with_metrics = True` in the `RBM()` model function. \n", "\n", "Once the model has been trained, we can predict new ratings on the test set."]}, {"block": 17, "type": "code", "linesLength": 5, "startIndex": 106, "lines": ["#number of top score elements to be recommended  \n", "K = 10\n", "\n", "#Model prediction on the test set Xtst. \n", "top_k, test_time =  model.recommend_k_items(Xtst)"]}, {"block": 18, "type": "markdown", "linesLength": 1, "startIndex": 111, "lines": ["`top_k` returns the first K elements having the highest recommendation score. Here the recommendation score is evaluated by multiplying the predicted rating by its probability, i.e. the confidence the algorithm has about its output. So if we have two items both with predicted ratings 5, but one with probability 0.5 and the other 0.9, the latter will be considered more relevant. In order to inspect the prediction and use the evaluation metrics in this repository, we convert both top_k and Xtst to pandas dataframe format:"]}, {"block": 19, "type": "code", "linesLength": 2, "startIndex": 112, "lines": ["top_k_df = am.map_back_sparse(top_k, kind = 'prediction')\n", "test_df = am.map_back_sparse(Xtst, kind = 'ratings')"]}, {"block": 20, "type": "code", "linesLength": 1, "startIndex": 114, "lines": ["top_k_df.head(10)"]}, {"block": 21, "type": "markdown", "linesLength": 3, "startIndex": 115, "lines": ["## 4 Evaluation metrics \n", "\n", "Here we evaluate the performance of the algorithm using the metrics provided in the `PythonRankingEvaluation` class. Note that the following metrics take into account only the first K elements, therefore their value may be different from the one displayed from the `model.fit()` method. "]}, {"block": 22, "type": "code", "linesLength": 40, "startIndex": 118, "lines": ["def ranking_metrics(\n", "    data_size,\n", "    data_true,\n", "    data_pred,\n", "    time_train,\n", "    time_test,\n", "    K\n", "):\n", "\n", "    eval_map = map_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n", "                    col_rating=\"rating\", col_prediction=\"prediction\", \n", "                    relevancy_method=\"top_k\", k= K)\n", "\n", "    eval_ndcg = ndcg_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n", "                      col_rating=\"rating\", col_prediction=\"prediction\", \n", "                      relevancy_method=\"top_k\", k= K)\n", "\n", "    eval_precision = precision_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n", "                               col_rating=\"rating\", col_prediction=\"prediction\", \n", "                               relevancy_method=\"top_k\", k= K)\n", "\n", "    eval_recall = recall_at_k(data_true, data_pred, col_user=\"userID\", col_item=\"movieID\", \n", "                          col_rating=\"rating\", col_prediction=\"prediction\", \n", "                          relevancy_method=\"top_k\", k= K)\n", "\n", "    \n", "    df_result = pd.DataFrame(\n", "        {   \"Dataset\": data_size,\n", "            \"K\": K,\n", "            \"MAP\": eval_map,\n", "            \"nDCG@k\": eval_ndcg,\n", "            \"Precision@k\": eval_precision,\n", "            \"Recall@k\": eval_recall,\n", "            \"Train time (s)\": time_train,\n", "            \"Test time (s)\": time_test\n", "        }, \n", "        index=[0]\n", "    )\n", "    \n", "    return df_result"]}, {"block": 23, "type": "code", "linesLength": 9, "startIndex": 158, "lines": ["eval_100k= ranking_metrics(\n", "    data_size = \"mv 100k\",\n", "    data_true =test_df,\n", "    data_pred =top_k_df,\n", "    time_train=train_time,\n", "    time_test =test_time,\n", "    K =10)\n", "\n", "eval_100k"]}, {"block": 24, "type": "code", "linesLength": 7, "startIndex": 167, "lines": ["# Record results with papermill for tests\n", "pm.record(\"map\", eval_100k['MAP'][0])\n", "pm.record(\"ndcg\", eval_100k['nDCG@k'][0])\n", "pm.record(\"precision\", eval_100k['Precision@k'][0])\n", "pm.record(\"recall\", eval_100k['Recall@k'][0])\n", "pm.record(\"train_time\", train_time)\n", "pm.record(\"test_time\", test_time)"]}, {"block": 25, "type": "code", "linesLength": 0, "startIndex": 174, "lines": []}]