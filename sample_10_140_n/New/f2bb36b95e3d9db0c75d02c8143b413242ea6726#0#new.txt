[{"block": 0, "type": "markdown", "linesLength": 3, "startIndex": 0, "lines": ["Copyright (c) Microsoft Corporation. All rights reserved.\n", "\n", "Licensed under the MIT License."]}, {"block": 1, "type": "markdown", "linesLength": 10, "startIndex": 3, "lines": ["## AKS Load Testing\n", "\n", "Once a model has been deployed to production it is important to ensure that the deployment target can support the expected load (number of users and expected response speed). This is critical for providing recommendations in production systems that must support recommendations for multiple users simultaneously. As the number of concurrent users grows the load on the recommendation system can increase significantly, so understanding the limits of any operationalized system is necessary to avoid unwanted system failures or slow response times for users. \n", "\n", "To perform this kind of load test we can leverage tools that simulate user requests at varying rates and establish how many requests per seconds, or what the average response time is for the service. This notebook walks through the process of performing load testing for a deployed model on Azure Kubernetes Service (AKS).\n", "\n", "This notebook assumes an AKS Webservice was used to deploy the model from a Azure Machine Learning service Workspace.\n", "An example of this approach is provided in the [LightGBM Operationalization notebook](lightgbm_criteo_o16n.ipynb).\n", "\n", "We use [Locust](https://docs.locust.io/en/stable/) to perform the load testing, see documentation for more details about this tool."]}, {"block": 2, "type": "code", "linesLength": 19, "startIndex": 13, "lines": ["import os\n", "import subprocess\n", "import sys\n", "from tempfile import TemporaryDirectory\n", "from urllib.parse import urlparse\n", "\n", "sys.path.append('../..')\n", "\n", "import requests\n", "\n", "from azureml.core import Workspace\n", "from azureml.core import VERSION as azureml_version\n", "from azureml.core.webservice import AksWebservice\n", "\n", "from reco_utils.dataset.criteo import get_spark_schema, load_pandas_df\n", "from reco_utils.azureml.azureml_utils import get_or_create_workspace\n", "\n", "# Check core SDK version number\n", "print(\"Azure ML SDK version: {}\".format(azureml_version))"]}, {"block": 3, "type": "code", "linesLength": 3, "startIndex": 32, "lines": ["# We increase the cell width to capture all the output from locust later\n", "from IPython.core.display import display, HTML\n", "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"]}, {"block": 4, "type": "markdown", "linesLength": 1, "startIndex": 35, "lines": ["### Create a temporary directory for generated files"]}, {"block": 5, "type": "code", "linesLength": 1, "startIndex": 36, "lines": ["TMP_DIR = TemporaryDirectory()"]}, {"block": 6, "type": "markdown", "linesLength": 1, "startIndex": 37, "lines": ["### Retrieve the AKS service information"]}, {"block": 7, "type": "code", "linesLength": 2, "startIndex": 38, "lines": ["# this must match the service name that has been deployed\n", "SERVICE_NAME = 'lightgbm-criteo'"]}, {"block": 8, "type": "code", "linesLength": 1, "startIndex": 40, "lines": ["ws = get_or_create_workspace()"]}, {"block": 9, "type": "code", "linesLength": 1, "startIndex": 41, "lines": ["aks_service = AksWebservice(ws, name=SERVICE_NAME)"]}, {"block": 10, "type": "code", "linesLength": 6, "startIndex": 42, "lines": ["# Get the scoring the URI\n", "url = aks_service.scoring_uri\n", "parsed_url = urlparse(url)\n", "\n", "# Setup authentication using one of the keys from aks_service\n", "headers = dict(Authorization='Bearer {}'.format(aks_service.get_keys()[0]))"]}, {"block": 11, "type": "markdown", "linesLength": 1, "startIndex": 48, "lines": ["### Get Sample data for testing"]}, {"block": 12, "type": "code", "linesLength": 2, "startIndex": 49, "lines": ["# Grab some sample data\n", "df = load_pandas_df(size='sample')"]}, {"block": 13, "type": "code", "linesLength": 2, "startIndex": 51, "lines": ["data = df.iloc[0, :].to_json()\n", "print(data)"]}, {"block": 14, "type": "code", "linesLength": 2, "startIndex": 53, "lines": ["# Ensure the aks service is running and provides expected results\n", "aks_service.run(data)"]}, {"block": 15, "type": "code", "linesLength": 3, "startIndex": 55, "lines": ["# Make sure an HTTP request to the service will also work\n", "response = requests.post(url=url, json=data, headers=headers)\n", "print(response.json())"]}, {"block": 16, "type": "markdown", "linesLength": 7, "startIndex": 58, "lines": ["### Setup LocustFile\n", "\n", "Locust uses a locust file (defaulting to locustfile.py) which controls the user behavior. \n", "\n", "In this example we create a UserBehavior class which encapsulates the tasks that the user will conduct each time it is started. We are only interested in ensure the service can handle a request with sample data so the only task used is the score task which is a simple post request like what was done manually above.\n", "\n", "The next class defines how a user will be instantiated, in this case we create a user which will make start an http session with the host server and execute the defined tasks. The task will be repeated after waiting for a small period of time. That wait period is determined by making a uniform random sample between the min and max wait times (in milliseconds)."]}, {"block": 17, "type": "code", "linesLength": 20, "startIndex": 65, "lines": ["locustfile = \"\"\"\n", "from locust import HttpLocust, TaskSet, task\n", "\n", "\n", "class UserBehavior(TaskSet):\n", "    @task\n", "    def score(self):\n", "        self.client.post(\"{score_url}\", json='{data}', headers={headers})\n", "\n", "\n", "class WebsiteUser(HttpLocust):\n", "    task_set = UserBehavior\n", "    # min and max time to wait before repeating task\n", "    min_wait = 1000\n", "    max_wait = 2000\n", "\"\"\".format(data=data, headers=headers, score_url=parsed_url.path)\n", "\n", "locustfile_path = os.path.join(TMP_DIR.name, 'locustfile.py')\n", "with open(locustfile_path, 'w') as f:\n", "    f.write(locustfile)"]}, {"block": 18, "type": "markdown", "linesLength": 1, "startIndex": 85, "lines": ["The next step is to start the locust load test tool. It can be run with a web interface or directly from the command line. In this case we will just run it from the command line and specify the number of concurrent users, how fast the users should spawn and how long the test should run for. All these options can be controlled via the web interface gui as well as providing more information on failures so it is useful to read the documentation for more advanced usage. Here we will just run the test and capture the summary results."]}, {"block": 19, "type": "code", "linesLength": 9, "startIndex": 86, "lines": ["cmd = \"locust -H {host} -f {path} --no-web -c {users} -r {rate} -t {duration} --only-summary\".format(\n", "    host='{url.scheme}://{url.netloc}'.format(url=parsed_url),\n", "    path=locustfile_path,\n", "    users=200,  # concurrent users\n", "    rate=10,  # hatch rate (users / second)\n", "    duration='1m',  # test duration\n", ")\n", "process = subprocess.run(cmd, shell=True, stderr=subprocess.PIPE)\n", "print(process.stderr.decode('utf-8'))"]}, {"block": 20, "type": "markdown", "linesLength": 5, "startIndex": 95, "lines": ["### Load Test Results\n", "\n", "Above you can see the number of requests, failures and statistics on response time, as well as the number of requests per second that the server is handling.\n", "\n", "The second line shows the distribution of response times which can be helpful to understand over all the requests how the load is impacting the response speed and whether there may be outliers which are impacting performance."]}, {"block": 21, "type": "markdown", "linesLength": 1, "startIndex": 100, "lines": ["### Cleanup temporary directory"]}, {"block": 22, "type": "code", "linesLength": 1, "startIndex": 101, "lines": ["TMP_DIR.cleanup()"]}, {"block": 23, "type": "code", "linesLength": 0, "startIndex": 102, "lines": []}]