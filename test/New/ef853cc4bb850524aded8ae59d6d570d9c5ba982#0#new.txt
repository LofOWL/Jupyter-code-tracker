[{"block": 0, "type": "markdown", "linesLength": 3, "startIndex": 0, "lines": ["# Introduction: Encoding Time Series Features\n", "\n", "In this notebook, we will explore the options for encoding times and dates in a time series problem. The primary objective is to determine the optimal method for representing time in a time-series problem, particularly as it relates to building energy data."]}, {"block": 1, "type": "code", "linesLength": 20, "startIndex": 3, "lines": ["# Standard Data Science Helpers\n", "import numpy as np\n", "import pandas as pd\n", "import os\n", "\n", "import plotly.plotly as py\n", "import plotly.graph_objs as go\n", "from plotly.offline import iplot, init_notebook_mode\n", "init_notebook_mode(connected=True)\n", "\n", "import cufflinks as cf\n", "cf.set_config_file(world_readable=True, theme=\"pearl\")\n", "cf.go_offline(connected=True)\n", "\n", "# Extra options\n", "pd.options.display.max_rows = 10\n", "pd.options.display.max_columns = 30\n", "# Show all code cells outputs\n", "from IPython.core.interactiveshell import InteractiveShell\n", "InteractiveShell.ast_node_interactivity = 'all'"]}, {"block": 2, "type": "code", "linesLength": 2, "startIndex": 23, "lines": ["%load_ext autoreload\n", "%autoreload 2"]}, {"block": 3, "type": "code", "linesLength": 1, "startIndex": 25, "lines": ["from time_features_utils import *"]}, {"block": 4, "type": "code", "linesLength": 1, "startIndex": 26, "lines": ["pd.read_csv('data/building_1.csv').head()"]}, {"block": 5, "type": "code", "linesLength": 7, "startIndex": 27, "lines": ["def data_reading(filename):\n", "    data = pd.read_csv(filename, parse_dates=['timestamp'])\n", "    data = data.dropna(subset=['energy'])\n", "    freq_counts = data['timestamp'].diff(1).value_counts()\n", "    freq = round(freq_counts.idxmax().total_seconds() / 60)\n", "    data = data.set_index('timestamp').sort_index()\n", "    return data, freq, len(data)"]}, {"block": 6, "type": "code", "linesLength": 8, "startIndex": 34, "lines": ["def data_testing(filename, model):\n", "    building_id = filename.split('_')[-1].split('.csv')[0]\n", "    data, freq, dpoints = data_reading(filename)\n", "    results = test_time_features(data, model)\n", "    results['freq'] = freq\n", "    results['dpoints'] = dpoints\n", "    results['building_id'] = building_id\n", "    return results"]}, {"block": 7, "type": "code", "linesLength": 42, "startIndex": 42, "lines": ["def test_time_features(data, model):\n", "    \n", "    data = pd.concat([data, create_time_features(data.index, cyc_encode=True)], axis=1)\n", "    \n", "    scores = []\n", "    methods = []\n", " \n", "    y = data.pop('energy')\n", "    \n", "    normal_features = ['timestamp_' + t for t in ['hour', 'dayofweek', 'month', 'dayofyear', 'year']]\n", "    normal_cyc_features = ['sin_' + t for t in normal_features if t not in ['timestamp_dayofyear', 'timestamp_year']] + ['cos_' + t for t in normal_features if t not in ['timestamp_dayofyear', 'timestamp_year']]\n", "\n", "    frac_features = ['timestamp_' + t for t in ['fracday', 'fracweek', 'fracmonth', 'fracyear']]\n", "    frac_cyc_features = ['sin_' + t for t in frac_features] + ['cos_' + t for t in frac_features]\n", "\n", "    data_normal = data[normal_features].copy()\n", "    data_normal_cyc = data[normal_cyc_features].copy()\n", "    data_frac = data[frac_features].copy()\n", "    data_frac_cyc = data[frac_cyc_features].copy()\n", "\n", "    results = {}\n", "    dataset_names = ['normal', 'normal_cyc', 'frac', 'frac_cyc']\n", "\n", "    for dataset, name in zip([data_normal, \n", "                                            data_normal_cyc, \n", "                                            data_frac, \n", "                                            data_frac_cyc], \n", "                                           dataset_names):\n", "        \n", "        to_drop = dataset.columns[(dataset.nunique() == 1) | (dataset.nunique() == len(dataset))]\n", "        \n", "        dataset = dataset.drop(columns=to_drop)\n", "        dataset['energy'] = y.copy()\n", "        try:\n", "            data_results = monthly_validation(dataset, model)\n", "            scores.append(data_results['score'])\n", "            methods.append(name)\n", "        except Exception as e:\n", "            print(e, name)\n", "    \n", "    results = pd.DataFrame(dict(score=scores, method=methods))\n", "    return results"]}, {"block": 8, "type": "code", "linesLength": 5, "startIndex": 84, "lines": ["from sklearn.linear_model import LinearRegression\n", "\n", "linear_model = LinearRegression()\n", "\n", "data_testing('data/building_10.csv', linear_model)"]}, {"block": 9, "type": "code", "linesLength": 9, "startIndex": 89, "lines": ["linear_results = []\n", "\n", "for file in tqdm_notebook(os.listdir('data/')):\n", "    if file.endswith('.csv'):\n", "        linear_results.append(data_testing(f'data/{file}', linear_model))\n", "        \n", "        \n", "all_linear_results = pd.concat(linear_results)\n", "all_linear_results.to_csv('results/linear_model.csv')"]}, {"block": 10, "type": "code", "linesLength": 1, "startIndex": 98, "lines": ["all_linear_results.groupby('building_id').apply(lambda x: x.loc[x['score'].idxmax(), 'method']).value_counts()"]}, {"block": 11, "type": "code", "linesLength": 1, "startIndex": 99, "lines": ["all_linear_results.pivot_table(index='building_id', columns='method', values='score').iplot()"]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 100, "lines": ["all_linear_results.set_index('building_id').iplot(y='score', categories='method')"]}, {"block": 13, "type": "code", "linesLength": 4, "startIndex": 101, "lines": ["from sklearn.ensemble import RandomForestRegressor\n", "\n", "random_model = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=10, n_jobs=-1)\n", "data_testing('data/building_10.csv', random_model)"]}, {"block": 14, "type": "code", "linesLength": 9, "startIndex": 105, "lines": ["random_results = []\n", "\n", "for file in tqdm_notebook(os.listdir('data/')):\n", "    if file.endswith('.csv'):\n", "        random_results.append(data_testing(f'data/{file}', random_model))\n", "        \n", "        \n", "all_random_results = pd.concat(random_results)\n", "all_random_results.to_csv('results/random_forest_model.csv')"]}, {"block": 15, "type": "code", "linesLength": 1, "startIndex": 114, "lines": ["all_random_results.groupby('building_id').apply(lambda x: x.loc[x['score'].idxmax, 'method']).value_counts()"]}, {"block": 16, "type": "code", "linesLength": 0, "startIndex": 115, "lines": []}]