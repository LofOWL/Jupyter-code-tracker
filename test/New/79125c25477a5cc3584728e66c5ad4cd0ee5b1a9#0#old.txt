[{"block": 0, "type": "markdown", "linesLength": 14, "startIndex": 0, "lines": ["# Introduction: Analysis of Medium Stats\n", "\n", "In this notebook, we will analyze my Medium article stats. The functions for scraping and formatting the data were developed in the `Development` notebook, and here we will focus on looking at the data quantitatively and visually.\n", "\n", "## Instructions\n", "\n", "To apply to your own medium data\n", "\n", "1. Go to the stats page https://medium.com/me/stats\n", "2. Make sure to scroll all the way down to the bottom so all the articles are loaded\n", "3. Right click, and hit 'save as'. \n", "4. Save the file as `stats.html` in the `data/` directory. You can also save the responses to do a similar analysis.\n", "\n", "![](images/stats-saving-medium.gif)"]}, {"block": 1, "type": "markdown", "linesLength": 3, "startIndex": 14, "lines": ["    # Might need to run this on MAC for multiprocessing to work properly\n", "    # see https://stackoverflow.com/questions/50168647/multiprocessing-causes-python-to-crash-and-gives-an-error-may-have-been-in-progr\n", "    export OBJC_DISABLE_INITIALIZE_FORK_SAFETY=YES"]}, {"block": 2, "type": "markdown", "linesLength": 3, "startIndex": 17, "lines": ["# Retrieve Statistics\n", "\n", "Thanks to a few functions already developed, you can get all of the statistics for your articles in under 10 seconds."]}, {"block": 3, "type": "code", "linesLength": 2, "startIndex": 20, "lines": ["%load_ext autoreload\n", "%autoreload 2"]}, {"block": 4, "type": "code", "linesLength": 3, "startIndex": 22, "lines": ["from retrieval import process_in_parallel, get_table_rows\n", "\n", "table_rows = get_table_rows(fname='stats.html')"]}, {"block": 5, "type": "markdown", "linesLength": 1, "startIndex": 25, "lines": ["Each of these entries is a separate article. To get the information about each article, we use the next function. This scrapes both the article metadata and the article itself (using `requests` and `BeautifulSoup`)."]}, {"block": 6, "type": "code", "linesLength": 2, "startIndex": 26, "lines": ["df = process_in_parallel(table_rows=table_rows, processes=25)\n", "df.head()"]}, {"block": 7, "type": "markdown", "linesLength": 3, "startIndex": 28, "lines": ["# Analysis\n", "\n", "With the comprehensive data, we can do any sort of analysis we want. There's a lot of data here and I'm sure you'll be able to find other interesting things to do with the data."]}, {"block": 8, "type": "code", "linesLength": 21, "startIndex": 31, "lines": ["# Data science imports\n", "import pandas as pd\n", "import numpy as np\n", "\n", "%load_ext autoreload\n", "%autoreload 2\n", "\n", "# Options for pandas\n", "pd.options.display.max_columns = 25\n", "\n", "# Display all cell outputs\n", "from IPython.core.interactiveshell import InteractiveShell\n", "InteractiveShell.ast_node_interactivity = 'all'\n", "\n", "import plotly.plotly as py\n", "import plotly.graph_objs as go\n", "import plotly.figure_factory as ff\n", "from plotly.offline import iplot\n", "\n", "import cufflinks\n", "cufflinks.go_offline()"]}, {"block": 9, "type": "markdown", "linesLength": 3, "startIndex": 52, "lines": ["## Correlations\n", "\n", "We can start off by looking at correlations. We'll limit this to the `published` articles for now."]}, {"block": 10, "type": "code", "linesLength": 2, "startIndex": 55, "lines": ["corrs = df[df['type'] == 'published'].corr()\n", "corrs.round(2)"]}, {"block": 11, "type": "markdown", "linesLength": 1, "startIndex": 57, "lines": ["If we are looking at maximizing claps, what do we want to focus on?"]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 58, "lines": ["corrs['claps'].sort_values(ascending=False)"]}, {"block": 13, "type": "markdown", "linesLength": 1, "startIndex": 59, "lines": ["Okay, so most of these occur after the article is released. However, the tag `Towards Data Science` seems to help quite a bit! It also looks like the read time is negatively correlated with the number of claps. "]}, {"block": 14, "type": "markdown", "linesLength": 9, "startIndex": 60, "lines": ["## Correlation Heatmap\n", "\n", "Using the `plotly` python library, we can very rapidly create interactive great looking charts.\n", "\n", "Here are the avaiable colorscales if you want to try others:\n", "\n", "    colorscales = ['Greys', 'YlGnBu', 'Greens', 'YlOrRd', 'Bluered', 'RdBu',\n", "            'Reds', 'Blues', 'Picnic', 'Rainbow', 'Portland', 'Jet',\n", "            'Hot', 'Blackbody', 'Earth', 'Electric', 'Viridis', 'Cividis']"]}, {"block": 15, "type": "code", "linesLength": 3, "startIndex": 69, "lines": ["colorscales = ['Greys', 'YlGnBu', 'Greens', 'YlOrRd', 'Bluered', 'RdBu',\n", "        'Reds', 'Blues', 'Picnic', 'Rainbow', 'Portland', 'Jet',\n", "        'Hot', 'Blackbody', 'Earth', 'Electric', 'Viridis', 'Cividis']"]}, {"block": 16, "type": "code", "linesLength": 6, "startIndex": 72, "lines": ["figure = ff.create_annotated_heatmap(z = corrs.round(2).values, \n", "                                     x =list(corrs.columns), \n", "                                     y=list(corrs.index), \n", "                                     colorscale='Portland',\n", "                                     annotation_text=corrs.round(2).values)\n", "iplot(figure)"]}, {"block": 17, "type": "markdown", "linesLength": 1, "startIndex": 78, "lines": ["Correlations by themselves don't tell us that much. It does not help that most of these are pretty obvious, such as the `claps` and `fans` will be highly correlated. Sometimes correlations by themselves are useful, but not really in this case."]}, {"block": 18, "type": "markdown", "linesLength": 1, "startIndex": 79, "lines": ["## Scatterplot Matrix"]}, {"block": 19, "type": "code", "linesLength": 4, "startIndex": 80, "lines": ["figure = ff.create_scatterplotmatrix(df[['read_time', 'claps', 'type']],\n", "                                     index = 'type', colormap='Jet', title='Scatterplot Matrix by Type',\n", "                                     diag='histogram', width=800, height=800)\n", "iplot(figure)"]}, {"block": 20, "type": "code", "linesLength": 4, "startIndex": 84, "lines": ["figure = ff.create_scatterplotmatrix(df[['read_time', 'claps', 'publication']],\n", "                                     index = 'publication', title='Scatterplot Matrix by Publication',\n", "                                     diag='histogram', width=800, height=800)\n", "iplot(figure)"]}, {"block": 21, "type": "code", "linesLength": 8, "startIndex": 88, "lines": ["figure = ff.create_scatterplotmatrix(df[['read_time', 'claps', 'views',\n", "                                         'num_responses', 'edit_days','publication']],\n", "                                     index = 'publication', \n", "                                     diag='histogram', \n", "                                     size=8, width=1000, height=1000,\n", "                                     title='Scatterplot Matrix by Publication')\n", "\n", "iplot(figure)"]}, {"block": 22, "type": "code", "linesLength": 7, "startIndex": 96, "lines": ["figure = ff.create_scatterplotmatrix(df[['read_time', 'views', 'ratio', 'publication']],\n", "                                     index = 'publication', \n", "                                     diag='histogram', \n", "                                     size=8, width=1000, height=1000,\n", "                                     title='Scatterplot Matrix by Publication')\n", "\n", "iplot(figure)"]}, {"block": 23, "type": "markdown", "linesLength": 1, "startIndex": 103, "lines": ["# Histograms"]}, {"block": 24, "type": "code", "linesLength": 1, "startIndex": 104, "lines": ["from visuals import make_hist"]}, {"block": 25, "type": "code", "linesLength": 2, "startIndex": 105, "lines": ["figure = make_hist(df, x='views', category='publication')\n", "iplot(figure)"]}, {"block": 26, "type": "code", "linesLength": 2, "startIndex": 107, "lines": ["figure = make_hist(df, x='word_count', category='type')\n", "iplot(figure)"]}, {"block": 27, "type": "code", "linesLength": 2, "startIndex": 109, "lines": ["figure=make_hist(df, x='claps')\n", "iplot(figure)"]}, {"block": 28, "type": "markdown", "linesLength": 1, "startIndex": 111, "lines": ["# Cumulative Plot"]}, {"block": 29, "type": "code", "linesLength": 1, "startIndex": 112, "lines": ["from visuals import make_cum_plot"]}, {"block": 30, "type": "code", "linesLength": 2, "startIndex": 113, "lines": ["figure = make_cum_plot(df, y='views')\n", "iplot(figure)"]}, {"block": 31, "type": "code", "linesLength": 2, "startIndex": 115, "lines": ["figure = make_cum_plot(df, y='word_count')\n", "iplot(figure)"]}, {"block": 32, "type": "code", "linesLength": 2, "startIndex": 117, "lines": ["figure = make_cum_plot(df, y='views', category='publication')\n", "iplot(figure)"]}, {"block": 33, "type": "code", "linesLength": 2, "startIndex": 119, "lines": ["figure = make_cum_plot(df, y=['word_count', 'views'])\n", "iplot(figure)"]}, {"block": 34, "type": "code", "linesLength": 2, "startIndex": 121, "lines": ["figure = make_cum_plot(df, y=['views', 'reads'])\n", "iplot(figure)"]}, {"block": 35, "type": "code", "linesLength": 1, "startIndex": 123, "lines": ["df.head()"]}, {"block": 36, "type": "markdown", "linesLength": 1, "startIndex": 124, "lines": ["# Scatter Plots"]}, {"block": 37, "type": "code", "linesLength": 1, "startIndex": 125, "lines": ["from visuals import make_scatter_plot"]}, {"block": 38, "type": "code", "linesLength": 2, "startIndex": 126, "lines": ["figure = make_scatter_plot(df, x='read_time', y='ratio')\n", "iplot(figure)"]}, {"block": 39, "type": "code", "linesLength": 2, "startIndex": 128, "lines": ["figure = make_scatter_plot(df, x='read_time', y='ratio', category='type')\n", "iplot(figure)"]}, {"block": 40, "type": "code", "linesLength": 3, "startIndex": 130, "lines": ["figure = make_scatter_plot(df, x='read_time', y='views', ylog=True,\n", "                           category='type')\n", "iplot(figure)"]}, {"block": 41, "type": "code", "linesLength": 3, "startIndex": 133, "lines": ["figure = make_scatter_plot(df, x='read_time', y='views', ylog=True,\n", "                           scale='ratio', sizeref=0.2)\n", "iplot(figure)"]}, {"block": 42, "type": "code", "linesLength": 2, "startIndex": 136, "lines": ["df['binned_ratio'] = pd.cut(df['ratio'], list(range(0, 100, 10))).astype('str')\n", "df['binned_claps'] = pd.cut(df['claps'], list(np.insert(np.logspace(start=0, stop=5, num=6),0,-1).astype(int))).astype(str)"]}, {"block": 43, "type": "code", "linesLength": 3, "startIndex": 138, "lines": ["figure = make_scatter_plot(df, x='word_count', y='fans',\n", "                           scale='claps', sizeref=5)\n", "iplot(figure)"]}, {"block": 44, "type": "code", "linesLength": 3, "startIndex": 141, "lines": ["figure = make_scatter_plot(df, x='word_count', y='reads', xlog=True,\n", "                           scale='claps', sizeref=3)\n", "iplot(figure)"]}, {"block": 45, "type": "markdown", "linesLength": 1, "startIndex": 144, "lines": ["# Univariate Linear Regressions"]}, {"block": 46, "type": "markdown", "linesLength": 1, "startIndex": 145, "lines": ["For the linear regressions, we'll focus on articles that were published in Towards Data Science. This makes the relationships clearer because the other articles are a mixed bag. We'll start off using a single variable - univariate - and focusing on linear relationships."]}, {"block": 47, "type": "code", "linesLength": 3, "startIndex": 146, "lines": ["tds = df[df['publication'] == 'Towards Data Science'].copy()\n", "figure = make_scatter_plot(tds, 'word_count', 'views')\n", "iplot(figure)"]}, {"block": 48, "type": "markdown", "linesLength": 1, "startIndex": 149, "lines": ["## Views Regressed by Word Count"]}, {"block": 49, "type": "markdown", "linesLength": 1, "startIndex": 150, "lines": ["Let's do a regression of the number of words versus the views for articles published in towards data science. We are using `statsmodels.api.OLS` which sets the intercept to be 0. I made this choice because the number of views can never be negative (sometimes we do need an intercept so I left this as a parameter)."]}, {"block": 50, "type": "code", "linesLength": 4, "startIndex": 151, "lines": ["import statsmodels.api as sm\n", "\n", "lin_reg=sm.OLS(tds['views'], tds['word_count']).fit()\n", "lin_reg.summary()"]}, {"block": 51, "type": "markdown", "linesLength": 1, "startIndex": 155, "lines": ["This tells us that for every extra word, I get 13 more views! If we look at the plot, there is one outlying data point beyond 5000 words. What happens if I stick to articles under 5000 words published on Towards Data Science?"]}, {"block": 52, "type": "code", "linesLength": 3, "startIndex": 156, "lines": ["tds_clean = tds[tds['word_count'] < 5000].copy()\n", "lin_reg = sm.OLS(tds_clean['views'], tds_clean['word_count']).fit()\n", "lin_reg.summary()"]}, {"block": 53, "type": "markdown", "linesLength": 1, "startIndex": 159, "lines": ["Now we see that for every extra word, I get 14 more views! However, it looks like I want to keep my articles under 5000 words (about a 25 minute reading time). "]}, {"block": 54, "type": "markdown", "linesLength": 3, "startIndex": 160, "lines": ["## Read Ratio Regressed by Reading Time\n", "\n", "If we want to fit a model with an intercept, we can use `scipy.stats.linregress`"]}, {"block": 55, "type": "code", "linesLength": 2, "startIndex": 163, "lines": ["figure = make_scatter_plot(tds_clean, 'read_time', 'ratio')\n", "iplot(figure)"]}, {"block": 56, "type": "code", "linesLength": 2, "startIndex": 165, "lines": ["from scipy import stats\n", "stats.linregress(tds_clean['read_time'], tds_clean['ratio'])"]}, {"block": 57, "type": "markdown", "linesLength": 1, "startIndex": 167, "lines": ["This time, we see that for every additional minute of reading time, the percentage of people who read the article declines by 2.3%. For an article with a 0 minute reading time, 53% of people will read it! "]}, {"block": 58, "type": "markdown", "linesLength": 1, "startIndex": 168, "lines": ["Let's take a look at a few different fits."]}, {"block": 59, "type": "code", "linesLength": 4, "startIndex": 169, "lines": ["from visuals import make_linear_regression\n", "\n", "figure, summary = make_linear_regression(tds_clean, x='word_count', y='views', intercept_0=True)\n", "iplot(figure)"]}, {"block": 60, "type": "code", "linesLength": 1, "startIndex": 173, "lines": ["summary"]}, {"block": 61, "type": "code", "linesLength": 2, "startIndex": 174, "lines": ["figure, summary = make_linear_regression(tds_clean, x='read_time', y='ratio', intercept_0=False)\n", "iplot(figure)"]}, {"block": 62, "type": "code", "linesLength": 1, "startIndex": 176, "lines": ["summary"]}, {"block": 63, "type": "markdown", "linesLength": 3, "startIndex": 177, "lines": ["# Univariate Polynomial Regressions\n", "\n", "Next, we'll let the degree of the fit increase above 1. Overfitting (especially with limited data) is definitely going to be the outcome, but we'll let this serve as a lesson about having too many parameters in your model! "]}, {"block": 64, "type": "code", "linesLength": 1, "startIndex": 180, "lines": ["from visuals import make_poly_fits"]}, {"block": 65, "type": "code", "linesLength": 2, "startIndex": 181, "lines": ["fit_stats, figure = make_poly_fits(df, x='word_count', y='reads', degree=6)\n", "fit_stats"]}, {"block": 66, "type": "code", "linesLength": 1, "startIndex": 183, "lines": ["iplot(figure)"]}, {"block": 67, "type": "code", "linesLength": 3, "startIndex": 184, "lines": ["tds['log_views'] = np.log10(tds['views'])\n", "fit_stats, figure = make_poly_fits(tds, x='word_count', y='log_views', degree=15)\n", "fit_stats"]}, {"block": 68, "type": "code", "linesLength": 1, "startIndex": 187, "lines": ["iplot(figure)"]}, {"block": 69, "type": "markdown", "linesLength": 3, "startIndex": 188, "lines": ["# Multivariate Regressions\n", "\n", "Next "]}, {"block": 70, "type": "code", "linesLength": 3, "startIndex": 191, "lines": ["from scipy import stats\n", "pub = df[df['type']=='published'].copy()\n", "stats.linregress(pub['word_count'], np.log10(pub['views']))"]}, {"block": 71, "type": "code", "linesLength": 2, "startIndex": 194, "lines": ["pub_tds = df[(df['type']=='published') & (df['<tag>Towards Data Science'] == 1)].copy()\n", "stats.linregress(pub_tds['word_count'], np.log10(pub_tds['views']))"]}, {"block": 72, "type": "markdown", "linesLength": 3, "startIndex": 196, "lines": ["# Extrapolations\n", "\n", "The most fun part of this is extrapolating wildly into the future! Using the past stats, we can make estimates for the future using the numbers of days since publishing."]}, {"block": 73, "type": "code", "linesLength": 2, "startIndex": 199, "lines": ["figure = make_cum_plot(df, 'views')\n", "iplot(figure)"]}, {"block": 74, "type": "code", "linesLength": 3, "startIndex": 201, "lines": ["\n", "figure = make_scatter_plot(df, 'days_since_publication', 'views')\n", "iplot(figure)"]}, {"block": 75, "type": "code", "linesLength": 1, "startIndex": 204, "lines": ["df.head()"]}, {"block": 76, "type": "code", "linesLength": 1, "startIndex": 205, "lines": ["df['cum_views'] = df['views'].cumsum()"]}, {"block": 77, "type": "code", "linesLength": 2, "startIndex": 206, "lines": ["figure = make_scatter_plot(df, 'days_since_publication', 'cum_views')\n", "iplot(figure)"]}, {"block": 78, "type": "code", "linesLength": 2, "startIndex": 208, "lines": ["linreg = stats.linregress(df['days_since_publication'], df['cum_views'])\n", "slope, intercept = linreg.slope, linreg.intercept"]}, {"block": 79, "type": "code", "linesLength": 1, "startIndex": 210, "lines": ["df['predicted_views'] = intercept + df['days_since_publication'] * slope"]}, {"block": 80, "type": "code", "linesLength": 2, "startIndex": 211, "lines": ["figure = make_scatter_plot(df, 'days_since_publication', 'cum_views', fits = ['predicted_views'])\n", "iplot(figure)"]}, {"block": 81, "type": "code", "linesLength": 2, "startIndex": 213, "lines": ["figure = make_scatter_plot(df, 'days_since_publication', 'word_count')\n", "iplot(figure)"]}, {"block": 82, "type": "code", "linesLength": 2, "startIndex": 215, "lines": ["figure = make_scatter_plot(df, 'days_since_publication', 'fans', scale='word_count', sizeref=8)\n", "iplot(figure)"]}, {"block": 83, "type": "code", "linesLength": 0, "startIndex": 217, "lines": []}]