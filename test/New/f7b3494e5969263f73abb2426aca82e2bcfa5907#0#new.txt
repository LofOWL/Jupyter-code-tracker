[{"block": 0, "type": "markdown", "linesLength": 3, "startIndex": 0, "lines": ["# Overfitting vs. Underfitting\n", "\n", "Exploring a fundamental problem in modeling. This notebook will look at a simple example showing the problem of overfitting and underfitting as well as how to address it via cross-validation. This example is based on the [scikit-learn exercise](http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html). "]}, {"block": 1, "type": "markdown", "linesLength": 3, "startIndex": 3, "lines": ["## Imports \n", "\n", "We will use numpy and pandas, two of the most common libraries for data manipulation. We use scikit-learn, a popular machine learning library, for creating and evaluating the models. Matplotlib is used for model visualization."]}, {"block": 2, "type": "code", "linesLength": 19, "startIndex": 6, "lines": ["# Numpy and pandas as usual\n", "import numpy as np\n", "import pandas as pd\n", "\n", "# Scikit-Learn for fitting models\n", "from sklearn.preprocessing import PolynomialFeatures\n", "from sklearn.linear_model import LinearRegression\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.metrics import mean_squared_error\n", "\n", "# For plotting in the notebook\n", "import matplotlib\n", "import matplotlib.pyplot as plt\n", "%matplotlib inline\n", "\n", "# Default parameters for plots\n", "matplotlib.rcParams['font.size'] = 12\n", "matplotlib.rcParams['figure.titlesize'] = 16\n", "matplotlib.rcParams['figure.figsize'] = [9, 7]"]}, {"block": 3, "type": "markdown", "linesLength": 3, "startIndex": 25, "lines": ["## Generate a relationship\n", "\n", "First, we need a \"true\" relationship. We define a curve, in this case a sine curve to serve as our process that generates the data. As the real-world is never perfectly celan however, we also need to add some noise into the observations. This is done by adding a small random number to each value. "]}, {"block": 4, "type": "code", "linesLength": 11, "startIndex": 28, "lines": ["# Set the random seed for reproducible results\n", "np.random.seed(42)\n", "\n", "# \"True\" generating function representing a process in real life\n", "def true_gen(x):\n", "    y = np.sin(1.2 * x * np.pi) \n", "    return(y)\n", "\n", "# x values and y value with a small amount of random noise\n", "x = np.sort(np.random.rand(120))\n", "y = true_gen(x) + 0.1 * np.random.randn(len(x))"]}, {"block": 5, "type": "markdown", "linesLength": 1, "startIndex": 39, "lines": ["## Training and Testing Sets"]}, {"block": 6, "type": "code", "linesLength": 15, "startIndex": 40, "lines": ["# Random indices for creating training and testing sets\n", "random_ind = np.random.choice(list(range(120)), size = 120, replace=False)\n", "xt = x[random_ind]\n", "yt = y[random_ind]\n", "\n", "# Training and testing observations\n", "train = xt[:int(0.7 * len(x))]\n", "test = xt[int(0.7 * len(x)):]\n", "\n", "y_train = yt[:int(0.7 * len(y))]\n", "y_test = yt[int(0.7 * len(y)):]\n", "\n", "# Model the true curve\n", "x_linspace = np.linspace(0, 1, 1000)\n", "y_true = true_gen(x_linspace)"]}, {"block": 7, "type": "code", "linesLength": 6, "startIndex": 55, "lines": ["# Visualize observations and true curve\n", "plt.plot(train, y_train, 'ko', label = 'Train'); \n", "plt.plot(test, y_test, 'ro', label = 'Test')\n", "plt.plot(x_linspace, y_true, 'b-', linewidth = 2, label = 'True Function')\n", "plt.legend()\n", "plt.xlabel('x'); plt.ylabel('y'); plt.title('Data');"]}, {"block": 8, "type": "markdown", "linesLength": 5, "startIndex": 61, "lines": ["# Polynomial Model\n", "\n", "We want to try and capture the data using a polynomial function. A polynomial is defined by the degree, or the highest power to for the x-values. A line has a degree of 1 because it is of the form $y = b_1*x + b_0$ where $b_1$ is the slope and $b_0$ is the intercept. A third degree polynomial would have the form $y = b_3 * x^3 + b_2 * x^2 + b_1 * x + b_0$ and so on. The higher the degree of the polynomial, the more flexible the model. A more flexible model is prone to overfitting because it can can \"bend\" to follow the training data.  \n", "\n", "The following function creates a polynomial with the specified number of degrees and plots the results. We can use these results to determine the optimal degrees to achieve the right balance between over and underfitting. "]}, {"block": 9, "type": "code", "linesLength": 62, "startIndex": 66, "lines": ["\n", "def fit_poly(train, y_train, test, y_test, degrees, plot='train', return_scores=False):\n", "    \n", "    # Create a polynomial transformation of features\n", "    features = PolynomialFeatures(degree=degrees, include_bias=False)\n", "    \n", "    # Reshape training features for use in scikit-learn and transform features\n", "    train = train.reshape((-1, 1))\n", "    train_trans = features.fit_transform(train)\n", "    \n", "    # Create the linear regression model and train\n", "    model = LinearRegression()\n", "    model.fit(train_trans, y_train)\n", "    \n", "    # Calculate the cross validation score\n", "    cross_valid = cross_val_score(model, train_trans, y_train, scoring='neg_mean_squared_error', cv = 5)\n", "    \n", "    # Training predictions and error\n", "    train_predictions = model.predict(train_trans)\n", "    training_error = mean_squared_error(y_train, train_predictions)\n", "    \n", "    # Format test features\n", "    test = test.reshape((-1, 1))\n", "    test_trans = features.fit_transform(test)\n", "    \n", "    # Test set predictions and error\n", "    test_predictions = model.predict(test_trans)\n", "    testing_error = mean_squared_error(y_test, test_predictions)\n", "    \n", "    # Find the model curve and the true curve\n", "    x_curve = np.linspace(0, 1, 100)\n", "    x_curve = x_curve.reshape((-1, 1))\n", "    x_curve_trans = features.fit_transform(x_curve)\n", "    \n", "    # Model curve\n", "    model_curve = model.predict(x_curve_trans)\n", "    \n", "    # True curve\n", "    y_true_curve = true_gen(x_curve[:, 0])\n", "    \n", "    # Plot observations, true function, and model predicted function\n", "    if plot == 'train':\n", "        plt.plot(train[:, 0], y_train, 'ko', label = 'Observations')\n", "        plt.plot(x_curve[:, 0], y_true_curve, linewidth = 4, label = 'True Function')\n", "        plt.plot(x_curve[:, 0], model_curve, linewidth = 4, label = 'Model Function')\n", "        plt.xlabel('x'); plt.ylabel('y')\n", "        plt.legend()\n", "        plt.ylim(-1, 1.5); plt.xlim(0, 1)\n", "        plt.title('{} Degree Model on Training Data'.format(degrees))\n", "        plt.show()\n", "        \n", "    elif plot == 'test':\n", "        # Plot the test observations and test predictions\n", "        plt.plot(test, y_test, 'o', label = 'Test Observations')\n", "        plt.plot(x_curve[:, 0], y_true_curve, 'b-', linewidth = 2, label = 'True Function')\n", "        plt.plot(test, test_predictions, 'ro', label = 'Test Predictions')\n", "        plt.ylim(-1, 1.5); plt.xlim(0, 1)\n", "        plt.legend(), plt.xlabel('x'), plt.ylabel('y'); plt.title('{} Degree Model on Testing Data'.format(degrees)), plt.show();\n", "    \n", "    # Return the metrics\n", "    if return_scores:\n", "        return training_error, testing_error, -np.mean(cross_valid)"]}, {"block": 10, "type": "markdown", "linesLength": 1, "startIndex": 128, "lines": ["## Try Model with Different Degrees"]}, {"block": 11, "type": "markdown", "linesLength": 3, "startIndex": 129, "lines": ["### Degrees = 1 -> Underfitting\n", "\n", "In this case, a linear model cannot accurate learn the relationship between x and y and will underfit the data. "]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 132, "lines": ["fit_poly(train, y_train, test, y_test, degrees = 1, plot='train')"]}, {"block": 13, "type": "code", "linesLength": 1, "startIndex": 133, "lines": ["fit_poly(train, y_train, test, y_test, degrees = 1, plot='test')"]}, {"block": 14, "type": "markdown", "linesLength": 3, "startIndex": 134, "lines": ["## Degrees = 25 -> Overfitting\n", "\n", "We can go in the completely opposite direction and create a model that overfits the data. This model has too much flexibility and learns the training data too closely. As the training data has some amount of noise, it will end up capturing that noise and will be misled by that noise when it tries to make predictions on the test data."]}, {"block": 15, "type": "code", "linesLength": 1, "startIndex": 137, "lines": ["fit_poly(train, y_train, test, y_test, plot='train', degrees = 25)"]}, {"block": 16, "type": "code", "linesLength": 1, "startIndex": 138, "lines": ["fit_poly(train, y_train, test, y_test, degrees=25, plot='test')"]}, {"block": 17, "type": "markdown", "linesLength": 3, "startIndex": 139, "lines": ["## Degrees = 5 -> Balanced Model\n", "\n", "Now that we have seen the two extremes, we can take a look at a model that does a good job of both accounting for the data while not following it too closely. "]}, {"block": 18, "type": "code", "linesLength": 1, "startIndex": 142, "lines": ["fit_poly(train, y_train, test, y_test, plot='train', degrees = 5)"]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 143, "lines": ["fit_poly(train, y_train, test, y_test, degrees=5, plot='test')"]}, {"block": 20, "type": "markdown", "linesLength": 3, "startIndex": 144, "lines": ["# Cross Validation\n", "\n", "To pick the optimal model, we need to use a validation set. Cross validation is even better than a single validation set because it uses numerous validation sets created from the training data. In this case, we are using 5 different validation sets. The model that performs best on the cross validation is usually the optimal model because it has shown that it can learn the relationships while not overfitting."]}, {"block": 21, "type": "code", "linesLength": 12, "startIndex": 147, "lines": ["# Range of model degrees to evaluate\n", "degrees = [int(x) for x in np.linspace(1, 40, 40)]\n", "\n", "# Results dataframe\n", "results = pd.DataFrame(0, columns = ['train_error', 'test_error', 'cross_valid'], index = degrees)\n", "\n", "# Try each value of degrees for the model and record results\n", "for degree in degrees:\n", "    degree_results = fit_poly(train, y_train, test, y_test, degree, plot=False, return_scores=True)\n", "    results.ix[degree, 'train_error'] = degree_results[0]\n", "    results.ix[degree, 'test_error'] = degree_results[1]\n", "    results.ix[degree, 'cross_valid'] = degree_results[2]"]}, {"block": 22, "type": "code", "linesLength": 3, "startIndex": 159, "lines": ["print('10 Lowest Cross Validation Errors\\n')\n", "train_eval = results.sort_values('cross_valid').reset_index(level=0).rename(columns={'index': 'degrees'})\n", "train_eval.ix[:,['degrees', 'cross_valid']] .head(10)"]}, {"block": 23, "type": "code", "linesLength": 4, "startIndex": 162, "lines": ["plt.plot(results.index, results['cross_valid'], 'go-', ms=6)\n", "plt.xlabel('Degrees'); plt.ylabel('Cross Validation Error'); plt.title('Cross Validation Results');\n", "plt.ylim(0, 0.2);\n", "print('Minimum Cross Validation Error occurs at {} degrees.\\n'.format(int(np.argmin(results['cross_valid']))))"]}, {"block": 24, "type": "markdown", "linesLength": 3, "startIndex": 166, "lines": ["# Final Model\n", "\n", "The model with the lowest cross validation error had four degrees. Therefore, we will use a 4th degree polynomial for the final model. "]}, {"block": 25, "type": "code", "linesLength": 1, "startIndex": 169, "lines": ["fit_poly(train, y_train, test, y_test, degrees=4, plot='train')"]}, {"block": 26, "type": "code", "linesLength": 1, "startIndex": 170, "lines": ["fit_poly(train, y_train, test, y_test, degrees=4, plot='test')"]}, {"block": 27, "type": "markdown", "linesLength": 3, "startIndex": 171, "lines": ["## Evaluate Models \n", "\n", "The next step is to examine the scores for the models. We will use a range of values to see how the performance on the training and testing set compares. A model with much lower errors on the training data than the testing data is overfit. A model with high error on the training data (which will lead to high testing error as well) is underfitting because it does not even learn the training data. "]}, {"block": 28, "type": "markdown", "linesLength": 1, "startIndex": 174, "lines": ["#### Quantitative Comparison"]}, {"block": 29, "type": "code", "linesLength": 3, "startIndex": 175, "lines": ["print('10 Lowest Training Errors\\n')\n", "train_eval = results.sort_values('train_error').reset_index(level=0).rename(columns={'index': 'degrees'})\n", "train_eval.ix[:,['degrees', 'train_error']] .head(10)"]}, {"block": 30, "type": "code", "linesLength": 3, "startIndex": 178, "lines": ["print('10 Lowest Testing Errors\\n')\n", "train_eval = results.sort_values('test_error').reset_index(level=0).rename(columns={'index': 'degrees'})\n", "train_eval.ix[:,['degrees', 'test_error']] .head(10)"]}, {"block": 31, "type": "markdown", "linesLength": 1, "startIndex": 181, "lines": ["#### Visual Comparison"]}, {"block": 32, "type": "code", "linesLength": 7, "startIndex": 182, "lines": ["plt.plot(results.index, results['train_error'], 'b-o', ms=6, label = 'Training Error')\n", "plt.plot(results.index, results['test_error'], 'r-*', ms=6, label = 'Testing Error')\n", "plt.legend(loc=2); plt.xlabel('Degrees'); plt.ylabel('Mean Squared Error'); plt.title('Training and Testing Curves');\n", "plt.ylim(0, 0.05); plt.show()\n", "\n", "print('\\nMinimum Training Error occurs at {} degrees.'.format(int(np.argmin(results['train_error']))))\n", "print('Minimum Testing Error occurs at {} degrees.\\n'.format(int(np.argmin(results['test_error']))))"]}, {"block": 33, "type": "code", "linesLength": 0, "startIndex": 189, "lines": []}]