[{"block": 0, "type": "markdown", "linesLength": 3, "startIndex": 0, "lines": ["# Introduction: Encoding Time Series Features\n", "\n", "In this notebook, we will explore the options for encoding times and dates in a time series problem. The primary objective is to determine the optimal method for representing time in a time-series problem, particularly as it relates to building energy data."]}, {"block": 1, "type": "code", "linesLength": 20, "startIndex": 3, "lines": ["# Standard Data Science Helpers\n", "import numpy as np\n", "import pandas as pd\n", "import scipy\n", "\n", "import plotly.plotly as py\n", "import plotly.graph_objs as go\n", "from plotly.offline import iplot, init_notebook_mode\n", "init_notebook_mode(connected=True)\n", "\n", "import cufflinks as cf\n", "cf.set_config_file(world_readable=True, theme=\"pearl\")\n", "cf.go_offline(connected=True)\n", "\n", "# Extra options\n", "pd.options.display.max_rows = 10\n", "pd.options.display.max_columns = 30\n", "# Show all code cells outputs\n", "from IPython.core.interactiveshell import InteractiveShell\n", "InteractiveShell.ast_node_interactivity = 'all'"]}, {"block": 2, "type": "code", "linesLength": 2, "startIndex": 23, "lines": ["%load_ext autoreload\n", "%autoreload 2"]}, {"block": 3, "type": "code", "linesLength": 1, "startIndex": 25, "lines": ["from time_features_utils import *"]}, {"block": 4, "type": "code", "linesLength": 3, "startIndex": 26, "lines": ["df = pd.read_csv('data/temp_open_utc_complete.csv', parse_dates=['timestamp'], index_col=0)\n", "\n", "data_dict = {c: df.loc[df[c].notnull(), c] for c in df}"]}, {"block": 5, "type": "code", "linesLength": 2, "startIndex": 29, "lines": ["series = data_dict['Office_Amelie']\n", "series.tail()"]}, {"block": 6, "type": "code", "linesLength": 1, "startIndex": 31, "lines": ["series.name = 'measurement'"]}, {"block": 7, "type": "code", "linesLength": 2, "startIndex": 32, "lines": ["ds = pd.concat([series\n", "                , create_time_features(series.index, cyc_encode=True)], axis=1)"]}, {"block": 8, "type": "code", "linesLength": 1, "startIndex": 34, "lines": ["ds.nunique()"]}, {"block": 9, "type": "code", "linesLength": 1, "startIndex": 35, "lines": ["series.to_frame()"]}, {"block": 10, "type": "code", "linesLength": 9, "startIndex": 36, "lines": ["i = 95\n", "\n", "for building, building_data in data_dict.items():\n", "    building_data.name = 'energy'\n", "    i += 1\n", "    building_data = building_data.to_frame().reset_index().rename(columns={'timestamp': 'measured_at'})\n", "    building_data.to_csv(f'data/building_{i}.csv')\n", "    if i % 100 == 0:\n", "        print(i)"]}, {"block": 11, "type": "code", "linesLength": 1, "startIndex": 45, "lines": ["building_data.head()"]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 46, "lines": ["pd.read_csv('data/building_1.csv').head()"]}, {"block": 13, "type": "code", "linesLength": 7, "startIndex": 47, "lines": ["def data_reading(filename):\n", "    data = pd.read_csv(filename, parse_dates=['timestamp'])\n", "    data = data.dropna(subset=['energy'])\n", "    freq_counts = data['timestamp'].diff(1).value_counts()\n", "    freq = round(freq_counts.idxmax().total_seconds() / 60)\n", "    data = data.set_index('timestamp').sort_index()\n", "    return data, freq, len(data)"]}, {"block": 14, "type": "code", "linesLength": 8, "startIndex": 54, "lines": ["def data_testing(filename, model):\n", "    building_id = filename.split('_')[-1].split('.csv')[0]\n", "    data, freq, dpoints = data_reading(filename)\n", "    results = test_time_features(data, model)\n", "    results['freq'] = freq\n", "    results['dpoints'] = dpoints\n", "    results['building_id'] = building_id\n", "    return results"]}, {"block": 15, "type": "code", "linesLength": 42, "startIndex": 62, "lines": ["def test_time_features(data, model):\n", "    \n", "    data = pd.concat([data, create_time_features(data.index, cyc_encode=True)], axis=1)\n", "    \n", "    scores = []\n", "    methods = []\n", " \n", "    y = data.pop('energy')\n", "    \n", "    normal_features = ['timestamp_' + t for t in ['hour', 'dayofweek', 'month', 'dayofyear', 'year']]\n", "    normal_cyc_features = ['sin_' + t for t in normal_features if t not in ['timestamp_dayofyear', 'timestamp_year']] + ['cos_' + t for t in normal_features if t not in ['timestamp_dayofyear', 'timestamp_year']]\n", "\n", "    frac_features = ['timestamp_' + t for t in ['fracday', 'fracweek', 'fracmonth', 'fracyear']]\n", "    frac_cyc_features = ['sin_' + t for t in frac_features] + ['cos_' + t for t in frac_features]\n", "\n", "    data_normal = data[normal_features].copy()\n", "    data_normal_cyc = data[normal_cyc_features].copy()\n", "    data_frac = data[frac_features].copy()\n", "    data_frac_cyc = data[frac_cyc_features].copy()\n", "\n", "    results = {}\n", "    dataset_names = ['normal', 'normal_cyc', 'frac', 'frac_cyc']\n", "\n", "    for dataset, name in zip([data_normal, \n", "                                            data_normal_cyc, \n", "                                            data_frac, \n", "                                            data_frac_cyc], \n", "                                           dataset_names):\n", "        \n", "        to_drop = dataset.columns[(dataset.nunique() == 1) | (dataset.nunique() == len(dataset))]\n", "        \n", "        dataset = dataset.drop(columns=to_drop)\n", "        dataset['energy'] = y.copy()\n", "        try:\n", "            data_results = monthly_validation(dataset, model)\n", "            scores.append(data_results['score'])\n", "            methods.append(name)\n", "        except Exception as e:\n", "            print(e, name)\n", "    \n", "    results = pd.DataFrame(dict(score=scores, method=methods))\n", "    return results"]}, {"block": 16, "type": "code", "linesLength": 5, "startIndex": 104, "lines": ["from sklearn.linear_model import LinearRegression\n", "\n", "linear_model = LinearRegression()\n", "\n", "data_testing('data/building_10.csv', linear_model)"]}, {"block": 17, "type": "code", "linesLength": 9, "startIndex": 109, "lines": ["linear_results = []\n", "\n", "for file in tqdm_notebook(os.listdir('data/')):\n", "    if file.endswith('.csv'):\n", "        linear_results.append(data_testing(f'data/{file}', linear_model))\n", "        \n", "        \n", "all_linear_results = pd.concat(linear_results)\n", "all_linear_results.to_csv('results/linear_model.csv')"]}, {"block": 18, "type": "code", "linesLength": 1, "startIndex": 118, "lines": ["all_linear_results.groupby('building_id').apply(lambda x: x.loc[x['score'].idxmax(), 'method']).value_counts()"]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 119, "lines": ["all_linear_results = pd.DataFrame(np.nan_to_num(all_linear_results.values), columns=all_linear_results.columns)"]}, {"block": 20, "type": "code", "linesLength": 1, "startIndex": 120, "lines": ["all_linear_results"]}, {"block": 21, "type": "code", "linesLength": 1, "startIndex": 121, "lines": ["all_linear_results.pivot_table(index='building_id', columns='method', values='score').iplot()"]}, {"block": 22, "type": "code", "linesLength": 1, "startIndex": 122, "lines": ["all_linear_results.set_index('building_id').iplot(y='score', categories='method')"]}, {"block": 23, "type": "code", "linesLength": 4, "startIndex": 123, "lines": ["from sklearn.ensemble import RandomForestRegressor\n", "\n", "random_model = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=10, n_jobs=-1)\n", "data_testing('data/building_10.csv', random_model)"]}, {"block": 24, "type": "code", "linesLength": 9, "startIndex": 127, "lines": ["random_results = []\n", "\n", "for file in tqdm_notebook(os.listdir('data/')):\n", "    if file.endswith('.csv'):\n", "        random_results.append(data_testing(f'data/{file}', random_model))\n", "        \n", "        \n", "all_random_results = pd.concat(random_results)\n", "all_random_results.to_csv('results/random_forest_model.csv')"]}, {"block": 25, "type": "code", "linesLength": 2, "startIndex": 136, "lines": ["import os\n", "r = [data_reading(f'data/{f}') for f in os.listdir('data') if f.endswith('.csv')]"]}, {"block": 26, "type": "code", "linesLength": 2, "startIndex": 138, "lines": ["meta = pd.DataFrame(r, columns=['freq', 'dpoints'])\n", "meta['freq'].iplot('hist')"]}, {"block": 27, "type": "code", "linesLength": 1, "startIndex": 140, "lines": ["meta['dpoints'].iplot('hist')"]}, {"block": 28, "type": "code", "linesLength": 2, "startIndex": 141, "lines": ["freq = data_reading('data/building_90.csv')\n", "freq"]}, {"block": 29, "type": "code", "linesLength": 2, "startIndex": 143, "lines": ["dt = pd.read_csv('data/building_80.csv', parse_dates=['measured_at'])\n", "dt['measured_at']"]}, {"block": 30, "type": "code", "linesLength": 1, "startIndex": 145, "lines": ["dt.set_index('measured_at').iplot()"]}, {"block": 31, "type": "code", "linesLength": 1, "startIndex": 146, "lines": ["dt[dt['energy'].isna()]"]}, {"block": 32, "type": "code", "linesLength": 1, "startIndex": 147, "lines": ["dt['measured_at'].dt.freq"]}, {"block": 33, "type": "code", "linesLength": 1, "startIndex": 148, "lines": ["ds.columns[(ds.nunique() <= 2) | (ds.nunique() > (0.95 * len(ds)))]"]}, {"block": 34, "type": "code", "linesLength": 2, "startIndex": 149, "lines": ["to_drop = ds.columns[(ds.nunique() <= 2) | (ds.nunique() > (0.8 * len(ds)))]\n", "to_drop"]}, {"block": 35, "type": "code", "linesLength": 1, "startIndex": 151, "lines": ["ds = ds.drop(columns=to_drop)"]}, {"block": 36, "type": "code", "linesLength": 2, "startIndex": 152, "lines": ["def mape(y_true, y_pred):\n", "    return 100*np.mean(np.abs((y_pred - y_true)/y_true))"]}, {"block": 37, "type": "code", "linesLength": 0, "startIndex": 154, "lines": []}, {"block": 38, "type": "code", "linesLength": 4, "startIndex": 154, "lines": ["from sklearn.ensemble import ExtraTreesRegressor\n", "from time_features_utils import monthly_validation\n", "\n", "model = ExtraTreesRegressor(n_estimators=10, max_depth=10, random_state=10)\n"]}, {"block": 39, "type": "code", "linesLength": 1, "startIndex": 158, "lines": ["monthly_validation(ds, model)"]}, {"block": 40, "type": "code", "linesLength": 3, "startIndex": 159, "lines": ["series = df.iloc[:, 0]\n", "data = pd.concat([series, create_time_features(series.index, cyc_encode=True)], axis=1)\n", "data.head()"]}, {"block": 41, "type": "code", "linesLength": 1, "startIndex": 162, "lines": ["series.index.week.unique()"]}, {"block": 42, "type": "code", "linesLength": 1, "startIndex": 163, "lines": ["normal_cyc_features"]}, {"block": 43, "type": "code", "linesLength": 1, "startIndex": 164, "lines": ["data.columns"]}, {"block": 44, "type": "code", "linesLength": 1, "startIndex": 165, "lines": ["data[normal_cyc_features]"]}, {"block": 45, "type": "code", "linesLength": 13, "startIndex": 166, "lines": ["data = pd.concat([series, create_time_features(series.index, cyc_encode=True)], axis=1)\n", "\n", "y = data.pop(series.name)\n", "normal_features = ['timestamp_' + t for t in ['hour', 'dayofweek', 'month', 'dayofyear', 'year']]\n", "normal_cyc_features = ['sin_' + t for t in normal_features if t not in ['timestamp_dayofyear', 'timestamp_year']] + ['cos_' + t for t in normal_features if t not in ['timestamp_dayofyear', 'timestamp_year']]\n", "\n", "frac_features = ['timestamp_' + t for t in ['fracday', 'fracweek', 'fracmonth', 'fracyear']]\n", "frac_cyc_features = ['sin_' + t for t in frac_features] + ['cos_' + t for t in frac_features]\n", "\n", "data_normal = data[normal_features].copy()\n", "data_normal_cyc = data[normal_cyc_features].copy()\n", "data_frac = data[frac_features].copy()\n", "data_frac_cyc = data[frac_cyc_features].copy()"]}, {"block": 46, "type": "code", "linesLength": 1, "startIndex": 179, "lines": ["data_frac_cyc.__name__"]}, {"block": 47, "type": "code", "linesLength": 3, "startIndex": 180, "lines": ["data_frac['measurement'] = y.copy()\n", "data_frac = data_frac.dropna(subset=['measurement'])\n", "monthly_validation(data_frac, model)"]}, {"block": 48, "type": "code", "linesLength": 3, "startIndex": 183, "lines": ["data_frac_cyc['measurement'] = y.copy()\n", "data_frac_cyc = data_frac_cyc.dropna(subset=['measurement'])\n", "monthly_validation(data_frac_cyc, model)"]}, {"block": 49, "type": "code", "linesLength": 1, "startIndex": 186, "lines": ["from tqdm import tqdm_notebook"]}, {"block": 50, "type": "code", "linesLength": 45, "startIndex": 187, "lines": ["def test_time_features(df, model):\n", "    \n", "    scores = []\n", "    buildings = []\n", "    methods = []\n", "    \n", "    \n", "    for col in tqdm_notebook(df, total=len(df.columns)):\n", "        \n", "        series = df[col].copy().dropna()\n", "        \n", "        data = pd.concat([series, create_time_features(series.index, cyc_encode=True)], axis=1)\n", "\n", "        y = data.pop(series.name)\n", "        normal_features = ['timestamp_' + t for t in ['hour', 'dayofweek', 'month', 'dayofyear', 'year']]\n", "        normal_cyc_features = ['sin_' + t for t in normal_features if t not in ['timestamp_dayofyear', 'timestamp_year']] + ['cos_' + t for t in normal_features if t not in ['timestamp_dayofyear', 'timestamp_year']]\n", "\n", "        frac_features = ['timestamp_' + t for t in ['fracday', 'fracweek', 'fracmonth', 'fracyear']]\n", "        frac_cyc_features = ['sin_' + t for t in frac_features] + ['cos_' + t for t in frac_features]\n", "\n", "        data_normal = data[normal_features].copy()\n", "        data_normal_cyc = data[normal_cyc_features].copy()\n", "        data_frac = data[frac_features].copy()\n", "        data_frac_cyc = data[frac_cyc_features].copy()\n", "\n", "        results = {}\n", "        dataset_names = ['normal', 'normal_cyc', 'frac', 'frac_cyc']\n", "\n", "        \n", "        for dataset, name in zip([data_normal, \n", "                                                data_normal_cyc, \n", "                                                data_frac, \n", "                                                data_frac_cyc], \n", "                                               dataset_names):\n", "            dataset['measurement'] = y.copy()\n", "            \n", "            try:\n", "                data_results = monthly_validation(dataset, model)\n", "                buildings.append(col)\n", "                scores.append(data_results['score'])\n", "                methods.append(name)\n", "            except Exception as e:\n", "                print(col, e, name)\n", "    results = pd.DataFrame(dict(building=buildings, score=scores, method=methods))\n", "    return results"]}, {"block": 51, "type": "code", "linesLength": 3, "startIndex": 232, "lines": ["from sklearn.linear_model import LinearRegression\n", "\n", "model = LinearRegression()"]}, {"block": 52, "type": "code", "linesLength": 1, "startIndex": 235, "lines": ["linear_results = test_time_features(df, model)"]}, {"block": 53, "type": "code", "linesLength": 4, "startIndex": 236, "lines": ["import pickle\n", "\n", "with open('linear_results.pkl', 'wb') as f:\n", "    f.write(pickle.dumps(linear_results))"]}, {"block": 54, "type": "code", "linesLength": 7, "startIndex": 240, "lines": ["from sklearn.ensemble import RandomForestRegressor\n", "\n", "model = RandomForestRegressor(random_state=50, n_estimators=50, max_depth=10, n_jobs=-1)\n", "random_forest_results = test_time_features(df, model)\n", "\n", "with open('random_forest_results.pkl', 'wb') as f:\n", "    f.write(pickle.dumps(random_forest_results))"]}, {"block": 55, "type": "code", "linesLength": 2, "startIndex": 247, "lines": ["with open('linear_results.pkl', 'rb') as f:\n", "    pickle.loads(f.read())"]}, {"block": 56, "type": "code", "linesLength": 2, "startIndex": 249, "lines": ["series = df['PrimClass_Jolie'].copy().dropna()\n", "series.iplot()"]}, {"block": 57, "type": "code", "linesLength": 2, "startIndex": 251, "lines": ["data = pd.concat([series, create_time_features(series.index, cyc_encode=True)], axis=1)\n", "data.head()"]}, {"block": 58, "type": "code", "linesLength": 2, "startIndex": 253, "lines": ["data = data.rename(columns={series.name: 'measurement'})\n", "monthly_validation(data, model, track=True)"]}, {"block": 59, "type": "code", "linesLength": 1, "startIndex": 255, "lines": ["model.fit(data.drop(columns=['measurement']), data['measurement'])"]}, {"block": 60, "type": "code", "linesLength": 1, "startIndex": 256, "lines": ["preds = model.predict(data.drop(columns=['measurement']))"]}, {"block": 61, "type": "code", "linesLength": 1, "startIndex": 257, "lines": ["preds"]}, {"block": 62, "type": "code", "linesLength": 1, "startIndex": 258, "lines": ["np.mean(np.abs((preds - data['measurement']) / data['measurement']))"]}, {"block": 63, "type": "code", "linesLength": 0, "startIndex": 259, "lines": []}]