[{"block": 0, "type": "markdown", "linesLength": 3, "startIndex": 0, "lines": ["# Introduction: Logistic Regression\n", "\n", "The purpose of this notebook is to gain an understanding of the simple method of logistic regression. Logistic regression is generally considered the simplest method of classification, but can still be a powerful and explainable algorithm."]}, {"block": 1, "type": "code", "linesLength": 20, "startIndex": 3, "lines": ["# Standard Data Science Helpers\n", "import numpy as np\n", "import pandas as pd\n", "import scipy\n", "\n", "import plotly.plotly as py\n", "import plotly.graph_objs as go\n", "from plotly.offline import iplot, init_notebook_mode\n", "init_notebook_mode(connected=True)\n", "\n", "import cufflinks as cf\n", "cf.set_config_file(world_readable=True, theme=\"pearl\")\n", "cf.go_offline(connected=True)\n", "\n", "# Extra options\n", "pd.options.display.max_rows = 10\n", "pd.options.display.max_columns = 25\n", "# Show all code cells outputs\n", "from IPython.core.interactiveshell import InteractiveShell\n", "InteractiveShell.ast_node_interactivity = 'all'"]}, {"block": 2, "type": "code", "linesLength": 27, "startIndex": 23, "lines": ["original_data = pd.read_csv('data/adult_income.csv')\n", "\n", "def process_data(data):\n", "    \"\"\"\n", "    Process the adult income dataset\n", "    \"\"\"\n", "    data = data.copy()\n", "    # Replace missing values\n", "    data = data.replace({' ?': np.nan})\n", "    \n", "    # Code gender\n", "    data['female'] = data['sex'].replace({' Male': 0, ' Female': 1})\n", "    # Code target\n", "    data['target'] = data['target'].replace({' >50K': 1, ' <=50K': 0})\n", "    # Create single column for capital wealth\n", "    data['capital'] = data['capital_gain'] - data['capital_loss']\n", "    to_drop = ['country', 'education', 'sex', \n", "           'capital_gain', 'capital_loss', \n", "           'working_class',\n", "          'race', 'occupation']\n", "    # Remove excess columns\n", "    data = data.drop(columns=to_drop)\n", "    data = pd.get_dummies(data)\n", "    return data\n", "\n", "data = process_data(original_data)\n", "data.info()"]}, {"block": 3, "type": "code", "linesLength": 2, "startIndex": 50, "lines": ["corrs = data.corr()\n", "corrs['target']"]}, {"block": 4, "type": "code", "linesLength": 6, "startIndex": 52, "lines": ["import plotly.figure_factory as ff\n", "from plotly.offline import iplot\n", "\n", "# Correlation Heatmap\n", "iplot(ff.create_annotated_heatmap(corrs.iloc[:10, :10].round(3).values, x=list(corrs.iloc[:10, :10].columns), \n", "                                  y=list(corrs.iloc[:10, :10].index), annotation_text=corrs.iloc[:10, :10].round(3).values))\n"]}, {"block": 5, "type": "code", "linesLength": 13, "startIndex": 58, "lines": ["from sklearn.linear_model import LogisticRegressionCV\n", "from sklearn.model_selection import train_test_split\n", "\n", "# Features and target\n", "X = data.copy()\n", "y = X.pop('target')\n", "\n", "# Split into training and testing\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n", "\n", "# Create the model\n", "model = LogisticRegressionCV(Cs=10, cv = 3, scoring='roc_auc', n_jobs=-1, verbose=1, random_state=42)\n", "model.fit(X_train, y_train)"]}, {"block": 6, "type": "markdown", "linesLength": 1, "startIndex": 71, "lines": ["## Metrics"]}, {"block": 7, "type": "code", "linesLength": 21, "startIndex": 72, "lines": ["from sklearn.metrics import f1_score, roc_auc_score\n", "\n", "def evaluate(model, X_test, y_test):\n", "    \"\"\"\n", "    Test a model on a few classification metrics.\n", "    \"\"\"\n", "    # Predictions and probabilities\n", "    predictions = model.predict(X_test)\n", "    probabilities = model.predict_proba(X_test)[:, 1]\n", "    roc_auc = roc_auc_score(y_test, probabilities)\n", "    f1_value = f1_score(y_test, predictions)\n", "    accuracy = np.mean(predictions == y_test)\n", "    \n", "    # Get a baseline\n", "    base_accuracy = np.mean(y_test == 0)\n", "    print(f'ROC AUC: {roc_auc:.4f}')\n", "    print(f'F1 Score: {f1_value:.4f}')\n", "    print(f'Accuracy: {100 * accuracy:.2f}%')\n", "    print(f'Baseline Accuracy: {100 * base_accuracy:.2f}%')\n", "    \n", "evaluate(model, X_test, y_test)"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 93, "lines": ["# Model Outputs"]}, {"block": 9, "type": "code", "linesLength": 3, "startIndex": 94, "lines": ["probability = model.predict_proba(X_test)[:, 1]\n", "log_odds = model.decision_function(X_test)\n", "classes = model.predict(X_test)"]}, {"block": 10, "type": "code", "linesLength": 2, "startIndex": 97, "lines": ["yhat = pd.DataFrame(dict(probability=probability, log_odds=log_odds, classes=classes))\n", "yhat.describe()"]}, {"block": 11, "type": "markdown", "linesLength": 1, "startIndex": 99, "lines": ["# Converting Between Log Odds and Probabilities"]}, {"block": 12, "type": "code", "linesLength": 10, "startIndex": 100, "lines": ["log_odds = yhat['log_odds']\n", "\n", "# Exponentiate the log odds\n", "odds_ratio = np.exp(log_odds)\n", "\n", "# Calculate the probabilitiy\n", "probability = odds_ratio / (1 + odds_ratio)\n", "\n", "# Sanity check\n", "np.allclose(probability, yhat['probability'].values)"]}, {"block": 13, "type": "markdown", "linesLength": 1, "startIndex": 110, "lines": ["# Visualization of Log Odds and Probabilities"]}, {"block": 14, "type": "code", "linesLength": 7, "startIndex": 111, "lines": ["log_odds = yhat['log_odds']\n", "\n", "# Apply sigmoid function by hand\n", "probability = 1 / (1 + np.exp(-log_odds))\n", "\n", "# Check\n", "np.allclose(probability, yhat['probability'].values)"]}, {"block": 15, "type": "code", "linesLength": 2, "startIndex": 118, "lines": ["yhat['odds_ratio'] = odds_ratio\n", "yhat['classes'] = yhat['classes'].map({0: '< 50K', 1: '>= 50K'})"]}, {"block": 16, "type": "code", "linesLength": 3, "startIndex": 120, "lines": ["yhat.sample(1000).iplot(x='log_odds', y='probability', \n", "           yTitle='Probability', xrange=(-5, 5), xTitle='Log Odds',\n", "           title='Probability vs Log Odds', categories='classes')"]}, {"block": 17, "type": "code", "linesLength": 3, "startIndex": 123, "lines": ["yhat.sample(1000).iplot(x='log_odds', y='odds_ratio', \n", "           yTitle='odds_ratio', xrange=(-2, 4), yrange=(0,15),\n", "           title='Odds Ratio vs Log Odds', categories='classes')"]}, {"block": 18, "type": "code", "linesLength": 3, "startIndex": 126, "lines": ["yhat.sample(1000).iplot(x='odds_ratio', y='probability', xTitle='Odds Ratio', yTitle='Probability', \n", "                        title='Probability vs Odds Ratio', \n", "                        mode='markers', xrange=(0, 10))"]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 129, "lines": ["yhat.sort_values('probability').sample(1000)"]}, {"block": 20, "type": "code", "linesLength": 3, "startIndex": 130, "lines": ["yhat.sort_values('probability').sample(1000).iplot(x='probability', mode='markers',\n", "                                                   yrange=(0, 10), xTitle='Probability', yTitle='Odds',\n", "                                                   title=\"Odds and Log Odds vs Probability\")"]}, {"block": 21, "type": "code", "linesLength": 5, "startIndex": 133, "lines": ["from sklearn.ensemble import RandomForestClassifier\n", "\n", "model = RandomForestClassifier()\n", "_=model.fit(X_train, y_train)\n", "evaluate(model, X_test, y_test)"]}, {"block": 22, "type": "code", "linesLength": 3, "startIndex": 138, "lines": ["model = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=50)\n", "_ = model.fit(X_train, y_train)\n", "evaluate(model, X_test, y_test)"]}, {"block": 23, "type": "code", "linesLength": 0, "startIndex": 141, "lines": []}]