[{"block": 0, "type": "markdown", "linesLength": 3, "startIndex": 0, "lines": ["# Introduction: Data Analysis of Medium Articles\n", "\n", "In this notebook, we'll do some basic data analysis of my medium articles. This is meant as a fun exercise that can also teach us a little about dealing with `HTML` files and making effective visuals."]}, {"block": 1, "type": "code", "linesLength": 19, "startIndex": 3, "lines": ["# Data science imports\n", "import pandas as pd\n", "import numpy as np\n", "\n", "# Options for pandas\n", "pd.options.display.max_columns = 20\n", "\n", "# Display all cell outputs\n", "from IPython.core.interactiveshell import InteractiveShell\n", "InteractiveShell.ast_node_interactivity = 'all'\n", "\n", "# Interactive plotting\n", "import plotly.plotly as py\n", "import plotly.graph_objs as go\n", "from plotly.offline import iplot\n", "import cufflinks\n", "cufflinks.go_offline()\n", "\n", "from timeit import default_timer as timer"]}, {"block": 2, "type": "markdown", "linesLength": 3, "startIndex": 22, "lines": ["# Parsing HTML with BeautifulSoup\n", "\n", "BeautifulSoup is the go-to method in Python for parsing HTML. To make a structured object (soup) out of HTML, we simply need to pass in the raw HTML. "]}, {"block": 3, "type": "code", "linesLength": 4, "startIndex": 25, "lines": ["from bs4 import BeautifulSoup\n", "\n", "soup = BeautifulSoup(open('data/published.html', 'r').read())\n", "soup.text[:100]"]}, {"block": 4, "type": "markdown", "linesLength": 3, "startIndex": 29, "lines": ["## Find All Articles\n", "\n", "Finding what we want from the soup is as easy as searching for different elements by the HTML tag or different attributes such as the `class`. Here we'll find all the entries on this page (which includes actual articles as well as responses). "]}, {"block": 5, "type": "code", "linesLength": 2, "startIndex": 32, "lines": ["entries = soup.find_all(attrs = {'class': 'bq y br af bs ag db dc dd c de df dg'})\n", "print(f'Found {len(entries)} entries.')"]}, {"block": 6, "type": "code", "linesLength": 1, "startIndex": 34, "lines": ["entries[-1]"]}, {"block": 7, "type": "markdown", "linesLength": 1, "startIndex": 35, "lines": ["(The [above article](https://medium.com/@williamkoehrsen/screw-the-environment-but-consider-your-wallet-a4f7cd3d3161) is one of my favorites!)"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 36, "lines": ["Later, we'll be able to sort out the articles because their pages have an `h1` header tag. For now, let's scrape the page for the title text and the reading times of all entries."]}, {"block": 9, "type": "code", "linesLength": 2, "startIndex": 37, "lines": ["titles = [e.text for e in entries]\n", "titles[-1]"]}, {"block": 10, "type": "markdown", "linesLength": 3, "startIndex": 39, "lines": ["## Find Reading Times\n", "\n", "The reading times can be extracted using a regular expression. We'll match the text to a regular expression."]}, {"block": 11, "type": "code", "linesLength": 3, "startIndex": 42, "lines": ["import re\n", "pattern = re.compile('[0-9]{1,} min read')\n", "pattern.findall(string = '15 min read')"]}, {"block": 12, "type": "code", "linesLength": 2, "startIndex": 45, "lines": ["read_times = soup.find_all(text = pattern)\n", "print(f'Found {len(read_times)} read times.')"]}, {"block": 13, "type": "markdown", "linesLength": 1, "startIndex": 47, "lines": ["Now for the best part: the total reading time of all articles. "]}, {"block": 14, "type": "code", "linesLength": 3, "startIndex": 48, "lines": ["read_times = [int(x.split(' ')[0]) for x in read_times]\n", "total_read_time = sum(read_times)\n", "print(f'Total Read Time of Entries: {total_read_time} minutes.')"]}, {"block": 15, "type": "markdown", "linesLength": 1, "startIndex": 51, "lines": ["This is somewhat inflated because some of these are responses. Later, we'll be able to sort out the responses."]}, {"block": 16, "type": "code", "linesLength": 5, "startIndex": 52, "lines": ["data = go.Histogram(x = read_times, xbins=dict(size=1), marker=dict(line=dict(color='black', width=1.2)))\n", "layout = go.Layout(title='Histogram of Read Times', \n", "                   yaxis=dict(title='Count'),\n", "                   xaxis=dict(title='Reading Time (minutes)'))\n", "figure = go.Figure(data=[data], layout=layout)"]}, {"block": 17, "type": "code", "linesLength": 1, "startIndex": 57, "lines": ["iplot(figure)"]}, {"block": 18, "type": "markdown", "linesLength": 3, "startIndex": 58, "lines": ["## Retrieving Articles\n", "\n", "Now that we have the basic metadata, we want to get the articles themselves. For this, we'll find the links associated with each entry. "]}, {"block": 19, "type": "code", "linesLength": 3, "startIndex": 61, "lines": ["entry_links = [entry.a.get_attribute_list('href')[0] for entry in entries]\n", "entry_links[-1]\n", "len(entry_links)"]}, {"block": 20, "type": "markdown", "linesLength": 1, "startIndex": 64, "lines": ["We can use the great `requests` library to retrieve all of the information on each of these linked pages."]}, {"block": 21, "type": "code", "linesLength": 7, "startIndex": 65, "lines": ["import requests\n", "\n", "entries = []\n", "for a in entry_links[:10]:\n", "    entries.append(requests.get(a).content)\n", "    \n", "entries[0][:10]"]}, {"block": 22, "type": "markdown", "linesLength": 1, "startIndex": 72, "lines": ["## Parsing Articles"]}, {"block": 23, "type": "markdown", "linesLength": 1, "startIndex": 73, "lines": ["We now have each entry as an HTML page. We can take the same approach as we did with the overall page to scrape whatever information we want. For example, we can find all the paragraphs on the page with the following:"]}, {"block": 24, "type": "code", "linesLength": 3, "startIndex": 74, "lines": ["entry_soup = BeautifulSoup(entries[0])\n", "entry_text = [p.text for p in entry_soup.find_all('p')]\n", "entry_text[0]"]}, {"block": 25, "type": "markdown", "linesLength": 1, "startIndex": 77, "lines": ["We can convert this to a single string with `join`. A rough word count can be found by then splitting this on spaces."]}, {"block": 26, "type": "code", "linesLength": 3, "startIndex": 78, "lines": ["entry_text = ' '.join(entry_text)\n", "word_count = len(entry_text.split(' '))\n", "print(f'There are {word_count} words in this article.')"]}, {"block": 27, "type": "markdown", "linesLength": 1, "startIndex": 81, "lines": ["We can also get the reading time (again) with a little parsing."]}, {"block": 28, "type": "code", "linesLength": 4, "startIndex": 82, "lines": ["read_time = entry_soup.find_all(attrs={'class': 'readingTime'})\n", "read_time[0].get('title')\n", "\n", "read_mins = int(read_time[0].get('title').split(' ')[0])"]}, {"block": 29, "type": "markdown", "linesLength": 3, "startIndex": 86, "lines": ["### Number of Claps\n", "\n", "The number of claps is hidden within an obscure class, but we can get it using this:"]}, {"block": 30, "type": "code", "linesLength": 12, "startIndex": 89, "lines": ["clap_pattern = re.compile('^[0-9]{1,} claps|^[0-9]{1,}.[0-9]{1,}K claps|^[0-9]{1,}K claps')\n", "claps = entry_soup.find_all(text = clap_pattern)\n", "\n", "if len(claps) > 0:\n", "    if 'K' in claps[0]:\n", "        clap_number = int(1e3 * float(claps[0].split('K')[0]))\n", "    else:\n", "        clap_number = int(claps[0].split(' ')[0])\n", "else:\n", "    clap_number = 0\n", "    \n", "claps"]}, {"block": 31, "type": "markdown", "linesLength": 3, "startIndex": 101, "lines": ["## Determining Responses vs Articles\n", "\n", "The easiest way to figure out if an entry is a response or an article is to search for the `h1` header."]}, {"block": 32, "type": "code", "linesLength": 6, "startIndex": 104, "lines": ["if entry_soup.h1 is not None:\n", "    title = entry_soup.h1.text\n", "else:\n", "    title = 'response'\n", "    \n", "print(f'Found title: \"{title}\"')"]}, {"block": 33, "type": "markdown", "linesLength": 1, "startIndex": 110, "lines": ["To store all this information, let's use one of my favorite Python data types, a dictionary."]}, {"block": 34, "type": "code", "linesLength": 6, "startIndex": 111, "lines": ["from collections import defaultdict\n", "entry_dict = defaultdict(dict)\n", "entry_dict[title]['text'] = entry_text\n", "entry_dict[title]['word_count'] = word_count\n", "entry_dict[title]['clap_count'] = clap_number\n", "entry_dict[title]['read_time'] = read_mins"]}, {"block": 35, "type": "code", "linesLength": 1, "startIndex": 117, "lines": ["entry_dict.keys()"]}, {"block": 36, "type": "markdown", "linesLength": 3, "startIndex": 118, "lines": ["## Finding Published Time\n", "\n", "Another piece of information we may want is the published time of the article. This is simple enough to get."]}, {"block": 37, "type": "code", "linesLength": 2, "startIndex": 121, "lines": ["t = entry_soup.find_all('time')[0]\n", "t.get('datetime')"]}, {"block": 38, "type": "markdown", "linesLength": 1, "startIndex": 123, "lines": ["This is the time in UTC. We can use Pandas to convert to the local time of publication."]}, {"block": 39, "type": "code", "linesLength": 1, "startIndex": 124, "lines": ["pd.to_datetime(t.get('datetime'), utc=True).tz_convert('America/New_York')"]}, {"block": 40, "type": "markdown", "linesLength": 1, "startIndex": 125, "lines": ["(I didn't publish all of my articles in the eastern time zone, most were published in the midwest. However, I'm not sure how to get geographic information from these pages, so for now we'll just localize using Eastern time)."]}, {"block": 41, "type": "markdown", "linesLength": 3, "startIndex": 126, "lines": ["## Number of Responses\n", "\n", "As another piece of information, let's find the number of responses to the article."]}, {"block": 42, "type": "code", "linesLength": 4, "startIndex": 129, "lines": ["responses = entry_soup.find_all(attrs={'class': 'button button--chromeless u-baseColor--buttonNormal u-marginRight12'})\n", "responses\n", "\n", "n_responses = int(responses[0].text)"]}, {"block": 43, "type": "markdown", "linesLength": 3, "startIndex": 133, "lines": ["## Tags for Article\n", "\n", "The final piece of information we'll retrieve about the article is the tags associated with it. These are also easy to grab."]}, {"block": 44, "type": "code", "linesLength": 3, "startIndex": 136, "lines": ["tags = entry_soup.find_all(attrs={'class': 'tags tags--postTags tags--borderless'})\n", "tags = [li.text for li in tags[0].find_all('li')]\n", "tags"]}, {"block": 45, "type": "code", "linesLength": 2, "startIndex": 139, "lines": ["entry_dict[title]['num_responses'] = n_responses\n", "entry_dict[title]['tags'] = tags"]}, {"block": 46, "type": "markdown", "linesLength": 1, "startIndex": 141, "lines": ["At this point we have quick a lot of information about each entry. In the case where the entry is a response, we won't be able to gather as much data, but we are mostly focused on the articles anyway."]}, {"block": 47, "type": "code", "linesLength": 2, "startIndex": 142, "lines": ["import pprint\n", "pprint.pprint({key: value for key, value in entry_dict[title].items() if key != 'text'})"]}, {"block": 48, "type": "markdown", "linesLength": 3, "startIndex": 144, "lines": ["# Function for Parsing Articles\n", "\n", "We'll put all of the above steps into a single function that can grab the information from all the entries if passed a list of entry links. The return will be a dictionary containing the complete data about each entry."]}, {"block": 49, "type": "code", "linesLength": 75, "startIndex": 147, "lines": ["def get_entries(entry_links):\n", "    \"\"\"\n", "    Retrieve data of all entries in a list of links.\n", "    \n", "    :param entry_links: list of strings for links to entries\n", "    \n", "    :return entries: dictionary with information about each entry\n", "    \"\"\"\n", "    \n", "    entry_dict = defaultdict(dict)\n", "    n_words = 0\n", "    \n", "    response_count = 0\n", "    # Iterate through all links\n", "    for i, link in enumerate(entry_links):\n", "        \n", "        # Tracking progress\n", "        if (i + 1) % 5 == 0:\n", "            print(f'{100 * i / len(entry_links):.2f}% complete. Total words = {n_words}.', end = '\\r')\n", "        \n", "        # Retrieve the article and create a soup\n", "        entry = requests.get(link).content\n", "        entry_soup = BeautifulSoup(entry)\n", "        \n", "        # Publication time\n", "        t = entry_soup.find_all('time')[0]\n", "        t = pd.to_datetime(t.get('datetime'), utc=True).tz_convert('America/New_York')\n", "        \n", "        # Find the title header (determines if an article or a response)\n", "        if entry_soup.h1 is not None:\n", "            title = entry_soup.h1.text\n", "        else:\n", "            title = f'response-{t}'\n", "            response_count += 1\n", "            \n", "        # Text as single long string\n", "        entry_text = [p.text for p in entry_soup.find_all('p')]\n", "        entry_text = ' '.join(entry_text)\n", "        \n", "        # Word count\n", "        word_count = len(entry_text.split(' '))\n", "        n_words += word_count\n", "        \n", "        # Reading time in minutes\n", "        read_time = entry_soup.find_all(attrs={'class': 'readingTime'})\n", "        read_mins = int(read_time[0].get('title').split(' ')[0])\n", "        \n", "        # Number of claps\n", "        clap_pattern = re.compile('^[0-9]{1,} claps|^[0-9]{1,}.[0-9]{1,}K claps|^[0-9]{1,}K claps')\n", "        claps = entry_soup.find_all(text = clap_pattern)\n", "\n", "        if len(claps) > 0:\n", "            if 'K' in claps[0]:\n", "                clap_number = int(1e3 * float(claps[0].split('K')[0]))\n", "            else:\n", "                clap_number = int(claps[0].split(' ')[0])\n", "        else:\n", "            clap_number = 0\n", "            \n", "        # Post tags\n", "        tags = entry_soup.find_all(attrs={'class': 'tags tags--postTags tags--borderless'})\n", "        tags = [li.text for li in tags[0].find_all('li')]\n", "        \n", "        # Store in dictionary with title as key\n", "        entry_dict[title]['text'] = entry_text\n", "        entry_dict[title]['word_count'] = word_count\n", "        entry_dict[title]['read_time'] = read_mins\n", "        entry_dict[title]['claps'] = clap_number\n", "        entry_dict[title]['time_published'] = t\n", "        entry_dict[title]['tags'] = tags\n", "        \n", "    print(f'Found {len(entry_dict) - response_count} articles and {response_count} responses.')\n", "    print(f'Total words: {n_words}.')\n", "    \n", "    return entry_dict"]}, {"block": 50, "type": "code", "linesLength": 3, "startIndex": 222, "lines": ["entry_soup = BeautifulSoup(requests.get('https://medium.com/@williamkoehrsen/one-of-the-best-parts-about-featuretools-is-that-its-not-constrained-by-human-limits-on-creativity-daa0b40406d6').content)\n", "clap_pattern = re.compile('^[0-9]{1,} claps')\n", "entry_soup.find_all(text=clap_pattern)"]}, {"block": 51, "type": "code", "linesLength": 3, "startIndex": 225, "lines": ["start = timer()\n", "entry_dict = get_entries(entry_links=entry_links)\n", "end = timer()"]}, {"block": 52, "type": "code", "linesLength": 1, "startIndex": 228, "lines": ["print(f'This operation took {end - start:.0f} seconds.')"]}, {"block": 53, "type": "markdown", "linesLength": 3, "startIndex": 229, "lines": ["## Aside: Parallelizing Operation\n", "\n", "If we want to make this go a little faster, was can parallelize the function. Instead of writing a function that takes in all of the links at once, we write a function to take in a single link and then `map` this function to workers."]}, {"block": 54, "type": "code", "linesLength": 63, "startIndex": 232, "lines": ["def process_entry(link):\n", "    \"\"\"\n", "    Retrieve data of single entry.\n", "    \n", "    :param link: string for link to entry\n", "    \n", "    :return entry_dict: dictionary of data about entry\n", "    \"\"\"\n", "    \n", "    entry_dict = {}\n", "     \n", "    # Retrieve the article and create a soup\n", "    entry = requests.get(link).content\n", "    entry_soup = BeautifulSoup(entry)\n", "    \n", "    # Publication time\n", "    t = entry_soup.find_all('time')[0]\n", "    t = pd.to_datetime(t.get('datetime'), utc=True).tz_convert('America/New_York')\n", "\n", "    # Find the title header (determines if an article or a response)\n", "    if entry_soup.h1 is not None:\n", "        title = entry_soup.h1.text\n", "    else:\n", "        title = f'response-{t}'\n", "\n", "    # Text as single long string\n", "    entry_text = [p.text for p in entry_soup.find_all('p')]\n", "    entry_text = ' '.join(entry_text)\n", "\n", "    # Word count\n", "    word_count = len(entry_text.split(' '))\n", "\n", "    # Reading time in minutes\n", "    read_time = entry_soup.find_all(attrs={'class': 'readingTime'})\n", "    read_mins = int(read_time[0].get('title').split(' ')[0])\n", "\n", "    # Number of claps\n", "    clap_pattern = re.compile('^[0-9]{1,} claps|^[0-9]{1,}.[0-9]{1,}K claps|^[0-9]{1,}K claps')\n", "    claps = entry_soup.find_all(text = clap_pattern)\n", "\n", "    if len(claps) > 0:\n", "        if 'K' in claps[0]:\n", "            clap_number = int(1e3 * float(claps[0].split('K')[0]))\n", "        else:\n", "            clap_number = int(claps[0].split(' ')[0])\n", "    else:\n", "        clap_number = 0\n", "\n", "    # Post tags\n", "    tags = entry_soup.find_all(attrs={'class': 'tags tags--postTags tags--borderless'})\n", "    tags = [li.text for li in tags[0].find_all('li')]\n", "        \n", "    # Store in dictionary with title as key\n", "    entry_dict['title'] = title\n", "    entry_dict['text'] = entry_text\n", "    entry_dict['word_count'] = word_count\n", "    entry_dict['read_time'] = read_mins\n", "    entry_dict['claps'] = clap_number\n", "    entry_dict['time_published'] = t\n", "    entry_dict['tags'] = tags\n", "        \n", "    \n", "    return entry_dict"]}, {"block": 55, "type": "code", "linesLength": 18, "startIndex": 295, "lines": ["from multiprocessing import Pool\n", "\n", "\n", "pool = Pool(processes=20)\n", "results = []\n", "\n", "start = timer()\n", "for i, result in enumerate(pool.imap_unordered(process_entry, entry_links)):\n", "    if (i + 1) % 5 == 0:\n", "        print(f'{100 * i / len(entry_links):.2f}% complete.', end='\\r')\n", "    results.append(result)\n", "    \n", "pool.close()\n", "pool.join()\n", "end = timer()\n", "\n", "results[0]['title']\n", "results[0]['word_count']"]}, {"block": 56, "type": "code", "linesLength": 1, "startIndex": 313, "lines": ["print(f'With multiprocessing this operation took {end - start:.0f} seconds.')"]}, {"block": 57, "type": "markdown", "linesLength": 3, "startIndex": 314, "lines": ["## Function for Parallel Processing\n", "\n", "Considering how much faster processing these articles is in parallel, we probably want to do that from now on! "]}, {"block": 58, "type": "code", "linesLength": 27, "startIndex": 317, "lines": ["def process_in_parallel(links, processes=20):\n", "    \"\"\"\n", "    Process entries in parallel\n", "    \n", "    :param links: list of entry links\n", "    :param processes: integer number of processes (threads) to use in parallel\n", "    \n", "    :return results: list of dictionaries of entry data\n", "    \"\"\"\n", "    pool = Pool(processes=processes)\n", "    results = []\n", "\n", "    start = timer()\n", "    for i, result in enumerate(pool.imap_unordered(process_entry, links)):\n", "        if (i + 1) % 5 == 0:\n", "            print(f'{100 * i / len(links):.2f}% complete.', end='\\r')\n", "        results.append(result)\n", "\n", "    pool.close()\n", "    pool.join()\n", "    end = timer()\n", "    \n", "    print(f'Processed {len(results)} entries in {end-start:.0f} seconds.')\n", "    \n", "    df = pd.DataFrame.from_dict(results)\n", "    df['response'] = ['response' if x == True else 'article' for x in df['title'].str.contains('response')]\n", "    return df"]}, {"block": 59, "type": "code", "linesLength": 1, "startIndex": 344, "lines": ["entry_data = process_in_parallel(entry_links, processes=50)"]}, {"block": 60, "type": "markdown", "linesLength": 3, "startIndex": 345, "lines": ["## Dataframe of Results\n", "\n", "Converting this dictionary to a dataframe is relatively simple (and was done in the function). We just need to call `DataFrame.from_dict` and each of the rows will be an article with the columns containing the data. This puts the dataframe in the familiar wide format which is best for plotting. We can also make a column indicating if the entry was a response or an article."]}, {"block": 61, "type": "code", "linesLength": 1, "startIndex": 348, "lines": ["entry_data.head()"]}, {"block": 62, "type": "code", "linesLength": 12, "startIndex": 349, "lines": ["data = [go.Histogram(x=list(entry_data.loc[entry_data['response'] == 'article', 'word_count']), \n", "                     name='article', marker=dict(color = 'blue', line=dict(color='black', width=1.1))),\n", "        go.Histogram(x=list(entry_data.loc[entry_data['response'] == 'response', 'word_count']), \n", "                     name='response', marker=dict(color = 'green', line=dict(color='black', width=1.1)))]\n", "        \n", "layout = go.Layout(title='Histogram of Word Counts', xaxis=dict(title='word count',\n", "                                                                tickfont=dict(size=14),\n", "                                                                titlefont=dict(size=16)),\n", "                   yaxis=dict(title='Count', tickfont=dict(size=14),\n", "                              titlefont=dict(size=16)))\n", "\n", "figure = go.Figure(data=data, layout=layout)"]}, {"block": 63, "type": "code", "linesLength": 1, "startIndex": 361, "lines": ["iplot(figure)"]}, {"block": 64, "type": "code", "linesLength": 2, "startIndex": 362, "lines": ["entry_data.iplot(x='time_published', y='word_count', opacity=0.75, mode='markers', xTitle='Date', yTitle='num_words',\n", "           title='Number of Words vs Date', text = 'title', categories='response')"]}, {"block": 65, "type": "markdown", "linesLength": 3, "startIndex": 364, "lines": ["## Interactive Plots\n", "\n", "With plotly, we can very easily add options to select `response` or `articles`."]}, {"block": 66, "type": "code", "linesLength": 28, "startIndex": 367, "lines": ["base_title = 'Word Counts'\n", "\n", "updatemenus = list([\n", "    dict(\n", "        buttons=list([\n", "            dict(\n", "                label='both', method='update', \n", "                args=[dict(visible=[True, True]), dict(title = base_title)]),\n", "            dict(\n", "                label='articles',\n", "                method='update',\n", "                args=[dict(visible=[True, False]), dict(title = 'Article ' + base_title)]),\n", "            dict(\n", "                label='responses',\n", "                method='update',\n", "                args=[dict(visible=[False, True]), dict(title='Response ' + base_title)])\n", "        ]))\n", "])\n", "\n", "layout = go.Layout(\n", "    title=base_title,\n", "    xaxis=dict(\n", "        title='word count', tickfont=dict(size=14), titlefont=dict(size=16)),\n", "    yaxis=dict(title='Count', tickfont=dict(size=14), titlefont=dict(size=16)),\n", "    updatemenus=updatemenus)\n", "\n", "figure = go.Figure(data=data, layout=layout)\n", "iplot(figure)"]}, {"block": 67, "type": "code", "linesLength": 3, "startIndex": 395, "lines": ["entry_data['claps_per_word'] = entry_data['claps'] / entry_data['word_count']\n", "responses = entry_data[entry_data['response'] == 'response'].copy()\n", "articles = entry_data[entry_data['response'] == 'article'].copy()"]}, {"block": 68, "type": "markdown", "linesLength": 1, "startIndex": 398, "lines": ["We can add this interactivity to any plot because the updatemenu was written to apply to all the data."]}, {"block": 69, "type": "code", "linesLength": 18, "startIndex": 399, "lines": ["def make_update_menu(base_title):\n", "    updatemenus = list([\n", "    dict(\n", "        buttons=list([\n", "            dict(\n", "                label='both', method='update', \n", "                args=[dict(visible=[True, True]), dict(title = base_title)]),\n", "            dict(\n", "                label='articles',\n", "                method='update',\n", "                args=[dict(visible=[True, False]), dict(title = 'Article ' + base_title)]),\n", "            dict(\n", "                label='responses',\n", "                method='update',\n", "                args=[dict(visible=[False, True]), dict(title='Response ' + base_title)])\n", "        ]))\n", "    ])\n", "    return updatemenus\n"]}, {"block": 70, "type": "markdown", "linesLength": 3, "startIndex": 417, "lines": ["## Function To Make Interactive Plots\n", "\n", "We can write a short function that will automatically make these interactive plots for us. All we have to do is pass in the `x` and `y` arguments along with a title. "]}, {"block": 71, "type": "code", "linesLength": 1, "startIndex": 420, "lines": ["go.layout.YAxis()"]}, {"block": 72, "type": "code", "linesLength": 80, "startIndex": 421, "lines": ["def make_iplot(data, x, y, base_title, time=False):\n", "    \"\"\"\n", "    Make an interactive plot. Adds a dropdown to separate articles from responses\n", "    if there are responses in the data\n", "    \n", "    :param\n", "    \n", "    \"\"\"\n", "\n", "    responses = data[data['response'] == 'response'].copy()\n", "    articles = data[data['response'] == 'article'].copy()\n", "\n", "    if not responses.empty:\n", "        plot_data = [\n", "            go.Scatter(\n", "                x=articles[x],\n", "                y=articles[y],\n", "                mode='markers',\n", "                name='articles',\n", "                text=articles['title'],\n", "                marker=dict(color='blue', size=12)),\n", "            go.Scatter(\n", "                x=responses[x],\n", "                y=responses[y],\n", "                mode='markers',\n", "                name='responses',\n", "                marker=dict(color='green', size=12))\n", "        ]\n", "\n", "        layout = go.Layout(\n", "            title=base_title,\n", "            xaxis=dict(\n", "                title=x.title(),\n", "                tickfont=dict(size=14),\n", "                titlefont=dict(size=16)),\n", "            yaxis=dict(\n", "                autorange=True,\n", "                title=y.title(),\n", "                tickfont=dict(size=14),\n", "                titlefont=dict(size=16)),\n", "            updatemenus=make_update_menu(base_title))\n", "\n", "    else:\n", "        plot_data = [\n", "            go.Scatter(\n", "                x=data[x],\n", "                y=data[y],\n", "                mode='markers',\n", "                text=data['title'],\n", "                marker=dict(color='blue', size=12))\n", "        ]\n", "\n", "        layout = go.Layout(\n", "            title=base_title,\n", "            xaxis=dict(\n", "                title=x.title(),\n", "                tickfont=dict(size=14),\n", "                titlefont=dict(size=16)),\n", "            yaxis=dict(\n", "                autorange=True,\n", "                title=y.title(),\n", "                tickfont=dict(size=14),\n", "                titlefont=dict(size=16)))\n", "\n", "    if time:\n", "        rangeselector = dict(\n", "            buttons=list([\n", "                dict(count=1, label='1m', step='month', stepmode='backward'),\n", "                dict(count=6, label='6m', step='month', stepmode='backward'),\n", "                dict(count=1, label='YTD', step='year', stepmode='todate'),\n", "                dict(count=1, label='1y', step='year', stepmode='backward'),\n", "                dict(step='all')\n", "            ]))\n", "        rangeslider = dict(visible=True)\n", "        layout['xaxis']['rangeselector'] = rangeselector\n", "        layout['xaxis']['rangeslider'] = rangeslider\n", "\n", "    figure = go.FigureWidget(data=plot_data, layout=layout)\n", "\n", "    return figure"]}, {"block": 73, "type": "code", "linesLength": 2, "startIndex": 501, "lines": ["figure = make_iplot(entry_data, 'time_published', 'word_count', 'Word Count over Time')\n", "iplot(figure)"]}, {"block": 74, "type": "code", "linesLength": 2, "startIndex": 503, "lines": ["figure = make_iplot(articles, 'time_published', 'word_count', 'Word Count over Time', time=True)\n", "iplot(figure)"]}, {"block": 75, "type": "code", "linesLength": 2, "startIndex": 505, "lines": ["articles.sort_values('time_published', inplace=True)\n", "articles.reset_index(inplace=True)"]}, {"block": 76, "type": "code", "linesLength": 7, "startIndex": 507, "lines": ["def zoom(layout, xrange):\n", "    in_view = articles.loc[articles['time_published'].between(figure.layout.xaxis.range[0], \n", "                                                              figure.layout.xaxis.range[1])].copy()\n", "    figure.layout.yaxis.range = [in_view['word_count'].min() - 2000, in_view['word_count'].max() + 2000]\n", "\n", "figure.layout.on_change(zoom, 'xaxis.range')\n", "figure"]}, {"block": 77, "type": "code", "linesLength": 2, "startIndex": 514, "lines": ["figure = make_iplot('time_published', 'claps', 'Claps over Time')\n", "iplot(figure)"]}, {"block": 78, "type": "code", "linesLength": 2, "startIndex": 516, "lines": ["figure = make_iplot('read_time', 'claps', 'Number of Claps vs Read Time')\n", "iplot(figure)"]}, {"block": 79, "type": "code", "linesLength": 2, "startIndex": 518, "lines": ["figure = make_iplot('read_time', 'word_count', 'Number of Words vs Read Time')\n", "iplot(figure)"]}, {"block": 80, "type": "code", "linesLength": 2, "startIndex": 520, "lines": ["figure = make_iplot('time_published', 'claps_per_word', 'Claps Per Word')\n", "iplot(figure)"]}, {"block": 81, "type": "code", "linesLength": 4, "startIndex": 522, "lines": ["articles['words_per_minute'] = articles['word_count'] / articles['read_time']\n", "articles['words_per_minute'].iplot(kind='hist', \n", "                                   xTitle='Words per Minute', \n", "                                   title=\"Histogram of Words per Minute\")"]}, {"block": 82, "type": "markdown", "linesLength": 1, "startIndex": 526, "lines": ["## Exploring Tags"]}, {"block": 83, "type": "markdown", "linesLength": 1, "startIndex": 527, "lines": ["If we want to look at the tags, we'll need to create find all of them which we can do by flattening the list of lists for each entry."]}, {"block": 84, "type": "code", "linesLength": 6, "startIndex": 528, "lines": ["from collections import Counter\n", "from itertools import chain\n", "\n", "all_tags = list(chain(*entry_data['tags'].tolist()))\n", "tag_counts = Counter(all_tags)\n", "tag_counts.most_common(10)"]}, {"block": 85, "type": "markdown", "linesLength": 1, "startIndex": 534, "lines": ["The most popular tags are not that surprising for my work! "]}, {"block": 86, "type": "code", "linesLength": 44, "startIndex": 535, "lines": ["def make_iplot_by_tag(data, x, y, title, n=10):\n", "    \"\"\"\n", "    Make an interactive plot colored by the post tag (with top `n` tags)\n", "    \n", "    :param data: dataframe of posts\n", "    :param x: string for the independent variable\n", "    :param y: string for the dependent variable\n", "    :param title: string for the title of plot\n", "    :param n: integer for number of most popular tags to display\n", "    \n", "    :return figure: a plotly figure for display\n", "    :return tag_plot: a plotly bar plot of tag counts\n", "    \n", "    \"\"\"\n", "    data = data.copy()\n", "    all_tags = list(chain(*data['tags'].tolist()))\n", "    tag_counts = Counter(all_tags)\n", "    tags = tag_counts.most_common(n)\n", "    \n", "    plot_data = []\n", "    for tag, count in tags:\n", "        flag = [1 if tag in tags else 0 for tags in data['tags']]\n", "        data.loc[:, tag] = flag\n", "        \n", "        subset = data[data[tag] == 1].copy()\n", "        plot_data.append(go.Scatter(x=subset[x], y=subset[y], marker=dict(size = 12), \n", "                               name=tag, mode='markers'))\n", "        \n", "    layout = go.Layout(\n", "        title=title,\n", "        xaxis=dict(\n", "            title=x.title(), tickfont=dict(size=14), titlefont=dict(size=16)),\n", "        yaxis=dict(title=y.title(), tickfont=dict(size=14), titlefont=dict(size=16)))\n", "    \n", "    figure = go.Figure(data=plot_data, layout=layout)\n", "    \n", "    tag_plot = go.Figure(data=[go.Bar(x=[tag[0] for tag in tags],\n", "                                          y=[tag[1] for tag in tags])],\n", "                              layout=go.Layout(title='Bar Plot of Tag Counts', \n", "                                              xaxis=dict(\n", "            title='tag', tickfont=dict(size=14), titlefont=dict(size=16)),\n", "        yaxis=dict(title='count', tickfont=dict(size=14), titlefont=dict(size=16))))\n", "    \n", "    return figure, tag_plot"]}, {"block": 87, "type": "code", "linesLength": 2, "startIndex": 579, "lines": ["figure, tag_plot = make_iplot_by_tag(articles, 'word_count', 'claps', title='Claps vs Word Count')\n", "iplot(figure)"]}, {"block": 88, "type": "markdown", "linesLength": 1, "startIndex": 581, "lines": ["You can highlight one tag by selecting it from the legend. "]}, {"block": 89, "type": "code", "linesLength": 1, "startIndex": 582, "lines": ["iplot(tag_plot)"]}, {"block": 90, "type": "markdown", "linesLength": 3, "startIndex": 583, "lines": ["## Function to get links from a soup\n", "\n", "When we found the links, we manually extracted them, but we can also use a function to find the links from any html page. This makes it easier to rapidly examine the entries on a page."]}, {"block": 91, "type": "code", "linesLength": 19, "startIndex": 586, "lines": ["def get_links(soup):\n", "    \"\"\"\n", "    Retrieve all links to entries on webpage\n", "    \n", "    :param soup: BeautifulSoup of HTML for page\n", "    :return entry_links: list of links to entries\n", "    \n", "    \"\"\"    \n", "    titles = soup.find_all(attrs = {'class': 'bq y br af bs ag db dc dd c de df dg'})\n", "    pattern = re.compile('[0-9]{1,} min read')\n", "    read_times = soup.find_all(text = pattern)\n", "    read_times = [int(x.split(' ')[0]) for x in read_times]\n", "    total_read_time = sum(read_times)\n", "    \n", "    print(f'Found {len(titles)} entries.')\n", "    print(f'Total Read Time of Entries: {total_read_time} minutes.')\n", "    entry_links = [title.a.get_attribute_list('href')[0] for title in titles]\n", "    \n", "    return entry_links"]}, {"block": 92, "type": "markdown", "linesLength": 1, "startIndex": 605, "lines": ["## Unlisted Articles"]}, {"block": 93, "type": "code", "linesLength": 2, "startIndex": 606, "lines": ["unlisted_soup = BeautifulSoup(open('data/unlisted.html', 'r').read())\n", "unlisted_soup.text[:100]"]}, {"block": 94, "type": "code", "linesLength": 1, "startIndex": 608, "lines": ["unlisted_links = get_links(unlisted_soup)"]}, {"block": 95, "type": "code", "linesLength": 2, "startIndex": 609, "lines": ["unlisted_data = process_in_parallel(unlisted_links)\n", "unlisted_data.head()"]}, {"block": 96, "type": "code", "linesLength": 0, "startIndex": 611, "lines": []}]