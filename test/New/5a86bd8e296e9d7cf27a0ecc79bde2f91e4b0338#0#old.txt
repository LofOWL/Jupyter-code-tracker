[{"block": 0, "type": "code", "linesLength": 25, "startIndex": 0, "lines": ["import pandas as pd\n", "import numpy as np\n", "\n", "%load_ext autoreload\n", "%autoreload 2\n", "\n", "import sys\n", "sys.path.append('../..')\n", "\n", "# Options for pandas\n", "pd.options.display.max_columns = 20\n", "pd.options.display.max_rows = 10\n", "\n", "# Display all cell outputs\n", "from IPython.core.interactiveshell import InteractiveShell\n", "InteractiveShell.ast_node_interactivity = 'all'\n", "\n", "import plotly.plotly as py\n", "import plotly.graph_objs as go\n", "from plotly.offline import iplot, init_notebook_mode\n", "init_notebook_mode(connected=True)\n", "\n", "import cufflinks\n", "cf.go_offline(connected=True)\n", "cf.set_config_file(theme='pearl')\n"]}, {"block": 1, "type": "code", "linesLength": 1, "startIndex": 25, "lines": ["!pip install pandas_datareader"]}, {"block": 2, "type": "code", "linesLength": 46, "startIndex": 26, "lines": ["import bs4 as bs\n", "import datetime as dt\n", "import os\n", "import pandas_datareader.data as web\n", "import pickle\n", "import requests\n", "\n", "\n", "def save_sp500_tickers():\n", "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n", "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n", "    table = soup.find('table', {'class': 'wikitable sortable'})\n", "    tickers = []\n", "    for row in table.findAll('tr')[1:]:\n", "        ticker = row.findAll('td')[0].text\n", "        tickers.append(ticker)\n", "    with open(\"sp500tickers.pickle\", \"wb\") as f:\n", "        pickle.dump(tickers, f)\n", "    return tickers\n", "\n", "\n", "# save_sp500_tickers()\n", "def get_data_from_yahoo(reload_sp500=False):\n", "    if reload_sp500:\n", "        tickers = save_sp500_tickers()\n", "    else:\n", "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n", "            tickers = pickle.load(f)\n", "    if not os.path.exists('stock_dfs'):\n", "        os.makedirs('stock_dfs')\n", "\n", "    start = dt.datetime(2010, 1, 1)\n", "    end = dt.datetime.now()\n", "    for ticker in tickers:\n", "        # just in case your connection breaks, we'd like to save our progress!\n", "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n", "            df = web.DataReader(ticker, 'yahoo', start, end)\n", "            df.reset_index(inplace=True)\n", "            df.set_index(\"Date\", inplace=True)\n", "            df = df.drop(\"Symbol\", axis=1)\n", "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n", "        else:\n", "            print('Already have {}'.format(ticker))\n", "\n", "\n", "get_data_from_yahoo()"]}, {"block": 3, "type": "code", "linesLength": 17, "startIndex": 72, "lines": ["import bs4 as bs\n", "import pickle\n", "import requests\n", "\n", "def save_sp500_tickers():\n", "    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n", "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n", "    table = soup.find('table', {'class': 'wikitable sortable'})\n", "    tickers = []\n", "    for row in table.findAll('tr')[1:]:\n", "        ticker = row.findAll('td')[0].text\n", "        tickers.append(ticker)\n", "\n", "    with open(\"sp500tickers.pickle\",\"wb\") as f:\n", "        pickle.dump(tickers,f)\n", "\n", "    return tickers"]}, {"block": 4, "type": "code", "linesLength": 1, "startIndex": 89, "lines": ["save_sp500_tickers()"]}, {"block": 5, "type": "code", "linesLength": 7, "startIndex": 90, "lines": ["# save_sp500_tickers()\n", "def get_data_from_yahoo(reload_sp500=False):\n", "    if reload_sp500:\n", "        tickers = save_sp500_tickers()\n", "    else:\n", "        with open(\"sp500tickers.pickle\", \"rb\") as f:\n", "            tickers = pickle.load(f)"]}, {"block": 6, "type": "code", "linesLength": 1, "startIndex": 97, "lines": ["get_data_from_yahoo()"]}, {"block": 7, "type": "code", "linesLength": 12, "startIndex": 98, "lines": ["    start = dt.datetime(2010, 1, 1)\n", "    end = dt.datetime.now()\n", "    for ticker in tickers:\n", "        # just in case your connection breaks, we'd like to save our progress!\n", "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n", "            df = web.DataReader(ticker, 'morningstar', start, end)\n", "            df.reset_index(inplace=True)\n", "            df.set_index(\"Date\", inplace=True)\n", "            df = df.drop(\"Symbol\", axis=1)\n", "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n", "        else:\n", "            print('Already have {}'.format(ticker))"]}]