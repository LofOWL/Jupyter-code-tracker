[{"block": 0, "type": "code", "linesLength": 21, "startIndex": 0, "lines": ["# Data science imports\n", "import pandas as pd\n", "import numpy as np\n", "\n", "%load_ext autoreload\n", "%autoreload 2\n", "\n", "import sys\n", "sys.path.append('../..')\n", "\n", "# Options for pandas\n", "pd.options.display.max_columns = 20\n", "\n", "# Display all cell outputs\n", "from IPython.core.interactiveshell import InteractiveShell\n", "InteractiveShell.ast_node_interactivity = 'all'\n", "\n", "import plotly.plotly as py\n", "import plotly.graph_objs as go\n", "import cufflinks\n", "cufflinks.go_offline()\n"]}, {"block": 1, "type": "code", "linesLength": 4, "startIndex": 21, "lines": ["from bs4 import BeautifulSoup\n", "\n", "soup = BeautifulSoup(open('data/published.html', 'r').read())\n", "soup.text[:10]"]}, {"block": 2, "type": "code", "linesLength": 2, "startIndex": 25, "lines": ["titles = soup.find_all(attrs = {'class': 'bq y br af bs ag db dc dd c de df dg'})\n", "print(f'Found {len(titles)} articles.')"]}, {"block": 3, "type": "code", "linesLength": 3, "startIndex": 27, "lines": ["import re\n", "pattern = re.compile('[0-9] min read')\n", "pattern.findall(string = '1 min read')"]}, {"block": 4, "type": "code", "linesLength": 2, "startIndex": 30, "lines": ["read_times = soup.find_all(text = pattern)\n", "print(f'Found {len(read_times)} read times.')"]}, {"block": 5, "type": "code", "linesLength": 2, "startIndex": 32, "lines": ["total_read_time = sum([int(x.split(' ')[0]) for x in read_times])\n", "print(f'Total Read Time of Articles: {total_read_time} minutes.')"]}, {"block": 6, "type": "code", "linesLength": 2, "startIndex": 34, "lines": ["a = titles[0].a\n", "a"]}, {"block": 7, "type": "code", "linesLength": 2, "startIndex": 36, "lines": ["article_links = [title.a.get_attribute_list('href')[0] for title in titles]\n", "len(article_links)"]}, {"block": 8, "type": "code", "linesLength": 5, "startIndex": 38, "lines": ["import requests\n", "\n", "articles = []\n", "for a in article_links[:10]:\n", "    articles.append(requests.get(a).text)"]}, {"block": 9, "type": "code", "linesLength": 3, "startIndex": 43, "lines": ["article_soup = BeautifulSoup(articles[0])\n", "article_text = [p.text for p in article_soup.find_all('p')]\n", "article_text[0]"]}, {"block": 10, "type": "code", "linesLength": 5, "startIndex": 46, "lines": ["from itertools import chain\n", "\n", "article_text_in_words = list(chain(*[p.split(' ') for p in article_text]))\n", "article_text_in_words[:10]\n", "len(article_text_in_words)"]}, {"block": 11, "type": "code", "linesLength": 1, "startIndex": 51, "lines": ["article_soup.h1.text"]}, {"block": 12, "type": "code", "linesLength": 2, "startIndex": 52, "lines": ["t = article_soup.find_all('time')[0]\n", "type(t)"]}, {"block": 13, "type": "code", "linesLength": 1, "startIndex": 54, "lines": ["t.get('datetime')"]}, {"block": 14, "type": "code", "linesLength": 1, "startIndex": 55, "lines": ["article_soup.h1"]}, {"block": 15, "type": "code", "linesLength": 29, "startIndex": 56, "lines": ["def get_articles(article_links):\n", "    \"\"\"Retrieve text of all articles in a list of links.\"\"\"\n", "    \n", "    articles = {}\n", "    n_words = 0\n", "    responses = 0\n", "    for i, link in enumerate(article_links):\n", "        if (i + 1) % 5 == 0:\n", "            print(f'{100 * i / len(article_links):.2f}% complete. Total words = {n_words}.', end = '\\r')\n", "        article = requests.get(link).text\n", "        article_soup = BeautifulSoup(article)\n", "        if article_soup.h1 is not None:\n", "            title = article_soup.h1.text\n", "        else:\n", "            title = f'response-{responses}'\n", "            responses += 1\n", "            \n", "        articles[title] = {}\n", "        article_text = [p.text for p in article_soup.find_all('p')]\n", "        article_text_in_words = list(chain(*[p.split(' ') for p in article_text]))\n", "        n_words += len(article_text_in_words)\n", "        articles[title]['n_words'] = len(article_text_in_words)\n", "        articles[title]['text'] = ' '.join(article_text_in_words)\n", "        articles[title]['date'] = article_soup.find_all('time')[0].get('datetime')\n", "        \n", "    print(f'Found {len(articles) - responses} articles.')\n", "    print(f'Total words: {n_words}.')\n", "    \n", "    return articles"]}, {"block": 16, "type": "code", "linesLength": 1, "startIndex": 85, "lines": ["all_articles_dict = get_articles(article_links)"]}, {"block": 17, "type": "code", "linesLength": 3, "startIndex": 86, "lines": ["data = pd.DataFrame(all_articles_dict).transpose().reset_index().rename(columns={'index': 'title'})\n", "data['date'] = pd.to_datetime(data['date'])\n", "data.head()"]}, {"block": 18, "type": "code", "linesLength": 2, "startIndex": 89, "lines": ["data['n_words'].iplot(kind='hist', xTitle='num words', yTitle='Count', \n", "                      title='Histogram of Number of Words')"]}, {"block": 19, "type": "code", "linesLength": 2, "startIndex": 91, "lines": ["data.iplot(x='date', y='n_words', opacity=0.4, mode='markers', xTitle='Date', yTitle='num_words',\n", "           title='Number of Words vs Date', text = 'title')"]}, {"block": 20, "type": "code", "linesLength": 4, "startIndex": 93, "lines": ["data['response'] = ['response' if x == True else 'article' for x in data['title'].str.contains('response')]\n", "data.iplot(x='date', y='n_words', opacity=0.8, mode='markers', xTitle='Date', yTitle='num_words',\n", "           title='Number of Words vs Date', categories='response', \n", "           text = 'title')"]}, {"block": 21, "type": "markdown", "linesLength": 1, "startIndex": 97, "lines": ["# Articles Over Time"]}, {"block": 22, "type": "code", "linesLength": 14, "startIndex": 98, "lines": ["def get_links(soup):\n", "    \"\"\"Retrieve all links within webpage to articles\"\"\"\n", "    titles = soup.find_all(attrs = {'class': 'bq y br af bs ag db dc dd c de df dg'})\n", "    print(f'Found {len(titles)} articles.')\n", "    \n", "    pattern = re.compile('[0-9] min read')\n", "    pattern.findall(string = '1 min read')\n", "    read_times = soup.find_all(text = pattern)\n", "    total_read_time = sum([int(x.split(' ')[0]) for x in read_times])\n", "    \n", "    print(f'Total Read Time of Articles: {total_read_time} minutes.')\n", "    article_links = [title.a.get_attribute_list('href')[0] for title in titles]\n", "    \n", "    return article_links"]}, {"block": 23, "type": "code", "linesLength": 2, "startIndex": 112, "lines": ["unlisted_soup = BeautifulSoup(open('data/unlisted.html', 'r').read())\n", "unlisted_soup.text[:100]"]}, {"block": 24, "type": "code", "linesLength": 1, "startIndex": 114, "lines": ["unlisted_links = get_links(unlisted_soup)"]}, {"block": 25, "type": "code", "linesLength": 1, "startIndex": 115, "lines": ["unlisted_articles = get_articles(unlisted_links)"]}, {"block": 26, "type": "code", "linesLength": 0, "startIndex": 116, "lines": []}]