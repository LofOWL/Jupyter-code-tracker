{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow with H2O \n",
    "\n",
    "This notebook shows how to use the tensorflow backend to tackle a simple image classification problem.\n",
    "\n",
    "We start by connecting to our h2o cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import h2o\n",
    "from h2o.estimators.deepwater import H2ODeepWaterEstimator\n",
    "import os.path\n",
    "from IPython.display import Image, display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "PATH=os.path.expanduser(\"~/Dev/code/github/h2o-3\")\n",
    "h2o.init(port=54321, nthreads=-1)\n",
    "if not H2ODeepWaterEstimator.available(): exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import Image, display, HTML\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Task\n",
    "\n",
    "H2O DeepWater allows you to specify a list of URIs (file paths) or URLs (links) to images, together with a response column (either a class membership (enum) or regression target (numeric)).\n",
    "\n",
    "For this example, we use a small dataset that has a few hundred images, and three classes: cat, dog and mouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frame = h2o.import_file(PATH + \"/bigdata/laptop/deepwater/imagenet/cat_dog_mouse.csv\")\n",
    "print(frame.dim)\n",
    "print(frame.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a LeNet image classification model in H2O, simply specify `network = \"lenet\"` and the **Tensorflow** backend to use the tensorflow lenet implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = H2ODeepWaterEstimator(epochs=500, network = \"lenet\", backend=\"tensorflow\")\n",
    "model.train(x=[0],y=1, training_frame=frame)\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFeatures\n",
    "\n",
    "We can also compute the output of any hidden layer, if we know its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.deepfeatures(frame, \"fc1/Relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to build your own Tensorflow network architecture, then this is easy as well.\n",
    "In this example script, we are using the **Tensorflow** backend. \n",
    "Models can easily be imported/exported between H2O and Tensorflow since H2O uses Tensorflow's format for model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_model(w, h, channels, classes):\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.python.framework import ops\n",
    "    # always create a new graph inside ipython or\n",
    "    # the default one will be used and can lead to\n",
    "    # unexpected behavior\n",
    "    graph = tf.Graph() \n",
    "    with graph.as_default():\n",
    "        size = w * h * channels\n",
    "        x = tf.placeholder(tf.float32, [None, size])\n",
    "        W = tf.Variable(tf.zeros([size, classes]))\n",
    "        b = tf.Variable(tf.zeros([classes]))\n",
    "        y = tf.matmul(x, W) + b\n",
    "\n",
    "        predictions = tf.nn.softmax(y)\n",
    "        \n",
    "        # labels\n",
    "        y_ = tf.placeholder(tf.float32, [None, classes])\n",
    "        \n",
    "        # train\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "        train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "        \n",
    "        tf.add_to_collection(ops.GraphKeys.TRAIN_OP, train_step)\n",
    "        tf.add_to_collection(\"predictions\", predictions)\n",
    "        # this is required by the h2o tensorflow backend\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        \n",
    "        init = tf.initialize_all_variables()\n",
    "        tf.add_to_collection(ops.GraphKeys.INIT_OP, init.name)\n",
    "        tf.add_to_collection(\"logits\", y)\n",
    "        saver = tf.train.Saver()\n",
    "        meta = json.dumps({\n",
    "                \"inputs\": {\"batch_image_input\": x.name, \"categorical_labels\": y_.name}, \n",
    "                \"outputs\": {\"categorical_logits\": y.name},\n",
    "                \"parameters\": {\"global_step\": global_step.name},\n",
    "        })\n",
    "        print(meta)\n",
    "        tf.add_to_collection(\"meta\", meta)\n",
    "        filename = \"/tmp/lenet_tensorflow.meta\"\n",
    "        tf.train.export_meta_graph(filename, saver_def=saver.as_saver_def())\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = simple_model(28, 28, 3, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = H2ODeepWaterEstimator(epochs=500, \n",
    "                              network_definition_file=filename,  ## specify the model\n",
    "                              image_shape=[28,28],  ## provide expected (or matching) image size\n",
    "                              channels=3,\n",
    "                              backend=\"tensorflow\", \n",
    "                             ) \n",
    "model.train(x=[0], y=1, training_frame=frame)\n",
    "model.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Custom models with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use libraries/APIs such as Keras to define the network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from keras.layers.core import Dense, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.objectives import categorical_crossentropy\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "def keras_model(w, h, channels, classes):\n",
    "    # always create a new graph inside ipython or\n",
    "    # the default one will be used and can lead to\n",
    "    # unexpected behavior\n",
    "    graph = tf.Graph() \n",
    "    with graph.as_default():\n",
    "        size = w * h * channels\n",
    "        # Input images fed via H2O\n",
    "        inp = tf.placeholder(tf.float32, [None, size])\n",
    "        # Actual labels used for training fed via H2O\n",
    "        labels = tf.placeholder(tf.float32, [None, classes])\n",
    "\n",
    "        # Keras network\n",
    "        x = Reshape((w, h, channels))(inp)\n",
    "        x = Conv2D(20, (5, 5), padding='same', activation='relu')(x)\n",
    "        x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "        x = Conv2D(50, (5, 5), padding='same', activation='relu')(x)\n",
    "        x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "        x = Flatten()(x)    \n",
    "\n",
    "        x = Dense(500, activation='relu')(x)\n",
    "\n",
    "        out = Dense(classes)(x)\n",
    "\n",
    "        predictions = tf.nn.softmax(out)\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels,logits=out))\n",
    "        train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "        init_op = tf.initialize_all_variables()\n",
    "\n",
    "        # Metadata required by H2O\n",
    "        tf.add_to_collection(ops.GraphKeys.INIT_OP, init_op.name)\n",
    "        tf.add_to_collection(ops.GraphKeys.TRAIN_OP, train_step)\n",
    "        tf.add_to_collection(\"logits\", out)\n",
    "        tf.add_to_collection(\"predictions\", predictions)\n",
    "\n",
    "        meta = json.dumps({\n",
    "                \"inputs\": {\"batch_image_input\": inp.name,\n",
    "                           \"categorical_labels\": labels.name},\n",
    "                \"outputs\": {\"categorical_logits\": out.name,\n",
    "                            \"layers\": ','.join([m.name for m in tf.get_default_graph().get_operations()])},\n",
    "                \"parameters\": {}\n",
    "            })\n",
    "        tf.add_to_collection(\"meta\", meta)\n",
    "\n",
    "        # Save the meta file with the graph\n",
    "        saver = tf.train.Saver()\n",
    "        filename = \"/tmp/keras_tensorflow.meta\"\n",
    "        tf.train.export_meta_graph(filename, saver_def=saver.as_saver_def())\n",
    "\n",
    "        return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = keras_model(28, 28, 3, classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = H2ODeepWaterEstimator(epochs=50, \n",
    "                              network_definition_file=filename,  ## specify the model\n",
    "                              image_shape=[28,28],  ## provide expected (or matching) image size\n",
    "                              channels=3,\n",
    "                              backend=\"tensorflow\", \n",
    "                             ) \n",
    "model.train(x=[0], y=1, training_frame=frame)\n",
    "model.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
