{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST GPU Deep Learning Benchmark with H2O Deep Water\n",
    "In reference to [Szilard's Benchmark-DL](https://github.com/szilard/benchm-dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>8 mins 25 secs</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.11.0.99999</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>10 hours and 16 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_arno_mc0sih</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>13.46 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>40</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>40</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.12 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------\n",
       "H2O cluster uptime:         8 mins 25 secs\n",
       "H2O cluster version:        3.11.0.99999\n",
       "H2O cluster version age:    10 hours and 16 minutes\n",
       "H2O cluster name:           H2O_from_python_arno_mc0sih\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    13.46 Gb\n",
       "H2O cluster total cores:    40\n",
       "H2O cluster allowed cores:  40\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "Python version:             2.7.12 final\n",
       "--------------------------  ---------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "import os.path\n",
    "import h2o\n",
    "from h2o.estimators.deepwater import H2ODeepWaterEstimator\n",
    "PATH = os.path.expanduser(\"~/h2o-3/\")\n",
    "h2o.init(nthreads=-1)\n",
    "if not H2ODeepWaterEstimator.available(): exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use one NVidia GTX1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 24 09:49:53 2016       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 367.44                 Driver Version: 367.44                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 1080    Off  | 0000:02:00.0      On |                  N/A |\r\n",
      "| 27%   36C    P8    10W / 180W |   1746MiB /  8097MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 1080    Off  | 0000:81:00.0      On |                  N/A |\r\n",
      "| 27%   40C    P8    10W / 180W |   1201MiB /  8113MiB |      3%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID  Type  Process name                               Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      6886    C   /usr/lib/jvm/java-8-oracle//bin/java           325MiB |\r\n",
      "|    0     19485    G   compiz                                         726MiB |\r\n",
      "|    0     28518    G   /usr/lib/xorg/Xorg                             690MiB |\r\n",
      "|    1     19485    G   compiz                                         726MiB |\r\n",
      "|    1     28518    G   /usr/lib/xorg/Xorg                             470MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We define the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn(num_classes):\n",
    "    import mxnet as mx\n",
    "    data = mx.symbol.Variable('data')\n",
    "\n",
    "    conv1 = mx.symbol.Convolution(data=data, kernel=(4,4), num_filter=32)\n",
    "    relu1 = mx.symbol.Activation(data=conv1, act_type=\"relu\")\n",
    "    pool1 = mx.symbol.Pooling(data=relu1, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "\n",
    "    conv2 = mx.symbol.Convolution(data=pool1, kernel=(3,3), num_filter=16)\n",
    "    relu2 = mx.symbol.Activation(data=conv2, act_type=\"relu\")\n",
    "    pool2 = mx.symbol.Pooling(data=relu2, pool_type=\"max\", kernel=(2,2), stride=(2,2))\n",
    "    drop = mx.symbol.Dropout(data=pool2, p=0.2)\n",
    "\n",
    "    flatten = mx.symbol.Flatten(data=drop)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=128)\n",
    "    relu3 = mx.symbol.Activation(data=fc1, act_type=\"relu\")\n",
    "\n",
    "    fc2 = mx.symbol.FullyConnected(data=relu3, num_hidden=64)\n",
    "    relu4 = mx.symbol.Activation(data=fc2, act_type=\"relu\")\n",
    "\n",
    "    fc3 = mx.symbol.FullyConnected(data=relu4, num_hidden=num_classes)\n",
    "    net = mx.symbol.SoftmaxOutput(data=fc3, name='softmax')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n",
      "deepwater Model Build progress: |█████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train = h2o.import_file(PATH + \"bigdata/laptop/mnist/train.csv.gz\")\n",
    "predictors  = list(range(0,784))\n",
    "resp        = 784\n",
    "train[resp] = train[resp].asfactor()\n",
    "nclasses    = train[resp].nlevels()[0]\n",
    "cnn(nclasses).save(\"/tmp/cnn.json\")\n",
    "model = H2ODeepWaterEstimator(epochs=10,\n",
    "                              learning_rate=0.05,\n",
    "                              learning_rate_annealing=1e-5,\n",
    "                              momentum_start=0.9,\n",
    "                              momentum_stable=0.9,\n",
    "                              mini_batch_size=128,\n",
    "                              train_samples_per_iteration=0,\n",
    "                              score_duty_cycle=0,\n",
    "                              stopping_rounds=0,\n",
    "                              ignore_const_cols=False,\n",
    "                              network_definition_file=\"/tmp/cnn.json\",\n",
    "                              image_shape=[28,28],\n",
    "                              channels=1,\n",
    "                              device_id=[0])\n",
    "\n",
    "model.train(x=predictors,y=resp, training_frame=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It takes about 26 seconds to train 600k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>training_speed</th>\n",
       "      <th>epochs</th>\n",
       "      <th>iterations</th>\n",
       "      <th>samples</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-24 09:50:41</td>\n",
       "      <td>0.000 sec</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2016-10-24 09:51:07</td>\n",
       "      <td>26.250 sec</td>\n",
       "      <td>23499 obs/sec</td>\n",
       "      <td>10.005333</td>\n",
       "      <td>10</td>\n",
       "      <td>600320.0</td>\n",
       "      <td>0.061987</td>\n",
       "      <td>0.014723</td>\n",
       "      <td>0.004052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp    duration training_speed     epochs  iterations  \\\n",
       "0    2016-10-24 09:50:41   0.000 sec           None   0.000000           0   \n",
       "1    2016-10-24 09:51:07  26.250 sec  23499 obs/sec  10.005333          10   \n",
       "\n",
       "    samples  training_rmse  training_logloss  training_classification_error  \n",
       "0       0.0            NaN               NaN                            NaN  \n",
       "1  600320.0       0.061987          0.014723                       0.004052  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.scoring_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's evaluate the test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n",
      "\n",
      "ModelMetricsMultinomial: deepwater\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.00895735071088\n",
      "RMSE: 0.0946432813827\n",
      "LogLoss: 0.0334264931925\n",
      "Mean Per-Class Error: 0.01115655357\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>974.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0061224</td>\n",
       "<td>6 / 980</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1133.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0017621</td>\n",
       "<td>2 / 1,135</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1019.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>5.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0125969</td>\n",
       "<td>13 / 1,032</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1003.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0069307</td>\n",
       "<td>7 / 1,010</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>975.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0071283</td>\n",
       "<td>7 / 982</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>8.0</td>\n",
       "<td>0.0</td>\n",
       "<td>881.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0123318</td>\n",
       "<td>11 / 892</td></tr>\n",
       "<tr><td>6.0</td>\n",
       "<td>3.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>3.0</td>\n",
       "<td>940.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0187891</td>\n",
       "<td>18 / 958</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>7.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1016.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0116732</td>\n",
       "<td>12 / 1,028</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>959.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0154004</td>\n",
       "<td>15 / 974</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>6.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>4.0</td>\n",
       "<td>990.0</td>\n",
       "<td>0.0188305</td>\n",
       "<td>19 / 1,009</td></tr>\n",
       "<tr><td>982.0</td>\n",
       "<td>1141.0</td>\n",
       "<td>1032.0</td>\n",
       "<td>1021.0</td>\n",
       "<td>983.0</td>\n",
       "<td>894.0</td>\n",
       "<td>945.0</td>\n",
       "<td>1028.0</td>\n",
       "<td>975.0</td>\n",
       "<td>999.0</td>\n",
       "<td>0.011</td>\n",
       "<td>110 / 10,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0    1     2     3     4    5    6    7     8    9    Error       Rate\n",
       "---  ----  ----  ----  ---  ---  ---  ----  ---  ---  ----------  ------------\n",
       "974  0     1     0     0    1    1    1     2    0    0.00612245  6 / 980\n",
       "0    1133  0     0     0    1    1    0     0    0    0.00176211  2 / 1,135\n",
       "0    1     1019  3     1    0    1    5     2    0    0.0125969   13 / 1,032\n",
       "0    0     0     1003  0    3    0    2     2    0    0.00693069  7 / 1,010\n",
       "0    0     1     0     975  0    2    0     2    2    0.00712831  7 / 982\n",
       "0    0     0     8     0    881  0    0     1    2    0.0123318   11 / 892\n",
       "6    3     2     1     1    3    940  0     2    0    0.0187891   18 / 958\n",
       "0    2     7     1     0    0    0    1016  1    1    0.0116732   12 / 1,028\n",
       "1    2     2     3     0    1    0    2     959  4    0.0154004   15 / 974\n",
       "1    0     0     2     6    4    0    2     4    990  0.0188305   19 / 1,009\n",
       "982  1141  1032  1021  983  894  945  1028  975  999  0.011       110 / 10,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.989</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.998</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9994</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9997</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9998</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9998</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.989\n",
       "2    0.998\n",
       "3    0.9994\n",
       "4    0.9997\n",
       "5    0.9998\n",
       "6    0.9998\n",
       "7    1\n",
       "8    1\n",
       "9    1\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test = h2o.import_file(PATH + \"bigdata/laptop/mnist/test.csv.gz\")\n",
    "print(model.model_performance(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
