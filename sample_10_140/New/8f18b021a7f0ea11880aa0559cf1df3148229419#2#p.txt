[{"block": 0, "type": "code", "linesLength": 3, "startIndex": 0, "lines": ["%matplotlib inline\n", "%reload_ext autoreload\n", "%autoreload 2"]}, {"block": 1, "type": "markdown", "linesLength": 1, "startIndex": 3, "lines": ["## WGAN"]}, {"block": 2, "type": "code", "linesLength": 4, "startIndex": 4, "lines": ["from fastai.conv_learner import *\n", "from fastai.dataset import *\n", "import gzip\n", "torch.cuda.set_device(3)"]}, {"block": 3, "type": "markdown", "linesLength": 10, "startIndex": 8, "lines": ["Download the LSUN scene classification dataset bedroom category, unzip it, and convert it to jpg files (the scripts folder is here in the `dl2` folder):\n", "\n", "```\n", "curl 'http://lsun.cs.princeton.edu/htbin/download.cgi?tag=latest&category=bedroom&set=train' -o bedroom.zip\n", "unzip bedroom.zip\n", "pip install lmdb\n", "python lsun-data.py {PATH}/bedroom_train_lmdb --out_dir {PATH}/bedroom\n", "```\n", "\n", "This isn't tested on Windows - if it doesn't work, you could use a Linux box to convert the files, then copy them over. Alternatively, you can download [this 20% sample](https://www.kaggle.com/jhoward/lsun_bedroom) from Kaggle datasets."]}, {"block": 4, "type": "code", "linesLength": 5, "startIndex": 18, "lines": ["PATH = Path('data/lsun/')\n", "IMG_PATH = PATH/'bedroom'\n", "CSV_PATH = PATH/'files.csv'\n", "TMP_PATH = PATH/'tmp'\n", "TMP_PATH.mkdir(exist_ok=True)"]}, {"block": 5, "type": "code", "linesLength": 4, "startIndex": 23, "lines": ["files = PATH.glob('bedroom/**/*.jpg')\n", "\n", "with CSV_PATH.open('w') as fo:\n", "    for f in files: fo.write(f'{f.relative_to(IMG_PATH)},0\\n')"]}, {"block": 6, "type": "code", "linesLength": 2, "startIndex": 27, "lines": ["# Optional - sampling a subset of files\n", "CSV_PATH = PATH/'files_sample.csv'"]}, {"block": 7, "type": "code", "linesLength": 5, "startIndex": 29, "lines": ["files = PATH.glob('bedroom/**/*.jpg')\n", "\n", "with CSV_PATH.open('w') as fo:\n", "    for f in files:\n", "        if random.random()<0.1: fo.write(f'{f.relative_to(IMG_PATH)},0\\n')"]}, {"block": 8, "type": "code", "linesLength": 10, "startIndex": 34, "lines": ["class ConvBlock(nn.Module):\n", "    def __init__(self, ni, no, ks, stride, bn=True, pad=None):\n", "        super().__init__()\n", "        if pad is None: pad = ks//2//stride\n", "        self.conv = nn.Conv2d(ni, no, ks, stride, padding=pad, bias=False)\n", "        self.bn = nn.BatchNorm2d(no)\n", "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n", "    \n", "    def forward(self, x):\n", "        return self.bn(self.relu(self.conv(x)))"]}, {"block": 9, "type": "code", "linesLength": 23, "startIndex": 44, "lines": ["class DCGAN_D(nn.Module):\n", "    def __init__(self, isize, nc, ndf, n_extra_layers=0):\n", "        super().__init__()\n", "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n", "\n", "        self.initial = ConvBlock(nc, ndf, 4, 2, bn=False)\n", "        csize,cndf = isize/2,ndf\n", "        self.extra = nn.Sequential(*[ConvBlock(cndf, cndf, 3, 1)\n", "                                    for t in range(n_extra_layers)])\n", "\n", "        pyr_layers = []\n", "        while csize > 4:\n", "            pyr_layers.append(ConvBlock(cndf, cndf*2, 4, 2))\n", "            cndf *= 2; csize /= 2\n", "        self.pyramid = nn.Sequential(*pyr_layers)\n", "        \n", "        self.final = nn.Conv2d(cndf, 1, 4, padding=0, bias=False)\n", "\n", "    def forward(self, input):\n", "        x = self.initial(input)\n", "        x = self.extra(x)\n", "        x = self.pyramid(x)\n", "        return self.final(x).mean(0).view(1)"]}, {"block": 10, "type": "code", "linesLength": 9, "startIndex": 67, "lines": ["class DeconvBlock(nn.Module):\n", "    def __init__(self, ni, no, ks, stride, pad, bn=True):\n", "        super().__init__()\n", "        self.conv = nn.ConvTranspose2d(ni, no, ks, stride, padding=pad, bias=False)\n", "        self.bn = nn.BatchNorm2d(no)\n", "        self.relu = nn.ReLU(inplace=True)\n", "        \n", "    def forward(self, x):\n", "        return self.bn(self.relu(self.conv(x)))"]}, {"block": 11, "type": "code", "linesLength": 27, "startIndex": 76, "lines": ["class DCGAN_G(nn.Module):\n", "    def __init__(self, isize, nz, nc, ngf, n_extra_layers=0):\n", "        super().__init__()\n", "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n", "\n", "        cngf, tisize = ngf//2, 4\n", "        while tisize!=isize: cngf*=2; tisize*=2\n", "        self.initial = DeconvBlock(nz, cngf, 4, 1, 0)\n", "\n", "        csize, cndf = 4, cngf\n", "        pyr_layers = []\n", "        while csize < isize//2:\n", "            pyr_layers.append(DeconvBlock(cngf, cngf//2, 4, 2, 1))\n", "            cngf //= 2; csize *= 2\n", "        self.pyramid = nn.Sequential(*pyr_layers)\n", "\n", "        self.extra = nn.Sequential(*[DeconvBlock(cngf, cngf, 3, 1, 1)\n", "                                    for t in range(n_extra_layers)])\n", "\n", "        self.final = nn.ConvTranspose2d(cngf, nc, 4, 2, 1, bias=False)\n", "\n", "    def forward(self, input):\n", "        x = self.initial(input)\n", "        x = self.pyramid(x)\n", "        x = self.extra(x)\n", "        x = self.final(x)\n", "        return F.tanh(x)"]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 103, "lines": ["bs,sz,nz = 64,64,100"]}, {"block": 13, "type": "code", "linesLength": 3, "startIndex": 104, "lines": ["tfms = tfms_from_stats(inception_stats, sz)\n", "md = ImageClassifierData.from_csv(PATH, 'bedroom', CSV_PATH, tfms=tfms,\n", "                                  skip_header=False, continuous=True)"]}, {"block": 14, "type": "code", "linesLength": 1, "startIndex": 107, "lines": ["md = md.resize(128)"]}, {"block": 15, "type": "code", "linesLength": 1, "startIndex": 108, "lines": ["x,_ = next(iter(md.val_dl))"]}, {"block": 16, "type": "code", "linesLength": 1, "startIndex": 109, "lines": ["plt.imshow(md.trn_ds.denorm(x)[0]);"]}, {"block": 17, "type": "code", "linesLength": 2, "startIndex": 110, "lines": ["netG = DCGAN_G(sz, nz, 3, 64, 1).cuda()\n", "netD = DCGAN_D(sz, 3, 64, 1).cuda()"]}, {"block": 18, "type": "code", "linesLength": 1, "startIndex": 112, "lines": ["def create_noise(b): return V(torch.zeros(b, nz, 1, 1).normal_(0, 1))"]}, {"block": 19, "type": "code", "linesLength": 5, "startIndex": 113, "lines": ["preds = netG(create_noise(4))\n", "pred_ims = md.trn_ds.denorm(preds)\n", "\n", "fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n", "for i,ax in enumerate(axes.flat): ax.imshow(pred_ims[i])"]}, {"block": 20, "type": "code", "linesLength": 7, "startIndex": 118, "lines": ["def gallery(x, nc=3):\n", "    n,h,w,c = x.shape\n", "    nr = n//nc\n", "    assert n == nr*nc\n", "    return (x.reshape(nr, nc, h, w, c)\n", "              .swapaxes(1,2)\n", "              .reshape(h*nr, w*nc, c))"]}, {"block": 21, "type": "code", "linesLength": 2, "startIndex": 125, "lines": ["netD.load_state_dict(torch.load(TMP_PATH/'netD_2.h5'))\n", "netG.load_state_dict(torch.load(TMP_PATH/'netG_2.h5'))"]}, {"block": 22, "type": "code", "linesLength": 2, "startIndex": 127, "lines": ["optimizerD = optim.RMSprop(netD.parameters(), lr = 1e-4)\n", "optimizerG = optim.RMSprop(netG.parameters(), lr = 1e-4)"]}, {"block": 23, "type": "code", "linesLength": 33, "startIndex": 129, "lines": ["def train(niter, first=True):\n", "    gen_iterations = 0\n", "    for epoch in trange(niter):\n", "        netD.train(); netG.train()\n", "        data_iter = iter(md.trn_dl)\n", "        i,n = 0,len(md.trn_dl)\n", "        while i < n:\n", "            set_trainable(netD, True)\n", "            set_trainable(netG, False)\n", "            d_iters = 100 if (first and (gen_iterations < 25) or (gen_iterations % 500 == 0)) else 5\n", "            j = 0\n", "            while (j < d_iters) and (i < n):\n", "                j += 1; i += 1\n", "                for p in netD.parameters(): p.data.clamp_(-0.01, 0.01)\n", "                real = V(next(data_iter)[0])\n", "                real_loss = netD(real)\n", "                fake = netG(create_noise(real.size(0)))\n", "                fake_loss = netD(V(fake.data))\n", "                netD.zero_grad()\n", "                lossD = real_loss-fake_loss\n", "                lossD.backward()\n", "                optimizerD.step()\n", "\n", "            set_trainable(netD, False)\n", "            set_trainable(netG, True)\n", "            netG.zero_grad()\n", "            lossG = netD(netG(create_noise(bs))).mean(0).view(1)\n", "            lossG.backward()\n", "            optimizerG.step()\n", "            gen_iterations += 1\n", "            \n", "        print(f'Loss_D {to_np(lossD)}; Loss_G {to_np(lossG)}; '\n", "              f'D_real {to_np(real_loss)}; Loss_D_fake {to_np(fake_loss)}')"]}, {"block": 24, "type": "code", "linesLength": 1, "startIndex": 162, "lines": ["torch.backends.cudnn.benchmark=True"]}, {"block": 25, "type": "code", "linesLength": 2, "startIndex": 163, "lines": ["train(50, False)\n", "# train(50, True)"]}, {"block": 26, "type": "code", "linesLength": 4, "startIndex": 165, "lines": ["set_trainable(netD, True)\n", "set_trainable(netG, True)\n", "optimizerD = optim.RMSprop(netD.parameters(), lr = 1e-5)\n", "optimizerG = optim.RMSprop(netG.parameters(), lr = 1e-5)"]}, {"block": 27, "type": "code", "linesLength": 1, "startIndex": 169, "lines": ["train(10, False)"]}, {"block": 28, "type": "code", "linesLength": 1, "startIndex": 170, "lines": ["netD.eval(); netG.eval();"]}, {"block": 29, "type": "code", "linesLength": 1, "startIndex": 171, "lines": ["fixed_noise = create_noise(bs)"]}, {"block": 30, "type": "code", "linesLength": 3, "startIndex": 172, "lines": ["netD.eval(); netG.eval();\n", "fake = netG(fixed_noise).data.cpu()\n", "faked = np.clip(md.trn_ds.denorm(fake),0,1)"]}, {"block": 31, "type": "code", "linesLength": 2, "startIndex": 175, "lines": ["plt.figure(figsize=(9,9))\n", "plt.imshow(gallery(faked, 8));"]}, {"block": 32, "type": "code", "linesLength": 2, "startIndex": 177, "lines": ["torch.save(netG.state_dict(), TMP_PATH/'netG_2.h5')\n", "torch.save(netD.state_dict(), TMP_PATH/'netD_2.h5')"]}, {"block": 33, "type": "markdown", "linesLength": 1, "startIndex": 179, "lines": ["## Incomplete upsampling experiments"]}, {"block": 34, "type": "code", "linesLength": 10, "startIndex": 180, "lines": ["class DeconvBlock(nn.Module):\n", "    def __init__(self, ni, no, ks, bn=True):\n", "        super().__init__()\n", "        self.conv = nn.Conv2d(ni, no, ks, 1, padding=ks//2, bias=False)\n", "        self.bn = nn.BatchNorm2d(no)\n", "        self.relu = nn.ReLU(inplace=True)\n", "        \n", "    def forward(self, x):\n", "        x = F.upsample(x, scale_factor=2, mode='bilinear')\n", "        return self.bn(self.relu(self.conv(x)))"]}, {"block": 35, "type": "code", "linesLength": 28, "startIndex": 190, "lines": ["class DCGAN_G(nn.Module):\n", "    def __init__(self, isize, nz, nc, ngf, n_extra_layers=0):\n", "        super().__init__()\n", "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n", "\n", "        cngf, tisize = ngf//2, 4\n", "        while tisize!=isize: cngf*=2; tisize*=2\n", "        self.initial = ConvBlock(nz, cngf, 4, 1, pad=3)\n", "\n", "        csize, cndf = 4, cngf\n", "        pyr_layers = []\n", "        while csize < isize//2:\n", "            pyr_layers.append(DeconvBlock(cngf, cngf//2, 3))\n", "            cngf //= 2; csize *= 2\n", "        self.pyramid = nn.Sequential(*pyr_layers)\n", "\n", "        self.extra = nn.Sequential(*[ConvBlock(cngf, cngf, 3, 1)\n", "                                    for t in range(n_extra_layers)])\n", "\n", "        self.final = nn.Conv2d(cngf, nc, 3, 1, 1, bias=False)\n", "\n", "    def forward(self, input):\n", "        x = self.initial(input)\n", "        x = self.pyramid(x)\n", "        x = self.extra(x)\n", "        x = F.upsample(x, scale_factor=2, mode='bilinear')\n", "        x = self.final(x)\n", "        return F.tanh(x)"]}, {"block": 36, "type": "code", "linesLength": 5, "startIndex": 218, "lines": ["preds = netG(create_noise(4))\n", "pred_ims = md.trn_ds.denorm(preds)\n", "\n", "fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n", "for i,ax in enumerate(axes.flat): ax.imshow(pred_ims[i])"]}, {"block": 37, "type": "markdown", "linesLength": 1, "startIndex": 223, "lines": ["Results after <1 epoch"]}, {"block": 38, "type": "code", "linesLength": 2, "startIndex": 224, "lines": ["plt.figure(figsize=(9,9))\n", "plt.imshow(gallery(faked, 8));"]}]