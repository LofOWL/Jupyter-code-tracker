[{"block": 0, "type": "markdown", "linesLength": 7, "startIndex": 0, "lines": ["##ThinkDSP\n", "\n", "This notebook contains code examples from Chapter 10: Signals and Systems\n", "\n", "Copyright 2015 Allen Downey\n", "\n", "License: [Creative Commons Attribution 4.0 International](http://creativecommons.org/licenses/by/4.0/)"]}, {"block": 1, "type": "code", "linesLength": 15, "startIndex": 7, "lines": ["from __future__ import print_function, division\n", "\n", "import thinkdsp\n", "import thinkplot\n", "\n", "import numpy as np\n", "import pandas as pd\n", "\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "PI2 = 2 * np.pi\n", "\n", "np.set_printoptions(precision=3, suppress=True)\n", "%matplotlib inline"]}, {"block": 2, "type": "markdown", "linesLength": 3, "startIndex": 22, "lines": ["###Impulse response\n", "\n", "To understand why the impulse response is sufficient to characterize a system, it is informative to look at the DFT of an impulse:"]}, {"block": 3, "type": "code", "linesLength": 4, "startIndex": 25, "lines": ["impulse = np.zeros(8)\n", "impulse[0] = 1\n", "wave = thinkdsp.Wave(impulse, framerate=8)\n", "print(wave.ys)"]}, {"block": 4, "type": "markdown", "linesLength": 1, "startIndex": 29, "lines": ["The DFT of an impulse is all ones, which means that the impulse contains equal energy at all frequencies.  So testing a system with an impulse is like testing it will all frequency components at the same time:"]}, {"block": 5, "type": "code", "linesLength": 2, "startIndex": 30, "lines": ["impulse_spectrum = wave.make_spectrum(full=True)\n", "print(impulse_spectrum.hs)"]}, {"block": 6, "type": "markdown", "linesLength": 1, "startIndex": 32, "lines": ["You might notice something about the impulse and its DFT:"]}, {"block": 7, "type": "code", "linesLength": 1, "startIndex": 33, "lines": ["np.sum(wave.ys**2)"]}, {"block": 8, "type": "code", "linesLength": 1, "startIndex": 34, "lines": ["np.sum(impulse_spectrum.hs**2)"]}, {"block": 9, "type": "markdown", "linesLength": 1, "startIndex": 35, "lines": ["In general, the total magnitue of DFT(y) is N times the total magnitude of y.\n"]}, {"block": 10, "type": "markdown", "linesLength": 3, "startIndex": 36, "lines": ["###System characterization\n", "\n", "Let's look at a mini example of system characterization.  Suppose you have a system that smooths the signal by taking a moving average of adjacent elements:"]}, {"block": 11, "type": "code", "linesLength": 2, "startIndex": 39, "lines": ["window_array = np.array([0.5, 0.5, 0, 0, 0, 0, 0, 0,])\n", "window = thinkdsp.Wave(window_array, framerate=8)"]}, {"block": 12, "type": "markdown", "linesLength": 1, "startIndex": 41, "lines": ["For this moving average window, we can compute the transfer function:"]}, {"block": 13, "type": "code", "linesLength": 2, "startIndex": 42, "lines": ["filtr = window.make_spectrum(full=True)\n", "print(filtr.hs)"]}, {"block": 14, "type": "markdown", "linesLength": 1, "startIndex": 44, "lines": ["Here are the magnitudes:"]}, {"block": 15, "type": "code", "linesLength": 1, "startIndex": 45, "lines": ["filtr.amps"]}, {"block": 16, "type": "markdown", "linesLength": 0, "startIndex": 46, "lines": []}, {"block": 17, "type": "code", "linesLength": 2, "startIndex": 46, "lines": ["filtr.plot()\n", "thinkplot.config(xlabel='Frequency', ylabel='Amplitude')"]}, {"block": 18, "type": "markdown", "linesLength": 1, "startIndex": 48, "lines": ["If you multiply the transfer function by the spectrum of an impulse (which is all ones), the result is the filter:"]}, {"block": 19, "type": "code", "linesLength": 2, "startIndex": 49, "lines": ["product = impulse_spectrum * filtr\n", "print(product.hs)"]}, {"block": 20, "type": "code", "linesLength": 1, "startIndex": 51, "lines": ["max(abs(product.hs - filtr.hs))"]}, {"block": 21, "type": "markdown", "linesLength": 1, "startIndex": 52, "lines": ["Now if you transform back to the time domain, you have the impulse response, which looks a lot like the window:"]}, {"block": 22, "type": "code", "linesLength": 2, "startIndex": 53, "lines": ["filtered = product.make_wave()\n", "filtered.plot()"]}, {"block": 23, "type": "code", "linesLength": 1, "startIndex": 55, "lines": ["print(filtered.ys.real)"]}, {"block": 24, "type": "markdown", "linesLength": 1, "startIndex": 56, "lines": ["This example is meant to demonstrate why a recording of an impulse response is sufficient to characterize a system: because it is the IDFT of the transfer function."]}, {"block": 25, "type": "markdown", "linesLength": 3, "startIndex": 57, "lines": ["###Acoustic impulse response\n", "\n", "Here's a recording of a gunshot, which approximates the acoustic impulse response of the room:"]}, {"block": 26, "type": "code", "linesLength": 9, "startIndex": 60, "lines": ["response = thinkdsp.read_wave('180961__kleeb__gunshots.wav')\n", "\n", "start = 0.26\n", "response = response.segment(start=start)\n", "response.shift(-start)\n", "\n", "response.normalize()\n", "response.plot()\n", "thinkplot.config(xlabel='Time (s)', ylim=[-1.05, 1.05])"]}, {"block": 27, "type": "markdown", "linesLength": 1, "startIndex": 69, "lines": ["Here's what it sounds like:"]}, {"block": 28, "type": "code", "linesLength": 1, "startIndex": 70, "lines": ["response.make_audio()"]}, {"block": 29, "type": "markdown", "linesLength": 1, "startIndex": 71, "lines": ["The DFT of the impulse response is the transfer function:"]}, {"block": 30, "type": "code", "linesLength": 3, "startIndex": 72, "lines": ["transfer = response.make_spectrum()\n", "transfer.plot()\n", "thinkplot.config(xlabel='Frequency (Hz)', ylabel='Amplitude')"]}, {"block": 31, "type": "markdown", "linesLength": 1, "startIndex": 75, "lines": ["Here's the transfer function on a log-log scale:"]}, {"block": 32, "type": "code", "linesLength": 3, "startIndex": 76, "lines": ["transfer.plot()\n", "thinkplot.config(xlabel='Frequency (Hz)', ylabel='Amplitude',\n", "                 xscale='log', yscale='log')"]}, {"block": 33, "type": "markdown", "linesLength": 1, "startIndex": 79, "lines": ["Now we can simulate what a recording would sound like if it were played in the same room and recorded in the same way.  Here's the violin recording we have used before:"]}, {"block": 34, "type": "code", "linesLength": 10, "startIndex": 80, "lines": ["violin = thinkdsp.read_wave('92002__jcveliz__violin-origional.wav')\n", "\n", "start = 0.11\n", "violin = violin.segment(start=start)\n", "violin.shift(-start)\n", "\n", "violin.truncate(len(response))\n", "violin.normalize()\n", "violin.plot()\n", "thinkplot.config(xlabel='Time (s)', ylim=[-1.05, 1.05])"]}, {"block": 35, "type": "markdown", "linesLength": 1, "startIndex": 90, "lines": ["Here's what it sounds like before transformation:"]}, {"block": 36, "type": "code", "linesLength": 1, "startIndex": 91, "lines": ["violin.make_audio()"]}, {"block": 37, "type": "markdown", "linesLength": 1, "startIndex": 92, "lines": ["Now we compute the DFT of the violin recording."]}, {"block": 38, "type": "code", "linesLength": 1, "startIndex": 93, "lines": ["spectrum = violin.make_spectrum()"]}, {"block": 39, "type": "markdown", "linesLength": 1, "startIndex": 94, "lines": ["I trimmed the violin recording to the same length as the impulse response:"]}, {"block": 40, "type": "code", "linesLength": 1, "startIndex": 95, "lines": ["len(spectrum.hs), len(transfer.hs)"]}, {"block": 41, "type": "markdown", "linesLength": 1, "startIndex": 96, "lines": ["We we can multiply in the frequency domain and the transform back to the time domain."]}, {"block": 42, "type": "code", "linesLength": 2, "startIndex": 97, "lines": ["output = (spectrum * transfer).make_wave()\n", "output.normalize()"]}, {"block": 43, "type": "markdown", "linesLength": 1, "startIndex": 99, "lines": ["Here's a  comparison of the original and transformed recordings:"]}, {"block": 44, "type": "code", "linesLength": 1, "startIndex": 100, "lines": ["violin.plot()"]}, {"block": 45, "type": "code", "linesLength": 1, "startIndex": 101, "lines": ["output.plot()"]}, {"block": 46, "type": "markdown", "linesLength": 1, "startIndex": 102, "lines": ["And here's what it sounds like:"]}, {"block": 47, "type": "code", "linesLength": 1, "startIndex": 103, "lines": ["output.make_audio()"]}, {"block": 48, "type": "markdown", "linesLength": 1, "startIndex": 104, "lines": ["At the beginning of the output, you might notice an extra note that has wrapped around from the end.  The reason is that multiplication in the frequency domain corresponds to *circular* convolution, which assumes that the signal is periodic.  When the signal is not periodic, we can avoid wrap-around by padding the signal with zeros."]}, {"block": 49, "type": "markdown", "linesLength": 3, "startIndex": 105, "lines": ["###Convolution\n", "\n", "To understand how that worked, you can think about the input signal as a series of impulses, and the output as the sum of shifted, scaled versions of the impulse response."]}, {"block": 50, "type": "code", "linesLength": 5, "startIndex": 108, "lines": ["def shifted_scaled(wave, shift, factor):\n", "    res = wave.copy()\n", "    res.shift(shift)\n", "    res.scale(factor)\n", "    return res"]}, {"block": 51, "type": "markdown", "linesLength": 1, "startIndex": 113, "lines": ["Here's what it would sound like if we fired a big gun followed by a small gun:"]}, {"block": 52, "type": "code", "linesLength": 6, "startIndex": 114, "lines": ["dt = 1\n", "factor = 0.5\n", "\n", "response2 = response + shifted_scaled(response, dt, factor)\n", "response2.plot()\n", "thinkplot.config(xlabel='time (s)', ylabel='amplitude', ylim=[-1.05, 1.05])"]}, {"block": 53, "type": "markdown", "linesLength": 1, "startIndex": 120, "lines": ["Two gunshots:"]}, {"block": 54, "type": "code", "linesLength": 1, "startIndex": 121, "lines": ["response2.make_audio()"]}, {"block": 55, "type": "markdown", "linesLength": 3, "startIndex": 122, "lines": ["Adding up shifted, scaled copies of the impulse response doesn't always sounds like gunshots.  If there are enough of them, close enough together, it sounds like a wave.\n", "\n", "Here's what it sounds like if we fire 220 guns at a rate of 441 gunshots per second:"]}, {"block": 56, "type": "code", "linesLength": 5, "startIndex": 125, "lines": ["dt = 1 / 441\n", "total = 0\n", "for k in range(220):\n", "    total += shifted_scaled(response, k*dt, 1.0)\n", "total.normalize()"]}, {"block": 57, "type": "code", "linesLength": 1, "startIndex": 130, "lines": ["total.plot()"]}, {"block": 58, "type": "markdown", "linesLength": 1, "startIndex": 131, "lines": ["Here's what it sounds like:"]}, {"block": 59, "type": "code", "linesLength": 1, "startIndex": 132, "lines": ["total.make_audio()"]}, {"block": 60, "type": "markdown", "linesLength": 1, "startIndex": 133, "lines": ["To me it sounds a bit like a car horn in a garage.\n"]}, {"block": 61, "type": "markdown", "linesLength": 1, "startIndex": 134, "lines": ["We can do the same thing with an arbitrary input signal."]}, {"block": 62, "type": "code", "linesLength": 4, "startIndex": 135, "lines": ["signal = thinkdsp.SawtoothSignal(freq=441)\n", "wave = signal.make_wave(duration=0.2, framerate=response.framerate)\n", "wave.plot()\n", "thinkplot.config(xlabel='Time (s)', ylim=[-1.05, 1.05])"]}, {"block": 63, "type": "markdown", "linesLength": 1, "startIndex": 139, "lines": ["And here's what we get if we use the wave to generate shifted, scaled versions of the impulse response:"]}, {"block": 64, "type": "code", "linesLength": 4, "startIndex": 140, "lines": ["total = 0\n", "for t, y in zip(wave.ts, wave.ys):\n", "    total += shifted_scaled(response, t, y)\n", "total.normalize()"]}, {"block": 65, "type": "markdown", "linesLength": 1, "startIndex": 144, "lines": ["The result is a simulation of what the wave would sound like if it was recorded in the room where the gunshot was recorded:"]}, {"block": 66, "type": "code", "linesLength": 2, "startIndex": 145, "lines": ["total.plot()\n", "thinkplot.config(xlabel='Time (s)', ylabel='Amplitude', ylim=[-1.05, 1.05])"]}, {"block": 67, "type": "markdown", "linesLength": 1, "startIndex": 147, "lines": ["And here's what it sounds like:"]}, {"block": 68, "type": "code", "linesLength": 1, "startIndex": 148, "lines": ["total.make_audio()"]}, {"block": 69, "type": "markdown", "linesLength": 1, "startIndex": 149, "lines": ["Here's a comparison of the spectrum before and after convolution:"]}, {"block": 70, "type": "code", "linesLength": 6, "startIndex": 150, "lines": ["high = 5000\n", "wave.make_spectrum().plot(high=high, color='0.7')\n", "\n", "segment = total.segment(duration=0.2)\n", "segment.make_spectrum().plot(high=high)\n", "thinkplot.config(xlabel='Frequency (Hz)', ylabel='Amplitude')"]}, {"block": 71, "type": "markdown", "linesLength": 1, "startIndex": 156, "lines": ["Now that we recognize this operation as convolution, we can compute it using the convolve method:"]}, {"block": 72, "type": "code", "linesLength": 3, "startIndex": 157, "lines": ["convolved = wave.convolve(response)\n", "convolved.normalize()\n", "convolved.make_audio()"]}, {"block": 73, "type": "markdown", "linesLength": 1, "startIndex": 160, "lines": ["And we can do the same thing with the violin recording:"]}, {"block": 74, "type": "code", "linesLength": 3, "startIndex": 161, "lines": ["convolved2 = violin.convolve(response)\n", "convolved2.normalize()\n", "convolved2.make_audio()"]}, {"block": 75, "type": "code", "linesLength": 0, "startIndex": 164, "lines": []}]