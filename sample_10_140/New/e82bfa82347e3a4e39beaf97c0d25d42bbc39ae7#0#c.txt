[{"block": 0, "type": "code", "linesLength": 2, "startIndex": 0, "lines": ["from fastai import *        # Quick accesss to most common functionality\n", "from fastai.text import *   # Quick accesss to NLP functionality"]}, {"block": 1, "type": "code", "linesLength": 2, "startIndex": 2, "lines": ["path = untar_data(URLs.IMDB_SAMPLE)\n", "path"]}, {"block": 2, "type": "code", "linesLength": 2, "startIndex": 4, "lines": ["def open_text(fn:PathOrStr):\n", "    with open(fn,'r') as f: return ''.join(f.readlines())"]}, {"block": 3, "type": "code", "linesLength": 11, "startIndex": 6, "lines": ["def _treat_html(o:str)->str:\n", "    return o.replace('\\n','\\\\n')\n", "\n", "def _text2html_table(items:Collection[Collection[str]], widths:Collection[int])->str:\n", "    html_code = f\"<table>\"\n", "    for w in widths: html_code += f\"  <col width='{w}%'>\"\n", "    for line in items:\n", "        html_code += \"  <tr>\\n\"\n", "        html_code += \"\\n\".join([f\"    <th>{_treat_html(o)}</th>\" for o in line if len(o) >= 1])\n", "        html_code += \"\\n  </tr>\\n\"\n", "    return html_code + \"</table>\\n\""]}, {"block": 4, "type": "code", "linesLength": 31, "startIndex": 17, "lines": ["class Text(ItemBase):\n", "    def __init__(self, ids, text): self.data,self.text = ids,text\n", "    def __str__(self):  return str(self.text)\n", "    \n", "    def show_batch(self, idxs:Collection[int], rows:int, ds:Dataset, figsize:Tuple[int,int]=(9,10))->None:\n", "        from IPython.display import clear_output, display, HTML\n", "        items = [['text', 'label']]\n", "        for i in idxs[:rows]:\n", "            x,y = ds[i]\n", "            items.append([str(x), str(y)])\n", "        display(HTML(_text2html_table(items, [90,10])))\n", "\n", "class NumericalizedTextList(ItemList):\n", "    def __init__(self, items:Iterator, vocab:Vocab=None, **kwargs):\n", "        super().__init__(items, **kwargs)\n", "        self.vocab = vocab\n", "        \n", "    def new(self, items:Iterator, **kwargs)->'NumericalizedTextList':\n", "        return super().new(items=items, vocab=self.vocab, **kwargs)\n", "    \n", "    def get(self, i):\n", "        o = super().get(i)\n", "        return Text(o, self.vocab.textify(o))\n", "    \n", "class TextList(NumericalizedTextList):\n", "    def __post_init(self): pass\n", "\n", "class TextFilesList(TextList):\n", "    def __init__(self, items:Iterator, create_func:Callable=None, path:PathOrStr='.'):\n", "        texts = [open_text(fn) for fn in items]\n", "        super().__init__(texts, create_func, path)"]}, {"block": 5, "type": "code", "linesLength": 14, "startIndex": 48, "lines": ["class TextProcessor(PreProcessor):\n", "    def __init__(self, tokenizer:Tokenizer=None, chunksize:int=10000,\n", "                 vocab:Vocab=None, max_vocab:int=60000, min_freq:int=2):\n", "        self.chunksize,self.max_vocab,self.min_freq = chunksize,max_vocab,min_freq\n", "        self.tokenizer,self.vocab = ifnone(tokenizer, Tokenizer()),vocab\n", "\n", "    def process(self, ds):\n", "        tokens = []\n", "        for i in progress_bar(range(0,len(ds),self.chunksize), leave=False):\n", "            tokens += self.tokenizer.process_all(ds.items[i:i+self.chunksize])\n", "        ds.items = tokens\n", "        if self.vocab is None: self.vocab = Vocab.create(ds.items, self.max_vocab, self.min_freq)\n", "        ds.vocab = self.vocab\n", "        ds.items = np.array([self.vocab.numericalize(t) for t in ds.items])"]}, {"block": 6, "type": "code", "linesLength": 1, "startIndex": 62, "lines": ["processor=TextProcessor()"]}, {"block": 7, "type": "code", "linesLength": 4, "startIndex": 63, "lines": ["il = (TextList.from_csv(path, 'texts.csv', create_func=None, col='text', processor=processor)\n", "        .random_split_by_pct()\n", "        .label_from_df(cols=0)\n", "     )"]}, {"block": 8, "type": "code", "linesLength": 1, "startIndex": 67, "lines": ["len(il.valid.vocab.itos), len(il.train.vocab.itos)"]}, {"block": 9, "type": "code", "linesLength": 2, "startIndex": 68, "lines": ["df = pd.read_csv(path/'texts.csv')\n", "df.head()"]}, {"block": 10, "type": "code", "linesLength": 1, "startIndex": 70, "lines": ["il.add_test(df['text'].values);"]}, {"block": 11, "type": "code", "linesLength": 2, "startIndex": 71, "lines": ["class C(int):\n", "    "]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 73, "lines": ["il.train.y.classes,il.valid.y.classes,il.test.y.classes"]}, {"block": 13, "type": "code", "linesLength": 1, "startIndex": 74, "lines": ["len(il.valid.vocab.itos), len(il.train.vocab.itos), len(il.test.vocab.itos)"]}, {"block": 14, "type": "code", "linesLength": 1, "startIndex": 75, "lines": ["data = il.databunch()"]}, {"block": 15, "type": "code", "linesLength": 1, "startIndex": 76, "lines": ["data.show_batch(ds_type=DatasetType.Test)"]}, {"block": 16, "type": "code", "linesLength": 0, "startIndex": 77, "lines": []}]