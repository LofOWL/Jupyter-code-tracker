[{"block": 0, "type": "markdown", "linesLength": 1, "startIndex": 0, "lines": ["## Computer vision"]}, {"block": 1, "type": "code", "linesLength": 1, "startIndex": 1, "lines": ["from fastai.gen_doc.nbdoc import *"]}, {"block": 2, "type": "markdown", "linesLength": 7, "startIndex": 2, "lines": ["The [`vision`](/vision.html#vision) module of the fastai library contains all the necessary functions to define a Dataset and train a model for computer vision tasks. It contains four different submodules to reach that goal:\n", "- [`vision.image`](/vision.image.html#vision.image) contains the basic definition of an [`Image`](/vision.image.html#Image) object and all the functions that are used behind the scenes to apply transformations to such an object.\n", "- [`vision.transform`](/vision.transform.html#vision.transform) contains all the transforms we can use for data augmentation.\n", "- [`vision.data`](/vision.data.html#vision.data) contains the definition of [`ImageDataBunch`](/vision.data.html#ImageDataBunch) as well as the utility function to easily build a [`DataBunch`](/basic_data.html#DataBunch) for Computer Vision problems.\n", "- [`vision.learner`](/vision.learner.html#vision.learner) lets you build and fine-tune models with a pretrained CNN backbone or train a randomly initialized model from scratch.\n", "\n", "Each of the four module links above includes a quick overview and examples of the functionality of that module, as well as complete API documentation. Below, we'll provide a walk-thru of end to end computer vision model training with the most commonly used functionality."]}, {"block": 3, "type": "markdown", "linesLength": 1, "startIndex": 9, "lines": ["## Minimal training example"]}, {"block": 4, "type": "markdown", "linesLength": 1, "startIndex": 10, "lines": ["First, import everything you need from the fastai library."]}, {"block": 5, "type": "code", "linesLength": 1, "startIndex": 11, "lines": ["from fastai.vision import *"]}, {"block": 6, "type": "markdown", "linesLength": 1, "startIndex": 12, "lines": ["First, create a data folder containing a MNIST subset in `data/mnist_sample` using this little helper that will download it for you:"]}, {"block": 7, "type": "code", "linesLength": 2, "startIndex": 13, "lines": ["path = untar_data(URLs.MNIST_SAMPLE)\n", "path"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 15, "lines": ["Since this contains standard [`train`](/train.html#train) and `valid` folders, and each contains one folder per class, you can create a [`DataBunch`](/basic_data.html#DataBunch) in a single line:"]}, {"block": 9, "type": "code", "linesLength": 1, "startIndex": 16, "lines": ["data = ImageDataBunch.from_folder(path)"]}, {"block": 10, "type": "markdown", "linesLength": 1, "startIndex": 17, "lines": ["You load a pretrained model (from [`vision.models`](/vision.models.html#vision.models)) ready for fine tuning:"]}, {"block": 11, "type": "code", "linesLength": 1, "startIndex": 18, "lines": ["learn = create_cnn(data, models.resnet18, metrics=accuracy)"]}, {"block": 12, "type": "markdown", "linesLength": 1, "startIndex": 19, "lines": ["And now you're ready to train!"]}, {"block": 13, "type": "code", "linesLength": 1, "startIndex": 20, "lines": ["learn.fit(1)"]}, {"block": 14, "type": "markdown", "linesLength": 1, "startIndex": 21, "lines": ["Let's look briefly at each of the [`vision`](/vision.html#vision) submodules."]}, {"block": 15, "type": "markdown", "linesLength": 1, "startIndex": 22, "lines": ["## Getting the data"]}, {"block": 16, "type": "markdown", "linesLength": 1, "startIndex": 23, "lines": ["The most important piece of [`vision.data`](/vision.data.html#vision.data) for classification is the [`ImageDataBunch`](/vision.data.html#ImageDataBunch). If you've got labels as subfolders, then you can just say:"]}, {"block": 17, "type": "code", "linesLength": 1, "startIndex": 24, "lines": ["data = ImageDataBunch.from_folder(path)"]}, {"block": 18, "type": "markdown", "linesLength": 1, "startIndex": 25, "lines": ["It will grab the data in a train and validation sets from subfolders of classes. You can then access that training and validation set by grabbing the corresponding attribute in [`data`](/vision.data.html#vision.data)."]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 26, "lines": ["ds = data.train_ds"]}, {"block": 20, "type": "markdown", "linesLength": 1, "startIndex": 27, "lines": ["## Images"]}, {"block": 21, "type": "markdown", "linesLength": 1, "startIndex": 28, "lines": ["That brings us to [`vision.image`](/vision.image.html#vision.image), which defines the [`Image`](/vision.image.html#Image) class. Our dataset will return [`Image`](/vision.image.html#Image) objects when we index it. Images automatically display in notebooks:"]}, {"block": 22, "type": "code", "linesLength": 2, "startIndex": 29, "lines": ["img,label = ds[0]\n", "img"]}, {"block": 23, "type": "markdown", "linesLength": 1, "startIndex": 31, "lines": ["You can change the way they're displayed:"]}, {"block": 24, "type": "code", "linesLength": 1, "startIndex": 32, "lines": ["img.show(figsize=(2,2), title='MNIST digit')"]}, {"block": 25, "type": "markdown", "linesLength": 1, "startIndex": 33, "lines": ["And you can transform them in various ways:"]}, {"block": 26, "type": "code", "linesLength": 1, "startIndex": 34, "lines": ["img.rotate(35)"]}, {"block": 27, "type": "markdown", "linesLength": 1, "startIndex": 35, "lines": ["## Data augmentation"]}, {"block": 28, "type": "markdown", "linesLength": 1, "startIndex": 36, "lines": ["[`vision.transform`](/vision.transform.html#vision.transform) lets us do data augmentation. Simplest is to choose from a standard set of transforms, where the defaults are designed for photos:"]}, {"block": 29, "type": "code", "linesLength": 1, "startIndex": 37, "lines": ["help(get_transforms)"]}, {"block": 30, "type": "markdown", "linesLength": 1, "startIndex": 38, "lines": ["...or create the exact list you want:"]}, {"block": 31, "type": "code", "linesLength": 1, "startIndex": 39, "lines": ["tfms = [rotate(degrees=(-20,20)), symmetric_warp(magnitude=(-0.3,0.3))]"]}, {"block": 32, "type": "markdown", "linesLength": 1, "startIndex": 40, "lines": ["You can apply these transforms to your images by using their `apply_tfms` method."]}, {"block": 33, "type": "code", "linesLength": 2, "startIndex": 41, "lines": ["fig,axes = plt.subplots(1,4,figsize=(8,2))\n", "for ax in axes: ds[0][0].apply_tfms(tfms).show(ax=ax)"]}, {"block": 34, "type": "markdown", "linesLength": 1, "startIndex": 43, "lines": ["You can create a [`DataBunch`](/basic_data.html#DataBunch) with your transformed training and validation data loaders in a single step, passing in a tuple of *(train_tfms, valid_tfms)*:"]}, {"block": 35, "type": "code", "linesLength": 1, "startIndex": 44, "lines": ["data = ImageDataBunch.from_folder(path, ds_tfms=(tfms, []))"]}, {"block": 36, "type": "markdown", "linesLength": 1, "startIndex": 45, "lines": ["## Training and interpretation"]}, {"block": 37, "type": "markdown", "linesLength": 1, "startIndex": 46, "lines": ["Now you're ready to train a model. To create a model, simply pass your [`DataBunch`](/basic_data.html#DataBunch) and a model creation function (such as one provided by [`vision.models`](/vision.models.html#vision.models) or [<code>torchvision.models</code>](https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models)) to [`create_cnn`](/vision.learner.html#create_cnn), and call [`fit`](/basic_train.html#fit):"]}, {"block": 38, "type": "code", "linesLength": 2, "startIndex": 47, "lines": ["learn = create_cnn(data, models.resnet18, metrics=accuracy)\n", "learn.fit(1)"]}, {"block": 39, "type": "markdown", "linesLength": 1, "startIndex": 49, "lines": ["Now we can take a look at the most incorrect images, and also the classification matrix."]}, {"block": 40, "type": "code", "linesLength": 1, "startIndex": 50, "lines": ["interp = ClassificationInterpretation.from_learner(learn)"]}, {"block": 41, "type": "code", "linesLength": 1, "startIndex": 51, "lines": ["interp.plot_top_losses(9, figsize=(6,6))"]}, {"block": 42, "type": "code", "linesLength": 1, "startIndex": 52, "lines": ["interp.plot_confusion_matrix()"]}, {"block": 43, "type": "markdown", "linesLength": 1, "startIndex": 53, "lines": ["To simply predict the result of a new image (of type [`Image`](/vision.image.html#Image), so opened with [`open_image`](/vision.image.html#open_image) for instance), just use `learn.predict`. It returns the class, its index and the probabilities of each class."]}, {"block": 44, "type": "code", "linesLength": 2, "startIndex": 54, "lines": ["img = learn.data.train_ds[0][0]\n", "learn.predict(img)"]}]