[{"block": 0, "type": "markdown", "linesLength": 1, "startIndex": 0, "lines": ["# The data block API"]}, {"block": 1, "type": "code", "linesLength": 4, "startIndex": 1, "lines": ["from fastai.gen_doc.nbdoc import *\n", "from fastai.vision import * \n", "from fastai import *\n", "np.random.seed(42)"]}, {"block": 2, "type": "markdown", "linesLength": 8, "startIndex": 5, "lines": ["The data block API lets you customize how to create a [`DataBunch`](/basic_data.html#DataBunch) by isolating the underlying parts of that process in separate blocks, mainly:\n", "- where are the inputs\n", "- how to split the data into a training and validation set\n", "- how to label them\n", "- possible transforms to apply\n", "- how to warp in dataloaders and create the [`DataBunch`](/basic_data.html#DataBunch)\n", "\n", "This is a bit longer than using the factory methods but is way more flexible. As usual, we'll begin with end-to-end examples, then switch to the details of each of those parts."]}, {"block": 3, "type": "markdown", "linesLength": 1, "startIndex": 13, "lines": ["## Examples of use"]}, {"block": 4, "type": "markdown", "linesLength": 1, "startIndex": 14, "lines": ["Let's begin by our traditional MNIST example."]}, {"block": 5, "type": "code", "linesLength": 3, "startIndex": 15, "lines": ["path = untar_data(URLs.MNIST_TINY)\n", "tfms = get_transforms(do_flip=False)\n", "path.ls()"]}, {"block": 6, "type": "code", "linesLength": 1, "startIndex": 18, "lines": ["(path/'train').ls()"]}, {"block": 7, "type": "markdown", "linesLength": 1, "startIndex": 19, "lines": ["In [`vision.data`](/vision.data.html#vision.data), we create an easy [`DataBunch`](/basic_data.html#DataBunch) suitable for classification by simply typing:"]}, {"block": 8, "type": "code", "linesLength": 1, "startIndex": 20, "lines": ["data = ImageDataBunch.from_folder(path, ds_tfms=tfms, size=24)"]}, {"block": 9, "type": "markdown", "linesLength": 1, "startIndex": 21, "lines": ["This is aimed at data that is in folders following an ImageNet style, with a train and valid directory containing each one subdirectory per class, where all the pictures are. With the data block API, the same thing is achieved like this:"]}, {"block": 10, "type": "code", "linesLength": 6, "startIndex": 22, "lines": ["data = (ImageItemList.from_folder(path) #Where to find the data? -> in path and its subfolders\n", "        .split_by_folder()              #How to split in train/valid? -> use the folders\n", "        .label_from_folder()            #How to label? -> depending on the folder of the filenames\n", "        .add_test_folder()              #Optionally add a test set (here default name is test)\n", "        .transform(tfms, size=64)       #Data augmentation? -> use tfms with a size of 64\n", "        .databunch())                   #Finally? -> use the defaults for conversion to ImageDataBunch"]}, {"block": 11, "type": "code", "linesLength": 1, "startIndex": 28, "lines": ["data.show_batch(3, figsize=(6,6), hide_axis=False)"]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 29, "lines": ["data.train_ds[0], data.test_ds.classes"]}, {"block": 13, "type": "markdown", "linesLength": 1, "startIndex": 30, "lines": ["Let's look at another example from [`vision.data`](/vision.data.html#vision.data) with the planet dataset. This time, it's a multiclassification problem with the labels in a csv file and no given split between valid and train data, so we use a random split. The factory method is:"]}, {"block": 14, "type": "code", "linesLength": 2, "startIndex": 31, "lines": ["planet = untar_data(URLs.PLANET_TINY)\n", "planet_tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)"]}, {"block": 15, "type": "code", "linesLength": 1, "startIndex": 33, "lines": ["data = ImageDataBunch.from_csv(planet, folder='train', size=128, suffix='.jpg', sep = ' ', ds_tfms=planet_tfms)"]}, {"block": 16, "type": "markdown", "linesLength": 1, "startIndex": 34, "lines": ["With the data block API we can rewrite this like that:"]}, {"block": 17, "type": "code", "linesLength": 10, "startIndex": 35, "lines": ["data = (ImageItemList.from_csv(planet, 'labels.csv', folder='train', suffix='.jpg')\n", "        #Where to find the data? -> in planet 'train' folder\n", "        .random_split_by_pct()\n", "        #How to split in train/valid? -> randomly with the default 20% in valid\n", "        .label_from_df(sep=' ')\n", "        #How to label? -> use the csv file\n", "        .transform(planet_tfms, size=128)\n", "        #Data augmentation? -> use tfms with a size of 128\n", "        .databunch())                          \n", "        #Finally -> use the defaults for conversion to databunch"]}, {"block": 18, "type": "code", "linesLength": 1, "startIndex": 45, "lines": ["data.show_batch(rows=2, figsize=(9,7))"]}, {"block": 19, "type": "markdown", "linesLength": 1, "startIndex": 46, "lines": ["The data block API also allows you to use dataset types for which there is no direct [`ImageDataBunch`](/vision.data.html#ImageDataBunch) factory method. For a segmentation task, for instance, we can use it to quickly get a [`DataBunch`](/basic_data.html#DataBunch). Let's take the example of the [camvid dataset](http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/). The images are in an 'images' folder and their corresponding mask is in a 'labels' folder."]}, {"block": 20, "type": "code", "linesLength": 3, "startIndex": 47, "lines": ["camvid = untar_data(URLs.CAMVID_TINY)\n", "path_lbl = camvid/'labels'\n", "path_img = camvid/'images'"]}, {"block": 21, "type": "markdown", "linesLength": 1, "startIndex": 50, "lines": ["We have a file that gives us the names of the classes (what each code inside the masks corresponds to: a pedestrian, a tree, a road...)"]}, {"block": 22, "type": "code", "linesLength": 1, "startIndex": 51, "lines": ["codes = np.loadtxt(camvid/'codes.txt', dtype=str); codes"]}, {"block": 23, "type": "markdown", "linesLength": 1, "startIndex": 52, "lines": ["And we define the following function that infers the mask filename from the image filename."]}, {"block": 24, "type": "code", "linesLength": 1, "startIndex": 53, "lines": ["get_y_fn = lambda x: path_lbl/f'{x.stem}_P{x.suffix}'"]}, {"block": 25, "type": "markdown", "linesLength": 1, "startIndex": 54, "lines": ["Then we can easily define a [`DataBunch`](/basic_data.html#DataBunch) using the data block API. Here we need to use `tfm_y=True` in the transform call because we need the same transforms to be applied to the target mask as were applied to the image."]}, {"block": 26, "type": "code", "linesLength": 5, "startIndex": 55, "lines": ["data = (SegmentationItemList.from_folder(path_img)\n", "        .random_split_by_pct()\n", "        .label_from_func(get_y_fn, classes=codes)\n", "        .transform(get_transforms(), tfm_y=True)\n", "        .databunch())"]}, {"block": 27, "type": "code", "linesLength": 1, "startIndex": 60, "lines": ["data.show_batch(rows=2, figsize=(7,5))"]}, {"block": 28, "type": "markdown", "linesLength": 1, "startIndex": 61, "lines": ["One last example for object detection. We use our tiny sample of the [COCO dataset](http://cocodataset.org/#home) here. There is a helper function in the library that reads the annotation file and returns the list of images names with the list of labelled bboxes associated to it. We convert it to a dictionary that maps image names with their bboxes and then write the function that will give us the target for each image filename."]}, {"block": 29, "type": "code", "linesLength": 4, "startIndex": 62, "lines": ["coco = untar_data(URLs.COCO_TINY)\n", "images, lbl_bbox = get_annotations(coco/'train.json')\n", "img2bbox = dict(zip(images, lbl_bbox))\n", "get_y_func = lambda o:img2bbox[o.name]"]}, {"block": 30, "type": "markdown", "linesLength": 1, "startIndex": 66, "lines": ["The following code is very similar to what we saw before. The only new addition is the use of special function to collate the samples in batches. This comes from the fact that our images may have multiple bounding boxes, so we need to pad them to the largest number of bounding boxes."]}, {"block": 31, "type": "code", "linesLength": 10, "startIndex": 67, "lines": ["data = (ObjectItemList.from_folder(coco)\n", "        #Where are the images? -> in coco\n", "        .random_split_by_pct()                          \n", "        #How to split in train/valid? -> randomly with the default 20% in valid\n", "        .label_from_func(get_y_func)\n", "        #How to find the labels? -> use get_y_func\n", "        .transform(get_transforms(), tfm_y=True)\n", "        #Data augmentation? -> Standard transforms with tfm_y=True\n", "        .databunch(bs=16, collate_fn=bb_pad_collate))   \n", "        #Finally we convert to a DataBunch and we use bb_pad_collate"]}, {"block": 32, "type": "code", "linesLength": 1, "startIndex": 77, "lines": ["data.show_batch(rows=2, ds_type=DatasetType.Valid, figsize=(6,6))"]}, {"block": 33, "type": "markdown", "linesLength": 1, "startIndex": 78, "lines": ["## Provide inputs"]}, {"block": 34, "type": "markdown", "linesLength": 1, "startIndex": 79, "lines": ["The inputs we want to feed our model are regrouped in the following class. The class contains methods to get the corresponding labels."]}, {"block": 35, "type": "code", "linesLength": 1, "startIndex": 80, "lines": ["show_doc(ItemList, title_level=3, doc_string=False)"]}, {"block": 36, "type": "markdown", "linesLength": 1, "startIndex": 81, "lines": ["This class regroups the inputs for our model in `items` and saves a `path` attribute which is where it will look for any files (image files, csv file with labels...) `create_func` is applied to `items` to get the final output. `label_cls` will be called to create the labels from the result of the label function, `xtra` contains additional information (usually an underlying dataframe) and `processor` is to be applied to the inputs after the splitting and labelling."]}, {"block": 37, "type": "code", "linesLength": 1, "startIndex": 82, "lines": ["show_doc(ItemList.from_folder)"]}, {"block": 38, "type": "code", "linesLength": 1, "startIndex": 83, "lines": ["show_doc(ItemList.from_df)"]}, {"block": 39, "type": "code", "linesLength": 1, "startIndex": 84, "lines": ["show_doc(ItemList.from_csv)"]}, {"block": 40, "type": "markdown", "linesLength": 1, "startIndex": 85, "lines": ["## Split the data"]}, {"block": 41, "type": "markdown", "linesLength": 1, "startIndex": 86, "lines": ["The following functions are methods of `ItemList`, to create an `ItemLists` in different ways."]}, {"block": 42, "type": "code", "linesLength": 1, "startIndex": 87, "lines": ["show_doc(ItemList.random_split_by_pct)"]}, {"block": 43, "type": "code", "linesLength": 1, "startIndex": 88, "lines": ["show_doc(ItemList.split_by_files)"]}, {"block": 44, "type": "code", "linesLength": 1, "startIndex": 89, "lines": ["show_doc(ItemList.split_by_fname_file)"]}, {"block": 45, "type": "code", "linesLength": 1, "startIndex": 90, "lines": ["show_doc(ItemList.split_by_folder)"]}, {"block": 46, "type": "code", "linesLength": 1, "startIndex": 91, "lines": ["jekyll_note(\"This method looks at the folder immediately after `self.path` for `valid` and `train`.\")"]}, {"block": 47, "type": "code", "linesLength": 1, "startIndex": 92, "lines": ["show_doc(ItemList.split_by_idx)"]}, {"block": 48, "type": "code", "linesLength": 1, "startIndex": 93, "lines": ["show_doc(ItemList.split_by_valid_func)"]}, {"block": 49, "type": "code", "linesLength": 1, "startIndex": 94, "lines": ["show_doc(ItemList.split_from_df)"]}, {"block": 50, "type": "markdown", "linesLength": 1, "startIndex": 95, "lines": ["## Labelling the inputs"]}, {"block": 51, "type": "markdown", "linesLength": 1, "startIndex": 96, "lines": ["All the followings are methods of `ItemList` (`ItemLists` delegates them to each one of its `ItemList`). Note that some of them are primarly intended for inputs that are filenames and might not work in general situations."]}, {"block": 52, "type": "code", "linesLength": 1, "startIndex": 97, "lines": ["show_doc(ItemList.label_from_list)"]}, {"block": 53, "type": "code", "linesLength": 1, "startIndex": 98, "lines": ["show_doc(ItemList.label_from_df)"]}, {"block": 54, "type": "code", "linesLength": 1, "startIndex": 99, "lines": ["show_doc(ItemList.label_const)"]}, {"block": 55, "type": "code", "linesLength": 1, "startIndex": 100, "lines": ["show_doc(ItemList.label_from_folder)"]}, {"block": 56, "type": "code", "linesLength": 1, "startIndex": 101, "lines": ["jekyll_note(\"This method looks at the last subfolder in the path to determine the classes.\")"]}, {"block": 57, "type": "code", "linesLength": 1, "startIndex": 102, "lines": ["show_doc(ItemList.label_from_func)"]}, {"block": 58, "type": "markdown", "linesLength": 1, "startIndex": 103, "lines": ["This method is primarly intended for inputs that are filenames, but could work in other settings."]}, {"block": 59, "type": "code", "linesLength": 1, "startIndex": 104, "lines": ["show_doc(ItemList.label_from_re)"]}, {"block": 60, "type": "code", "linesLength": 1, "startIndex": 105, "lines": ["show_doc(LabelList, title_level=3, doc_string=False)"]}, {"block": 61, "type": "markdown", "linesLength": 1, "startIndex": 106, "lines": ["The basic dataset in fastai. Inputs are in `x`, targets in `y`. Optionally apply `tfms` to `x` and also `y` if `tfm_y` is `True`. "]}, {"block": 62, "type": "code", "linesLength": 1, "startIndex": 107, "lines": ["show_doc(LabelList.process)"]}, {"block": 63, "type": "code", "linesLength": 1, "startIndex": 108, "lines": ["show_doc(LabelList.transform)"]}, {"block": 64, "type": "code", "linesLength": 1, "startIndex": 109, "lines": ["show_doc(ItemLists, doc_string=False, title_level=3)"]}, {"block": 65, "type": "markdown", "linesLength": 1, "startIndex": 110, "lines": ["Data in `path` split between several streams of inputs, `train`, `valid` and maybe `test`."]}, {"block": 66, "type": "code", "linesLength": 1, "startIndex": 111, "lines": ["show_doc(LabelLists, title_level=3, doc_string=False)"]}, {"block": 67, "type": "markdown", "linesLength": 1, "startIndex": 112, "lines": ["Data in `path` split between several streams of inputs/targets, `train`, `valid` and maybe `test`."]}, {"block": 68, "type": "code", "linesLength": 1, "startIndex": 113, "lines": ["show_doc(LabelLists.add_test)"]}, {"block": 69, "type": "code", "linesLength": 1, "startIndex": 114, "lines": ["show_doc(LabelLists.add_test_folder)"]}, {"block": 70, "type": "code", "linesLength": 1, "startIndex": 115, "lines": ["show_doc(LabelLists.databunch)"]}, {"block": 71, "type": "markdown", "linesLength": 1, "startIndex": 116, "lines": ["## Preprocessing"]}, {"block": 72, "type": "markdown", "linesLength": 1, "startIndex": 117, "lines": ["Preprocessing is a step that happens after the data has been split and labelled, where the inputs and targets go through a bunch of `PreProcessor`."]}, {"block": 73, "type": "code", "linesLength": 1, "startIndex": 118, "lines": ["show_doc(PreProcessor, title_level=3, doc_string=False)"]}, {"block": 74, "type": "markdown", "linesLength": 1, "startIndex": 119, "lines": ["Basic class that will regroup functions applied to the train set and recording an inner state (vocabulary, statistics of transforms) that it will keep when applied to the validation and maybe the test set."]}, {"block": 75, "type": "markdown", "linesLength": 1, "startIndex": 120, "lines": ["## Undocumented Methods - Methods moved below this line will intentionally be hidden"]}, {"block": 76, "type": "markdown", "linesLength": 1, "startIndex": 121, "lines": ["## New Methods - Please document or move to the undocumented section"]}]