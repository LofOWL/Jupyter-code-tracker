[{"block": 0, "type": "markdown", "linesLength": 3, "startIndex": 0, "lines": ["<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n", "\n", "<i>Licensed under the MIT License.</i>"]}, {"block": 1, "type": "markdown", "linesLength": 1, "startIndex": 3, "lines": ["# Vowpal Wabbit Deep Dive"]}, {"block": 2, "type": "markdown", "linesLength": 15, "startIndex": 4, "lines": ["<center>\n", "<img src=\"https://github.com/VowpalWabbit/vowpal_wabbit/blob/master/logo_assets/vowpal-wabbits-github-logo.png?raw=true\" height=\"30%\" width=\"30%\" alt=\"Vowpal Wabbit\">\n", "</center>\n", "\n", "[Vowpal Wabbit](https://github.com/VowpalWabbit/vowpal_wabbit) is a fast online machine learning library that implements several algorithms relevant to the recommendation use case.\n", "\n", "The main advantage of Vowpal Wabbit (VW) is that training is done in an online fashion typically using Stochastic Gradient Descent or similar variants, which allows it to scale well to very large datasets. Additionally, it is optimized to run very quickly and can support distributed training scenarios for extremely large datasets.\n", "\n", "In this notebook we demonstrate how to use the VW library to generate recommendations on the [Movielens](https://grouplens.org/datasets/movielens/) dataset.\n", "\n", "Several things are worth noting in how VW is being used in this notebook. By leveraging an Azure Data Science Virtual Machine ([DSVM](https://azure.microsoft.com/en-us/services/virtual-machines/data-science-virtual-machines/)), VW comes pre-installed and can be used directly from the command line. There are also python bindings to be able to use VW within a python environment and even a wrapper conforming to the SciKit-Learn Estimator API. However, the python bindings must be installed as an additional python package with Boost dependencies, so for simplicity's sake execution of VW is done via a subprocess call mimicking what would happen from the command line execution of the model.\n", "\n", "VW expects a specific [input format](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Input-format), and to_vw() below is a convenience function to convert the standard movielens dataset into that format. Datafiles then are written to disk and passed to VW for training.\n", "\n", "The examples shown are to demonstrate functional capabilities not to indicate performance advantages of different approaches. There are several hyper-parameters (i.e. learning rate and regularization tems) that can greatly impact performance of VW models which can be adjusted using [command line options](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Command-Line-Arguments). To properly compare approaches it is helpful to learn about and tune these parameters for production workloads."]}, {"block": 3, "type": "markdown", "linesLength": 1, "startIndex": 19, "lines": ["<h3>Environment Setup</h3>"]}, {"block": 4, "type": "code", "linesLength": 15, "startIndex": 20, "lines": ["import os\n", "import sys\n", "from subprocess import run\n", "from tempfile import TemporaryDirectory\n", "from time import process_time\n", "\n", "import pandas as pd\n", "import papermill as pm\n", "\n", "from reco_utils.dataset.movielens import load_pandas_df\n", "from reco_utils.dataset.python_splitters import python_stratified_split\n", "from reco_utils.evaluation.python_evaluation import rmse, mae, exp_var, rsquared, get_top_k_items\n", "\n", "print(\"System version: {}\".format(sys.version))\n", "print(\"Pandas version: {}\".format(pd.__version__))"]}, {"block": 5, "type": "code", "linesLength": 23, "startIndex": 35, "lines": ["def to_vw(df, output, logistic=False):\n", "    \"\"\"Convert Pandas DataFrame to vw input format\n", "    Args:\n", "        df (pd.DataFrame): input DataFrame\n", "        output (str): path to output file\n", "        logistic (bool): flag to convert label to logistic value\n", "    \"\"\"\n", "    with open(output, 'w') as f:\n", "        tmp = df.reset_index()\n", "\n", "        # we need to reset the rating type to an integer to simplify the vw formatting\n", "        tmp['rating'] = tmp['rating'].astype('int64')\n", "        \n", "        # convert rating to binary value\n", "        if logistic:\n", "            tmp['rating'] = tmp['rating'].apply(lambda x: 1 if x >= 3 else -1)\n", "        \n", "        # convert each row to VW input format\n", "        # [label] [tag]|[user namespace] [user id feature] |[item namespace] [movie id feature]\n", "        # label is the true rating, tag is a unique id for the example just used to link predictions to truth\n", "        # user and item namespaces separate the features to support interaction features through command line options\n", "        for _, row in tmp.iterrows():\n", "            f.write('{rating} {index}|user {userID} |item {itemID}\\n'.format_map(row))"]}, {"block": 6, "type": "code", "linesLength": 43, "startIndex": 58, "lines": ["def run_vw(train_params, test_params, test_data, prediction_path, logistic=False):\n", "    \"\"\"Convenience function to train, test, and show metrics of interest\n", "    Args:\n", "        train_params (str): vw training parameters\n", "        test_params (str): vw testing parameters\n", "        test_data (pd.dataFrame): test data\n", "        prediction_path (str): path to vw prediction output\n", "        logistic (bool): flag to convert label to logistic value\n", "    Returns:\n", "        (dict): metrics and timing information\n", "    \"\"\"\n", "\n", "    # train model\n", "    train_start = process_time()\n", "    run(train_params.split(' '), check=True)\n", "    train_stop = process_time()\n", "    \n", "    # test model\n", "    test_start = process_time()\n", "    run(test_params.split(' '), check=True)\n", "    test_stop = process_time()\n", "    \n", "    # read in predictions\n", "    pred_df = pd.read_csv(prediction_path, delim_whitespace=True, names=['prediction'], index_col=1).join(test_data)\n", "    \n", "    test_df = test_data.copy()\n", "    if logistic:\n", "        # make the true label binary so that the metrics are captured correctly\n", "        test_df['rating'] = test['rating'].apply(lambda x: 1 if x >= 3 else -1)\n", "    else:\n", "        # ensure results are integers in correct range\n", "        pred_df['prediction'] = pred_df['prediction'].apply(lambda x: int(max(1, min(5, round(x)))))\n", "\n", "    # calculate metrics\n", "    result = dict()\n", "    result['RMSE'] = rmse(test_df, pred_df)\n", "    result['MAE'] = mae(test_df, pred_df)\n", "    result['R2'] = rsquared(test_df, pred_df)\n", "    result['Explained Variance'] = exp_var(test_df, pred_df)\n", "    result['Train Time (ms)'] = (train_stop - train_start) * 1000\n", "    result['Test Time (ms)'] = (test_stop - test_start) * 1000\n", "    \n", "    return result"]}, {"block": 7, "type": "code", "linesLength": 9, "startIndex": 101, "lines": ["# create temp directory to maintain data files\n", "tmpdir = TemporaryDirectory()\n", "\n", "model_path = os.path.join(tmpdir.name, 'vw.model')\n", "train_path = os.path.join(tmpdir.name, 'train.dat')\n", "test_path = os.path.join(tmpdir.name, 'test.dat')\n", "train_logistic_path = os.path.join(tmpdir.name, 'train_logistic.dat')\n", "test_logistic_path = os.path.join(tmpdir.name, 'test_logistic.dat')\n", "prediction_path = os.path.join(tmpdir.name, 'prediction.dat')"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 110, "lines": ["<h3>Load & Transform Data</h3>"]}, {"block": 9, "type": "code", "linesLength": 13, "startIndex": 111, "lines": ["# load movielens data (use the 1M dataset)\n", "df = load_pandas_df('1m')\n", "\n", "# split data to train and test sets, default values take 75% of each users ratings as train, and 25% as test\n", "train, test = python_stratified_split(df)\n", "\n", "# save train and test data in vw format\n", "to_vw(df=train, output=train_path)\n", "to_vw(df=test, output=test_path)\n", "\n", "# save data for logistic regression (requires adjusting the label)\n", "to_vw(df=train, output=train_logistic_path, logistic=True)\n", "to_vw(df=test, output=test_logistic_path, logistic=True)"]}, {"block": 10, "type": "markdown", "linesLength": 15, "startIndex": 124, "lines": ["<h3>Regression Based Recommendations</h3>\n", "\n", "When considering different approaches for solving a problem with machine learning it is helpful to generate a baseline approach to understand how more complex solutions perform across dimensions of performance, time, and resource (memory or cpu) usage.\n", "\n", "Regression based approaches are some of the simplest and fastest baselines to consider for many ML problems.\n", "\n", "<h4> Linear Regression</h4>\n", "\n", "As the data provides a numerical rating between 1-5, fitting those values with a linear regression model is easy first step. This model is trained on examples of ratings as the target variable and corresponding user ids and movie ids as independent features.\n", "\n", "By passing each user-item rating in as an example the model will begin to learn weights based on average ratings for each user as well as average ratings per item.\n", "\n", "VW uses linear regression by default, so no extra command line options are needed beyond specifying where to locate the model and the data.\n", "\n", "This however can generate predicted ratings which are no longer integers, so some additional adjustments should be made at prediction time to convert them back to the integer scale of 1 through 5 if necessary. Here, this is done in the evaluate function."]}, {"block": 11, "type": "code", "linesLength": 10, "startIndex": 139, "lines": ["train_params = 'vw -f {model} -d {data}'.format(model=model_path, data=train_path)\n", "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n", "\n", "result = run_vw(train_params=train_params, \n", "                test_params=test_params, \n", "                test_data=test, \n", "                prediction_path=prediction_path)\n", "\n", "comparison = pd.DataFrame(result, index=['Linear Regression'])\n", "comparison"]}, {"block": 12, "type": "markdown", "linesLength": 7, "startIndex": 149, "lines": ["<h4> Multinomial Logistic Regression</h4>\n", "\n", "A similar alternative is to leverage multinomial classification, which treats each rating value as a distinct class. \n", "\n", "This avoids any non integer results, but also reduces the training data for each class which could lead to poorer performance if the counts of different rating levels are skewed.\n", "\n", "Basic multiclass logistic regression can be accomplished using the One Against All approach specified by the '--oaa N' option, where N is the number of classes and proving the logistic option for the loss function to be used."]}, {"block": 13, "type": "code", "linesLength": 10, "startIndex": 156, "lines": ["train_params = 'vw --loss_function logistic --oaa 5 -f {model} -d {data}'.format(model=model_path, data=train_path)\n", "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n", "\n", "result = run_vw(train_params=train_params,\n", "                test_params=test_params,\n", "                test_data=test,\n", "                prediction_path=prediction_path)\n", "\n", "comparison = comparison.append(pd.DataFrame(result, index=['Multinomial Regression']))\n", "comparison"]}, {"block": 14, "type": "markdown", "linesLength": 5, "startIndex": 166, "lines": ["<h4>Logistic Regression</h4>\n", "\n", "Additionally, one might simply be interested in whether the user likes or dislikes an item and we can adjust the input data to represent a binary outcome, where ratings in (1,3] are dislikes (negative results) and (3,5] are likes (positive results).\n", "\n", "This framing allows for a simple logistic regression model to be applied. To perform logistic regression the loss_function parameter is changed to 'logistic' and the target label is switched to [0, 1]. Also, be sure to set '--link logistic' during prediction to convert the logit output back to a probability value."]}, {"block": 15, "type": "code", "linesLength": 11, "startIndex": 171, "lines": ["train_params = 'vw --loss_function logistic -f {model} -d {data}'.format(model=model_path, data=train_logistic_path)\n", "test_params = 'vw --link logistic -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_logistic_path, pred=prediction_path)\n", "\n", "result = run_vw(train_params=train_params,\n", "                test_params=test_params,\n", "                test_data=test,\n", "                prediction_path=prediction_path,\n", "                logistic=True)\n", "\n", "comparison = comparison.append(pd.DataFrame(result, index=['Logistic Regression']))\n", "comparison"]}, {"block": 16, "type": "markdown", "linesLength": 7, "startIndex": 182, "lines": ["<h4>Linear Regression with Interaction Features</h4>\n", "\n", "So far we have treated the user features and item features independently, but taking into account interactions between features can provide a mechanism to learn more fine grained preferences of the users.\n", "\n", "To generate interaction features use the quadratic command line argument and specify the namespaces that should be combined: '-q ui' combines the user and item namespaces based on the first letter of each.\n", "\n", "When generating interaction terms one thing to consider is the [hash space](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Feature-Hashing-and-Extraction) used for the features. It can be beneficial to increase the size of the space to reduce unwanted collisions."]}, {"block": 17, "type": "code", "linesLength": 10, "startIndex": 189, "lines": ["train_params = 'vw -b 24 -q ui -f {model} -d {data}'.format(model=model_path, data=train_path)\n", "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n", "\n", "result = run_vw(train_params=train_params,\n", "                test_params=test_params,\n", "                test_data=test,\n", "                prediction_path=prediction_path)\n", "\n", "comparison = comparison.append(pd.DataFrame(result, index=['Linear Regression w/ Interaction']))\n", "comparison"]}, {"block": 18, "type": "markdown", "linesLength": 9, "startIndex": 199, "lines": ["<h3>Matrix Factorization Based Recommendations</h3>\n", "\n", "All of the above approaches train a regression model, but VW also supports matrix factorization with two different approaches.\n", "\n", "<h4>Singular Value Decomposition Based Matrix Factorization</h4>\n", "\n", "The first approach is called using the '--rank' command line argument and performs matrix factorization based on Singular Value Decomposition (SVD).\n", "\n", "See the [Matrix Factorization Example](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Matrix-factorization-example) for more detail."]}, {"block": 19, "type": "code", "linesLength": 10, "startIndex": 208, "lines": ["train_params = 'vw --rank 5 -q ui -f {model} -d {data}'.format(model=model_path, data=train_path)\n", "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n", "\n", "result = run_vw(train_params=train_params,\n", "                test_params=test_params,\n", "                test_data=test,\n", "                prediction_path=prediction_path)\n", "\n", "comparison = comparison.append(pd.DataFrame(result, index=['Matrix Factorization (Rank)']))\n", "comparison"]}, {"block": 20, "type": "markdown", "linesLength": 7, "startIndex": 218, "lines": ["<h4>Factorization Machine Based Matrix Factorization</h4>\n", "\n", "An alternative approach based on [Rendel's factorization machines](https://cseweb.ucsd.edu/classes/fa17/cse291-b/reading/Rendle2010FM.pdf) is called using '--lrq' (low rank quadratic). More LRQ details in this [demo](https://github.com/VowpalWabbit/vowpal_wabbit/tree/master/demo/movielens).\n", "\n", "This learns two lower rank matrices which are multiplied to generate an approximation of the user-item rating matrix. Compressing the matrix in this way leads to learning generalizable factors which avoids some of the limitations of using regression models with extremely sparse interaction features. This can lead to better convergence and smaller on-disk models.\n", "\n", "An additional term to improve performance is --lrqdropout which will dropout columns during training. This however tends to increase the optimal rank size. Other parameters such as L2 regularization can help avoid overfitting."]}, {"block": 21, "type": "code", "linesLength": 10, "startIndex": 225, "lines": ["train_params = 'vw --lrq ui7 --lrqdropout -f {model} -d {data}'.format(model=model_path, data=train_path)\n", "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=test_path, pred=prediction_path)\n", "\n", "result = run_vw(train_params=train_params,\n", "                test_params=test_params,\n", "                test_data=test,\n", "                prediction_path=prediction_path)\n", "\n", "comparison = comparison.append(pd.DataFrame(result, index=['Matrix Factorization (LRQ)']))\n", "comparison"]}, {"block": 22, "type": "markdown", "linesLength": 1, "startIndex": 235, "lines": ["<h3>Scoring</h3>"]}, {"block": 23, "type": "markdown", "linesLength": 1, "startIndex": 236, "lines": ["After training a model with any of the above approaches, the model can be used to score potential user-pairs in offline batch mode, or in a real-time scoring mode. The example below shows how to leverage the utilities in the reco_utils directory to  generate Top-K recommendations from offline scored output."]}, {"block": 24, "type": "code", "linesLength": 12, "startIndex": 237, "lines": ["# store all data\n", "data_path = os.path.join(tmpdir.name, 'all.dat')\n", "to_vw(df=df, output=data_path)\n", "\n", "# predict on the full set of users\n", "train_params = 'vw --lrq ui7 --lrqdropout -f {model} -d {data}'.format(model=model_path, data=train_path)\n", "test_params = 'vw -i {model} -d {data} -t -p {pred}'.format(model=model_path, data=data_path, pred=prediction_path)\n", "\n", "result = run_vw(train_params=train_params,\n", "                test_params=test_params,\n", "                test_data=df,\n", "                prediction_path=prediction_path)"]}, {"block": 25, "type": "code", "linesLength": 6, "startIndex": 249, "lines": ["# load predictions and filter to test set\n", "test_users = [1, 2, 3]\n", "pred_data = pd.read_csv(prediction_path, delim_whitespace=True, names=['prediction'], index_col=1).join(df)\n", "test_user_data = pred_data[pred_data['userID'].isin(test_users)]\n", "\n", "get_top_k_items(test_user_data, col_rating='prediction', k=5)"]}, {"block": 26, "type": "markdown", "linesLength": 1, "startIndex": 255, "lines": ["<h3>Cleanup</h3>"]}, {"block": 27, "type": "code", "linesLength": 1, "startIndex": 256, "lines": ["tmpdir.cleanup()"]}]