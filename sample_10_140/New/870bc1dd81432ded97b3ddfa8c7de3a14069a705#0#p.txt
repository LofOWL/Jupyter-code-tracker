[{"block": 0, "type": "code", "linesLength": 9, "startIndex": 0, "lines": ["import azureml.core\n", "from azureml.core import Workspace, Experiment\n", "from azureml.core.compute import ComputeTarget, AmlCompute\n", "from azureml.core.compute_target import ComputeTargetException\n", "from azureml.train.dnn import TensorFlow\n", "from azureml.train.hyperdrive import *\n", "from azureml.widgets import RunDetails\n", "\n", "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"]}, {"block": 1, "type": "markdown", "linesLength": 1, "startIndex": 9, "lines": ["Connect to a workspace from `.\\aml_config\\config.json` file"]}, {"block": 2, "type": "code", "linesLength": 3, "startIndex": 10, "lines": ["# Connect to a workspace\n", "ws = Workspace.from_config()\n", "print(\"Workspace name: \", ws.name)"]}, {"block": 3, "type": "code", "linesLength": 1, "startIndex": 13, "lines": ["ws.get_default_datastore().as_mount()"]}, {"block": 4, "type": "markdown", "linesLength": 1, "startIndex": 14, "lines": ["Create a remote compute target"]}, {"block": 5, "type": "code", "linesLength": 23, "startIndex": 15, "lines": ["CLUSTER_NAME = 'gpu-cluster'\n", "\n", "try:\n", "    compute_target = ComputeTarget(workspace=ws, name=CLUSTER_NAME)\n", "    print('Found existing compute target')\n", "except ComputeTargetException:\n", "    print('Creating a new compute target...')\n", "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', # STANDARD_NC24s_v3\n", "                                                           min_nodes=1,\n", "                                                           max_nodes=4)\n", "    # create the cluster\n", "    compute_target = ComputeTarget.create(ws, CLUSTER_NAME, compute_config)\n", "\n", "    # can poll for a minimum number of nodes and for a specific timeout. \n", "    # if no min node count is provided it uses the scale settings for the cluster\n", "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n", "\n", "# Use the 'status' property to get a detailed status for the current cluster. \n", "print(compute_target.status.serialize())\n", "\n", "compute_targets = ws.compute_targets\n", "for name, ct in compute_targets.items():\n", "    print(name, ct.type, ct.provisioning_state)"]}, {"block": 6, "type": "markdown", "linesLength": 1, "startIndex": 38, "lines": ["Prepare dataset"]}, {"block": 7, "type": "code", "linesLength": 5, "startIndex": 39, "lines": ["DATA_PATH = 'movielens_100k'\n", "\n", "# TODO Download dataset and upload to datastore\n", "# ds = ws.get_default_datastore()\n", "# ds.upload(src_dir='./'+DATA_PATH, target_path=DATA_PATH, overwrite=True, show_progress=True)"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 44, "lines": ["Prepare training script"]}, {"block": 9, "type": "code", "linesLength": 2, "startIndex": 45, "lines": ["DEEP_MODEL_TRAIN_SCRIPT = 'deep_model_train.py'\n", "SCRIPT_FOLDER = './model_train'\n"]}, {"block": 10, "type": "markdown", "linesLength": 1, "startIndex": 47, "lines": ["Set (or search) hyperparameter"]}, {"block": 11, "type": "code", "linesLength": 48, "startIndex": 48, "lines": ["HYPERPARAMETER_TUNING = True\n", "\n", "if HYPERPARAMETER_TUNING:\n", "    # vs. Estimator\n", "    est = TensorFlow(source_directory=SCRIPT_FOLDER,\n", "                     script_params={'--data-folder': ws.get_default_datastore().as_mount()},\n", "                     compute_target=compute_target,\n", "                     entry_script=DEEP_MODEL_TRAIN_SCRIPT, \n", "                     use_gpu=True)\n", "    \n", "    # vs. GridParameterSampling\n", "    ps = RandomParameterSampling(\n", "        {\n", "    #         '--batch-size': choice(25, 50, 100),\n", "            '--first-layer-neurons': choice(10, 50, 200, 300, 500),\n", "            '--second-layer-neurons': choice(10, 50, 200, 500),\n", "            '--learning-rate': loguniform(-6, -1)\n", "        }\n", "    )\n", "\n", "    # Early termnination policy\n", "    policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)\n", "\n", "    hdrc = HyperDriveRunConfig(estimator=est, \n", "                               hyperparameter_sampling=ps, \n", "                               policy=policy, \n", "                               primary_metric_name='validation_acc', \n", "                               primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n", "                               max_total_runs=8,\n", "                               max_concurrent_runs=4)\n", "    run = exp.submit(config=htc)\n", "else:\n", "    est = TensorFlow(source_directory=SCRIPT_FOLDER,\n", "                     script_params={\n", "                         '--data-folder': ws.get_default_datastore().as_mount(),\n", "                         '--batch-size': 50,\n", "                         '--first-layer-neurons': 300,\n", "                         '--second-layer-neurons': 100,\n", "                         '--learning-rate': 0.01\n", "                     },\n", "                     compute_target=compute_target,\n", "                     entry_script=DEEP_MODEL_TRAIN_SCRIPT, \n", "                     use_gpu=True)\n", "    run = exp.submit(est)\n", "    \n", "    \n", "RunDetails(run).show()\n", "run.wait_for_completion(show_output=True)\n"]}, {"block": 12, "type": "code", "linesLength": 4, "startIndex": 96, "lines": ["best_run = run.get_best_run_by_primary_metric()\n", "print(best_run.get_file_names())\n", "model = best_run.register_model(model_name='tf-dnn', model_path='outputs/model')\n", "\n"]}, {"block": 13, "type": "code", "linesLength": 25, "startIndex": 100, "lines": ["# TODO Checks\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "# Create AmlCompute cluster\n", "\n", "\n", "# Create an experiment to track the runs in the workspace\n", "deep_model_exp = Experiment(workspace=ws, name='deep-model')\n", "\n", "# Start a run\n", "deep_model_run = exp.start_logging()\n", "\n", "# Log a number\n", "deep_model_run.log(\"my_number\", 42)\n", "deep_model_run.log_list(\"my_list\", [1, 2, 3])\n", "deep_model_run.complete()\n", "\n", "print(deep_model_run.get_portal_url())\n", "\n"]}, {"block": 14, "type": "code", "linesLength": 14, "startIndex": 125, "lines": ["from azureml.train.hyperdrive import *\n", "import math\n", "\n", "param_sampling = RandomParameterSampling( {\n", "         'learning_rate': loguniform(math.log(1e-4), math.log(1e-6)),\n", "})\n", "\n", "hyperdrive_run_config = HyperDriveRunConfig(\n", "     estimator=estimator,\n", "     hyperparameter_sampling=param_sampling,\n", "     primary_metric_name='f1',\n", "     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n", "     max_total_runs=16,\n", "     max_concurrent_runs=4)"]}, {"block": 15, "type": "code", "linesLength": 2, "startIndex": 139, "lines": ["# Clean-up resources\n", "ws.delete(delete_dependent_resources=True)\n"]}, {"block": 16, "type": "markdown", "linesLength": 4, "startIndex": 141, "lines": ["### References\n", "\n", "* [Fine-tune natural language processing models using Azure Machine Learning service](https://azure.microsoft.com/en-us/blog/fine-tune-natural-language-processing-models-using-azure-machine-learning-service/)\n", "* [Training, hyperparameter tune, and deploy with TensorFlow](https://github.com/Azure/MachineLearningNotebooks/blob/master/how-to-use-azureml/training-with-deep-learning/train-hyperparameter-tune-deploy-with-tensorflow/train-hyperparameter-tune-deploy-with-tensorflow.ipynb)\n"]}, {"block": 17, "type": "code", "linesLength": 0, "startIndex": 145, "lines": []}]