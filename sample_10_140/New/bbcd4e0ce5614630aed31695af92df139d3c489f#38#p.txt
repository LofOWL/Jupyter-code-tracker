[{"block": 0, "type": "code", "linesLength": 3, "startIndex": 0, "lines": ["%matplotlib inline\n", "%reload_ext autoreload\n", "%autoreload 2"]}, {"block": 1, "type": "markdown", "linesLength": 1, "startIndex": 3, "lines": ["## Style transfer"]}, {"block": 2, "type": "code", "linesLength": 6, "startIndex": 4, "lines": ["from fastai.conv_learner import *\n", "from pathlib import Path\n", "from scipy import ndimage\n", "torch.cuda.set_device(3)\n", "\n", "torch.backends.cudnn.benchmark=True"]}, {"block": 3, "type": "code", "linesLength": 3, "startIndex": 10, "lines": ["# wget http://files.fast.ai/data/imagenet-sample-train.tar.gz\n", "PATH = Path('data/imagenet')\n", "PATH_TRN = PATH/'train'"]}, {"block": 4, "type": "code", "linesLength": 2, "startIndex": 13, "lines": ["m_vgg = to_gpu(vgg16(True)).eval()\n", "set_trainable(m_vgg, False)"]}, {"block": 5, "type": "code", "linesLength": 3, "startIndex": 15, "lines": ["img_fn = PATH_TRN/'n01558993'/'n01558993_9684.JPEG'\n", "img = open_image(img_fn)\n", "plt.imshow(img);"]}, {"block": 6, "type": "code", "linesLength": 1, "startIndex": 18, "lines": ["sz=288"]}, {"block": 7, "type": "code", "linesLength": 3, "startIndex": 19, "lines": ["trn_tfms,val_tfms = tfms_from_model(vgg16, sz)\n", "img_tfm = val_tfms(img)\n", "img_tfm.shape"]}, {"block": 8, "type": "code", "linesLength": 2, "startIndex": 22, "lines": ["opt_img = np.random.uniform(0, 1, size=img.shape).astype(np.float32)\n", "plt.imshow(opt_img);"]}, {"block": 9, "type": "code", "linesLength": 1, "startIndex": 24, "lines": ["opt_img = scipy.ndimage.filters.median_filter(opt_img, [8,8,1])"]}, {"block": 10, "type": "code", "linesLength": 1, "startIndex": 25, "lines": ["plt.imshow(opt_img);"]}, {"block": 11, "type": "code", "linesLength": 3, "startIndex": 26, "lines": ["opt_img = val_tfms(opt_img)/2\n", "opt_img_v = V(opt_img[None], requires_grad=True)\n", "opt_img_v.shape"]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 29, "lines": ["m_vgg = nn.Sequential(*children(m_vgg)[:37])"]}, {"block": 13, "type": "code", "linesLength": 3, "startIndex": 30, "lines": ["targ_t = m_vgg(VV(img_tfm[None]))\n", "targ_v = V(targ_t)\n", "targ_t.shape"]}, {"block": 14, "type": "code", "linesLength": 3, "startIndex": 33, "lines": ["max_iter = 1000\n", "show_iter = 100\n", "optimizer = optim.LBFGS([opt_img_v], lr=0.5)"]}, {"block": 15, "type": "code", "linesLength": 1, "startIndex": 36, "lines": ["def actn_loss(x): return F.mse_loss(m_vgg(x), targ_v)*1000"]}, {"block": 16, "type": "code", "linesLength": 8, "startIndex": 37, "lines": ["def step(loss_fn):\n", "    global n_iter\n", "    optimizer.zero_grad()\n", "    loss = loss_fn(opt_img_v)\n", "    loss.backward()\n", "    n_iter+=1\n", "    if n_iter%show_iter==0: print(f'Iteration: {n_iter}, loss: {loss.data[0]}')\n", "    return loss"]}, {"block": 17, "type": "code", "linesLength": 2, "startIndex": 45, "lines": ["n_iter=0\n", "while n_iter <= max_iter: optimizer.step(partial(step,actn_loss))"]}, {"block": 18, "type": "code", "linesLength": 3, "startIndex": 47, "lines": ["x = val_tfms.denorm(np.rollaxis(to_np(opt_img_v.data),1,4))[0]\n", "plt.figure(figsize=(7,7))\n", "plt.imshow(x);"]}, {"block": 19, "type": "markdown", "linesLength": 1, "startIndex": 50, "lines": ["## forward hook"]}, {"block": 20, "type": "code", "linesLength": 5, "startIndex": 51, "lines": ["class SaveFeatures():\n", "    features=None\n", "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n", "    def hook_fn(self, module, input, output): self.features = output\n", "    def close(self): self.hook.remove()"]}, {"block": 21, "type": "code", "linesLength": 2, "startIndex": 56, "lines": ["m_vgg = to_gpu(vgg16(True)).eval()\n", "set_trainable(m_vgg, False)"]}, {"block": 22, "type": "code", "linesLength": 3, "startIndex": 58, "lines": ["block_ends = [i-1 for i,o in enumerate(children(m_vgg))\n", "              if isinstance(o,nn.MaxPool2d)]\n", "block_ends"]}, {"block": 23, "type": "code", "linesLength": 1, "startIndex": 61, "lines": ["sf = SaveFeatures(children(m_vgg)[block_ends[3]])"]}, {"block": 24, "type": "code", "linesLength": 5, "startIndex": 62, "lines": ["def get_opt():\n", "    opt_img = np.random.uniform(0, 1, size=img.shape).astype(np.float32)\n", "    opt_img = scipy.ndimage.filters.median_filter(opt_img, [8,8,1])\n", "    opt_img_v = V(val_tfms(opt_img/2)[None], requires_grad=True)\n", "    return opt_img_v, optim.LBFGS([opt_img_v])"]}, {"block": 25, "type": "code", "linesLength": 1, "startIndex": 67, "lines": ["opt_img_v, optimizer = get_opt()"]}, {"block": 26, "type": "code", "linesLength": 3, "startIndex": 68, "lines": ["m_vgg(VV(img_tfm[None]))\n", "targ_v = V(sf.features.clone())\n", "targ_v.shape"]}, {"block": 27, "type": "code", "linesLength": 4, "startIndex": 71, "lines": ["def actn_loss2(x):\n", "    m_vgg(x)\n", "    out = V(sf.features)\n", "    return F.mse_loss(out, targ_v)*1000"]}, {"block": 28, "type": "code", "linesLength": 2, "startIndex": 75, "lines": ["n_iter=0\n", "while n_iter <= max_iter: optimizer.step(partial(step,actn_loss2))"]}, {"block": 29, "type": "code", "linesLength": 3, "startIndex": 77, "lines": ["x = val_tfms.denorm(np.rollaxis(to_np(opt_img_v.data),1,4))[0]\n", "plt.figure(figsize=(7,7))\n", "plt.imshow(x);"]}, {"block": 30, "type": "code", "linesLength": 1, "startIndex": 80, "lines": ["sf.close()"]}, {"block": 31, "type": "markdown", "linesLength": 1, "startIndex": 81, "lines": ["## Style match"]}, {"block": 32, "type": "code", "linesLength": 2, "startIndex": 82, "lines": ["# wget https://raw.githubusercontent.com/jeffxtang/fast-style-transfer/master/images/starry_night.jpg\n", "style_fn = PATH/'style'/'starry_night.jpg'"]}, {"block": 33, "type": "code", "linesLength": 2, "startIndex": 84, "lines": ["style_img = open_image(style_fn)\n", "style_img.shape, img.shape"]}, {"block": 34, "type": "code", "linesLength": 1, "startIndex": 86, "lines": ["plt.imshow(style_img);"]}, {"block": 35, "type": "code", "linesLength": 6, "startIndex": 87, "lines": ["def scale_match(src, targ):\n", "    h,w,_ = src.shape\n", "    sh,sw,_ = targ.shape\n", "    rat = max(h/sh,w/sw); rat\n", "    res = cv2.resize(targ, (int(sw*rat), int(sh*rat)))\n", "    return res[:h,:w]"]}, {"block": 36, "type": "code", "linesLength": 1, "startIndex": 93, "lines": ["style = scale_match(img, style_img)"]}, {"block": 37, "type": "code", "linesLength": 2, "startIndex": 94, "lines": ["plt.imshow(style)\n", "style.shape, img.shape"]}, {"block": 38, "type": "code", "linesLength": 1, "startIndex": 96, "lines": ["opt_img_v, optimizer = get_opt()"]}, {"block": 39, "type": "code", "linesLength": 1, "startIndex": 97, "lines": ["sfs = [SaveFeatures(children(m_vgg)[idx]) for idx in block_ends]"]}, {"block": 40, "type": "code", "linesLength": 3, "startIndex": 98, "lines": ["m_vgg(VV(img_tfm[None]))\n", "targ_vs = [V(o.features.clone()) for o in sfs]\n", "[o.shape for o in targ_vs]"]}, {"block": 41, "type": "code", "linesLength": 1, "startIndex": 101, "lines": ["style_tfm = val_tfms(style_img)"]}, {"block": 42, "type": "code", "linesLength": 3, "startIndex": 102, "lines": ["m_vgg(VV(style_tfm[None]))\n", "targ_styles = [V(o.features.clone()) for o in sfs]\n", "[o.shape for o in targ_styles]"]}, {"block": 43, "type": "code", "linesLength": 6, "startIndex": 105, "lines": ["def gram(input):\n", "        b,c,h,w = input.size()\n", "        x = input.view(b*c, -1)\n", "        return torch.mm(x, x.t())/input.numel()*1e6\n", "\n", "def gram_mse_loss(input, target): return F.mse_loss(gram(input), gram(target))"]}, {"block": 44, "type": "code", "linesLength": 5, "startIndex": 111, "lines": ["def style_loss(x):\n", "    m_vgg(opt_img_v)\n", "    outs = [V(o.features) for o in sfs]\n", "    losses = [gram_mse_loss(o, s) for o,s in zip(outs, targ_styles)]\n", "    return sum(losses)"]}, {"block": 45, "type": "code", "linesLength": 2, "startIndex": 116, "lines": ["n_iter=0\n", "while n_iter <= max_iter: optimizer.step(partial(step,style_loss))"]}, {"block": 46, "type": "code", "linesLength": 3, "startIndex": 118, "lines": ["x = val_tfms.denorm(np.rollaxis(to_np(opt_img_v.data),1,4))[0]\n", "plt.figure(figsize=(7,7))\n", "plt.imshow(x);"]}, {"block": 47, "type": "code", "linesLength": 1, "startIndex": 121, "lines": ["for sf in sfs: sf.close()"]}, {"block": 48, "type": "markdown", "linesLength": 1, "startIndex": 122, "lines": ["## Style transfer"]}, {"block": 49, "type": "code", "linesLength": 1, "startIndex": 123, "lines": ["opt_img_v, optimizer = get_opt()"]}, {"block": 50, "type": "code", "linesLength": 1, "startIndex": 124, "lines": ["sfs = [SaveFeatures(children(m_vgg)[idx]) for idx in block_ends]"]}, {"block": 51, "type": "code", "linesLength": 7, "startIndex": 125, "lines": ["def comb_loss(x):\n", "    m_vgg(opt_img_v)\n", "    outs = [V(o.features) for o in sfs]\n", "    losses = [gram_mse_loss(o, s) for o,s in zip(outs, targ_styles)]\n", "    cnt_loss   = F.mse_loss(outs[3], targ_vs[3])*1000000\n", "    style_loss = sum(losses)\n", "    return cnt_loss + style_loss"]}, {"block": 52, "type": "code", "linesLength": 2, "startIndex": 132, "lines": ["n_iter=0\n", "while n_iter <= max_iter: optimizer.step(partial(step,comb_loss))"]}, {"block": 53, "type": "code", "linesLength": 4, "startIndex": 134, "lines": ["x = val_tfms.denorm(np.rollaxis(to_np(opt_img_v.data),1,4))[0]\n", "plt.figure(figsize=(9,9))\n", "plt.imshow(x, interpolation='lanczos')\n", "plt.axis('off');"]}, {"block": 54, "type": "code", "linesLength": 1, "startIndex": 138, "lines": ["for sf in sfs: sf.close()"]}, {"block": 55, "type": "code", "linesLength": 0, "startIndex": 139, "lines": []}]