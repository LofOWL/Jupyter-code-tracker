[{"block": 0, "type": "markdown", "linesLength": 4, "startIndex": 0, "lines": ["# Surprise Singular Value Decomposition (SVD)\n", "\n", "\n", "This notebook serves both as an introduction to the [Surprise](http://surpriselib.com/) library, and also introduces the 'SVD' algorithm very similar to ALS presented in the ALS deep dive notebook. This algorithm was heavily used during the Netflix Prize competition by the winning BellKor team."]}, {"block": 1, "type": "markdown", "linesLength": 1, "startIndex": 4, "lines": ["## 0 Global Settings and Imports"]}, {"block": 2, "type": "code", "linesLength": 11, "startIndex": 5, "lines": ["import sys\n", "sys.path.append(\"../../\")\n", "import surprise\n", "import pandas as pd\n", "from reco_utils.dataset.url_utils import maybe_download\n", "from reco_utils.dataset.python_splitters import python_random_split\n", "from reco_utils.evaluation.python_evaluation import rmse, mae, rsquared, exp_var\n", "from reco_utils.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n", "\n", "print(\"System version: {}\".format(sys.version))\n", "print(\"Surprise version: {}\".format(surprise.__version__))"]}, {"block": 3, "type": "markdown", "linesLength": 35, "startIndex": 16, "lines": ["## 1 Matrix factorization algorithm\n", "\n", "The SVD model algorithm is very similar to the ALS algorithm presented in the ALS deep dive notebook. The two differences between the two approaches are:\n", "\n", "- SVD additionally models the user and item biases (also called baselines in the litterature) from users and items.\n", "- The optimization technique in ALS is Alternating Least Squares (hence the name), while SVD uses stochastic gradient descent.\n", "\n", "### 1.1 The SVD model\n", "\n", "In ALS, the ratings are modeled as follows:\n", "\n", "$$\\hat r_{u,i} = q_{i}^{T}p_{u}$$\n", "\n", "SVD introduces two new scalar variables: the user biases $b_u$ and the item biases $b_i$. The user biases are supposed to capture the tendency of some users to rate items higher (or lower) than the average. The same goes for items: some items are usually rated higher than some others. The model is SVD is then as follows:\n", "\n", "$$\\hat r_{u,i} = \\mu + b_u + b_i + q_{i}^{T}p_{u}$$\n", "\n", "Where $\\mu$ is the global average of all the ratings in the dataset. The regularised optimization problem naturally becomes:\n", "\n", "$$ \\sum(r_{u,i} - (\\mu + b_u + b_i + q_{i}^{T}p_{u}))^2 +     \\lambda(b_i^2 + b_u^2 + ||q_i||^2 + ||p_u||^2)$$\n", "\n", "where $\\lambda$ is a the regularization parameter.\n", "\n", "\n", "### 1.2 Stochastic Gradient Descent\n", "\n", "Stochastic Gradient Descent (SGD) is a very common algorithm for optimization where the parameters (here the biases and the factor vectors) are iteratively incremented with the negative gradients w.r.t the optimization function. The algorithm essentially performs the following steps for a given number of iteration:\n", "\n", "\n", "$$b_u \\leftarrow b_u + \\gamma (e_{ui} - \\lambda b_u)$$\n", "$$b_i \\leftarrow b_i + \\gamma (e_{ui} - \\lambda b_i)$$  \n", "$$p_u \\leftarrow p_u + \\gamma (e_{ui} \\cdot q_i - \\lambda p_u)$$\n", "$$q_i \\leftarrow q_i + \\gamma (e_{ui} \\cdot p_u - \\lambda q_i)$$\n", "\n", "where $\\gamma$ is the learning rate and $e_{ui} =  r_{ui} - \\hat r_{u,i} = r_{u,i} - (\\mu + b_u + b_i + q_{i}^{T}p_{u})$ is the error made by the model for the pair $(u, i)$."]}, {"block": 4, "type": "markdown", "linesLength": 5, "startIndex": 51, "lines": ["# 1 Load Data\n", "\n", "We will use the movielens dataset, which is composed of integer ratings from 1 to 5. \n", "\n", "Surprise supports dataframes as long as they have three colums reprensenting the user ids, item ids, and the ratings (in this order)."]}, {"block": 5, "type": "code", "linesLength": 4, "startIndex": 56, "lines": ["filepath = maybe_download(\"http://files.grouplens.org/datasets/movielens/ml-100k/u.data\", \"ml-100k.data\")\n", "data = pd.read_csv(filepath, sep=\"\\t\", names=[\"UserId\", \"MovieId\", \"Rating\", \"Timestamp\"])\n", "data = data[[\"UserId\", \"MovieId\", \"Rating\"]]\n", "data.head()"]}, {"block": 6, "type": "markdown", "linesLength": 5, "startIndex": 60, "lines": ["# 2 Train the SVD Model\n", "\n", "Note that Surprise has a lot of built-in support for [cross-validation](https://surprise.readthedocs.io/en/stable/getting_started.html#use-cross-validation-iterators) or also [grid search](https://surprise.readthedocs.io/en/stable/getting_started.html#tune-algorithm-parameters-with-gridsearchcv) inspired scikit-learn, but we will here use the provided tools instead.\n", "\n", "We start by splitting our data into trainset and testset with the `python_random_split` function."]}, {"block": 7, "type": "code", "linesLength": 1, "startIndex": 65, "lines": ["train, test = python_random_split(data)"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 66, "lines": ["Surprise needs to build an internal model of the data. We here use the `load_from_df` method to build a `Dataset` object, and then indicate that we want to train on all the samples of this dataset by using the `build_full_trainset` method."]}, {"block": 9, "type": "code", "linesLength": 2, "startIndex": 67, "lines": ["train = surprise.Dataset.load_from_df(data, reader=surprise.Reader('ml-100k')).build_full_trainset()\n", "train"]}, {"block": 10, "type": "markdown", "linesLength": 1, "startIndex": 69, "lines": ["The [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD) has a lot of parameters but we will here use the defaults (only setting the RNG for reproducibility). To train the model, we simply need to call the `fit()` method."]}, {"block": 11, "type": "code", "linesLength": 2, "startIndex": 70, "lines": ["svd = surprise.SVD(random_state=0)\n", "svd.fit(train)"]}, {"block": 12, "type": "markdown", "linesLength": 1, "startIndex": 72, "lines": ["Now that our model is fitted, we can call `predict` to get some predictions. `predict` returns an internal object `Prediction` which can be easily converted back to a dataframe:"]}, {"block": 13, "type": "code", "linesLength": 7, "startIndex": 73, "lines": ["predictions = [svd.predict(row.UserId, row.MovieId, row.Rating)\n", "               for (_, row) in test.iterrows()]\n", "predictions = pd.DataFrame(predictions)\n", "predictions = predictions.rename(index=str, columns={'uid': 'userID', 'iid': 'itemID',\n", "                                                     'est': 'prediction'})\n", "predictions = predictions.drop(['details', 'r_ui'], axis='columns')\n", "predictions.head()"]}, {"block": 14, "type": "markdown", "linesLength": 7, "startIndex": 80, "lines": ["### 5. Evaluate how well SAR performs \n", "\n", "The SVD algorithm was specifically designed to predict ratings as close as possible to their actual values. In particular, it is designed to have a very low RMSE (Root Mean Squared Error), computed as:\n", "\n", "$$\\sqrt{\\frac{1}{N} (\\hat{r_{ui}} - r_{ui})^2}$$\n", "\n", "As we can see, the RMSE and MAE (Mean Absolute Error) are pretty low (i.e. good), indicating that on average predicted ratings are about 0.5 away from their actual values."]}, {"block": 15, "type": "code", "linesLength": 2, "startIndex": 87, "lines": ["test = test.rename(index=str, columns={'UserId': 'userID', 'MovieId': 'itemID', 'Rating': 'rating'})\n", "rmse(test, predictions), mae(test, predictions)"]}, {"block": 16, "type": "code", "linesLength": 0, "startIndex": 89, "lines": []}, {"block": 17, "type": "code", "linesLength": 11, "startIndex": 89, "lines": ["# map_at_k and so on require different column names it seems\n", "\n", "\n", "# predictions_df = predictions_df.rename(index=str, columns={'uid': 'UserId', 'iid': 'MovieId', 'est': 'prediction'})\n", "#predictions_df = predictions_df.drop(['details', 'r_ui'], axis='columns')\n", "\n", "#k = 10\n", "#eval_map = map_at_k(test, predictions_df, col_user=\"UserId\", col_item=\"MovieId\", \n", "#                    col_rating=\"Rating\", col_prediction=\"prediction\", \n", "#                    relevancy_method=\"top_k\", k=k)\n", "#eval_map"]}, {"block": 18, "type": "code", "linesLength": 0, "startIndex": 100, "lines": []}, {"block": 19, "type": "code", "linesLength": 0, "startIndex": 100, "lines": []}, {"block": 20, "type": "code", "linesLength": 0, "startIndex": 100, "lines": []}, {"block": 21, "type": "code", "linesLength": 0, "startIndex": 100, "lines": []}, {"block": 22, "type": "code", "linesLength": 0, "startIndex": 100, "lines": []}, {"block": 23, "type": "code", "linesLength": 0, "startIndex": 100, "lines": []}, {"block": 24, "type": "code", "linesLength": 0, "startIndex": 100, "lines": []}, {"block": 25, "type": "code", "linesLength": 0, "startIndex": 100, "lines": []}]