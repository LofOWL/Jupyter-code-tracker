[{"block": 0, "type": "markdown", "linesLength": 7, "startIndex": 0, "lines": ["##ThinkDSP\n", "\n", "This notebook contains a solution to an exercise in Chapter 5: Autocorrelation\n", "\n", "Copyright 2015 Allen Downey\n", "\n", "License: [Creative Commons Attribution 4.0 International](http://creativecommons.org/licenses/by/4.0/)"]}, {"block": 1, "type": "code", "linesLength": 15, "startIndex": 7, "lines": ["from __future__ import print_function, division\n", "\n", "import thinkdsp\n", "import thinkplot\n", "import thinkstats2\n", "\n", "import numpy as np\n", "\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "from IPython.html.widgets import interact, fixed\n", "from IPython.html import widgets\n", "\n", "%matplotlib inline"]}, {"block": 2, "type": "markdown", "linesLength": 5, "startIndex": 22, "lines": ["###The case of the missing fundamental\n", "\n", "This notebook investigates autocorrelation, pitch perception and a phenomenon called the \"missing fundamental\".\n", "\n", "I'll start with a recording of a saxophone."]}, {"block": 3, "type": "code", "linesLength": 3, "startIndex": 27, "lines": ["wave = thinkdsp.read_wave('100475__iluppai__saxophone-weep.wav')\n", "wave.normalize()\n", "wave.make_audio()"]}, {"block": 4, "type": "markdown", "linesLength": 1, "startIndex": 30, "lines": ["The spectrogram shows the harmonic structure over time."]}, {"block": 5, "type": "code", "linesLength": 3, "startIndex": 31, "lines": ["gram = wave.make_spectrogram(seg_length=1024)\n", "gram.plot(high=3000)\n", "thinkplot.config(xlabel='Time (s)', ylabel='Frequency (Hz)')"]}, {"block": 6, "type": "markdown", "linesLength": 1, "startIndex": 34, "lines": ["To see the harmonics more clearly, I'll take a segment near the 2 second mark and compute its spectrum."]}, {"block": 7, "type": "code", "linesLength": 4, "startIndex": 35, "lines": ["start = 2.0\n", "duration = 0.5\n", "segment = wave.segment(start=start, duration=duration)\n", "segment.make_audio()"]}, {"block": 8, "type": "code", "linesLength": 3, "startIndex": 39, "lines": ["spectrum = segment.make_spectrum()\n", "spectrum.plot(high=3000)\n", "thinkplot.config(xlabel='Frequency (Hz)', ylabel='Amplitude')"]}, {"block": 9, "type": "markdown", "linesLength": 1, "startIndex": 42, "lines": ["The peaks in the spectrum are at 1392, 928, and 464 Hz."]}, {"block": 10, "type": "code", "linesLength": 1, "startIndex": 43, "lines": ["spectrum.peaks()[:10]"]}, {"block": 11, "type": "markdown", "linesLength": 3, "startIndex": 44, "lines": ["The pitch we perceive is the fundamental, at 464 Hz, even though it is not the dominant frequency.\n", "\n", "For comparison, here's a triangle wave at 464 Hz."]}, {"block": 12, "type": "code", "linesLength": 1, "startIndex": 47, "lines": ["thinkdsp.TriangleSignal(freq=464).make_wave(duration=0.5).make_audio()"]}, {"block": 13, "type": "markdown", "linesLength": 1, "startIndex": 48, "lines": ["And here's the segment again."]}, {"block": 14, "type": "code", "linesLength": 1, "startIndex": 49, "lines": ["segment.make_audio()"]}, {"block": 15, "type": "markdown", "linesLength": 5, "startIndex": 50, "lines": ["They have the same perceived pitch.\n", "\n", "To understand why we perceive the fundamental frequency, even though it is not dominant, it helps to look at the autocorrelation function (ACF).\n", "\n", "The following function computes the ACF, selects the second half (which corresponds to positive lags) and normalizes the results:"]}, {"block": 16, "type": "code", "linesLength": 9, "startIndex": 55, "lines": ["def autocorr(segment):\n", "    corrs = np.correlate(segment.ys, segment.ys, mode='same')\n", "    N = len(corrs)\n", "    lengths = range(N, N//2, -1)\n", "\n", "    half = corrs[N//2:].copy()\n", "    half /= lengths\n", "    half /= half[0]\n", "    return half"]}, {"block": 17, "type": "markdown", "linesLength": 1, "startIndex": 64, "lines": ["And here's what the result:"]}, {"block": 18, "type": "code", "linesLength": 3, "startIndex": 65, "lines": ["corrs = autocorr(segment)\n", "thinkplot.plot(corrs[:200])\n", "thinkplot.config(xlabel='Lag', ylabel='Correlation', ylim=[-1.05, 1.05])"]}, {"block": 19, "type": "markdown", "linesLength": 3, "startIndex": 68, "lines": ["The first major peak is near lag 100.\n", "\n", "The following function finds the highest correlation in a given range of lags and returns the corresponding frequency."]}, {"block": 20, "type": "code", "linesLength": 6, "startIndex": 71, "lines": ["def find_frequency(corrs, low, high):\n", "    lag = np.array(corrs[low:high]).argmax() + low\n", "    print(lag)\n", "    period = lag / segment.framerate\n", "    frequency = 1 / period\n", "    return frequency"]}, {"block": 21, "type": "markdown", "linesLength": 1, "startIndex": 77, "lines": ["The highest peak is at a lag 95, which corresponds to frequency 464 Hz."]}, {"block": 22, "type": "code", "linesLength": 1, "startIndex": 78, "lines": ["find_frequency(corrs, 80, 100)"]}, {"block": 23, "type": "markdown", "linesLength": 1, "startIndex": 79, "lines": ["At least in this example, the pitch we perceive corresponds to the highest peak in the autocorrelation function (ACF) rather than the highest component of the spectrum."]}, {"block": 24, "type": "markdown", "linesLength": 1, "startIndex": 80, "lines": ["Surprisingly, the perceived pitch doesn't change if we remove the fundamental completely.  Here's what the spectrum looks like if we use a high-pass filter to clobber the fundamental."]}, {"block": 25, "type": "code", "linesLength": 4, "startIndex": 81, "lines": ["spectrum2 = segment.make_spectrum()\n", "spectrum2.high_pass(600)\n", "spectrum2.plot(high=3000)\n", "thinkplot.config(xlabel='Frequency (Hz)', ylabel='Amplitude')"]}, {"block": 26, "type": "markdown", "linesLength": 1, "startIndex": 85, "lines": ["And here's what it sounds like."]}, {"block": 27, "type": "code", "linesLength": 2, "startIndex": 86, "lines": ["segment2 = spectrum2.make_wave()\n", "segment2.make_audio()"]}, {"block": 28, "type": "markdown", "linesLength": 3, "startIndex": 88, "lines": ["The perceived pitch is still 464 Hz, even though there is no power at that frequency.  This phenomenon is called the \"missing fundamental\": https://en.wikipedia.org/wiki/Missing_fundamental\n", "\n", "The effect persists even if we get rid of the first harmonic (near 900 Hz)."]}, {"block": 29, "type": "code", "linesLength": 4, "startIndex": 91, "lines": ["spectrum3 = segment.make_spectrum()\n", "spectrum3.high_pass(1200)\n", "spectrum3.plot(high=3000)\n", "thinkplot.config(xlabel='Frequency (Hz)', ylabel='Amplitude')"]}, {"block": 30, "type": "code", "linesLength": 2, "startIndex": 95, "lines": ["segment3 = spectrum3.make_wave()\n", "segment3.make_audio()"]}, {"block": 31, "type": "markdown", "linesLength": 3, "startIndex": 97, "lines": ["The perceived pitch is still 464 Hz, even though there is no power below 1200 Hz.\n", "\n", "To understand why we hear a frequency that's not in the signal, it helps to look at the autocorrelation function (ACF)."]}, {"block": 32, "type": "code", "linesLength": 3, "startIndex": 100, "lines": ["corrs = autocorr(segment3)\n", "thinkplot.plot(corrs[:200])\n", "thinkplot.config(xlabel='Lag', ylabel='Correlation', ylim=[-1.05, 1.05])"]}, {"block": 33, "type": "markdown", "linesLength": 1, "startIndex": 103, "lines": ["The third peak, which corresponds to 464 Hz, is still the highest:"]}, {"block": 34, "type": "code", "linesLength": 1, "startIndex": 104, "lines": ["find_frequency(corrs, 80, 100)"]}, {"block": 35, "type": "markdown", "linesLength": 1, "startIndex": 105, "lines": ["But there are two other peaks that are almost as high, corresponding to 1297 Hz and 722 Hz.  "]}, {"block": 36, "type": "code", "linesLength": 1, "startIndex": 106, "lines": ["find_frequency(corrs, 20, 50)"]}, {"block": 37, "type": "code", "linesLength": 1, "startIndex": 107, "lines": ["find_frequency(corrs, 50, 80)"]}, {"block": 38, "type": "markdown", "linesLength": 3, "startIndex": 108, "lines": ["So why don't we perceive either of those pitches, instead of 464 Hz?  The reason is that the higher components that are present in the signal are harmonics of 464 Hz and they are not harmonics of 722 or 1297 Hz.\n", "\n", "Our ear interprets the high harmonics as evidence that the \"right\" fundamental is at 464 Hz."]}, {"block": 39, "type": "markdown", "linesLength": 1, "startIndex": 111, "lines": ["If we get rid of the high harmonics, the effect goes away.  Here's a spectrum with harmonics above 1800 Hz removed."]}, {"block": 40, "type": "code", "linesLength": 5, "startIndex": 112, "lines": ["spectrum4 = segment.make_spectrum()\n", "spectrum4.high_pass(1200)\n", "spectrum4.low_pass(1800)\n", "spectrum4.plot(high=3000)\n", "thinkplot.config(xlabel='Frequency (Hz)', ylabel='Amplitude')"]}, {"block": 41, "type": "markdown", "linesLength": 1, "startIndex": 117, "lines": ["Now the perceived pitch is 1378 Hz."]}, {"block": 42, "type": "code", "linesLength": 2, "startIndex": 118, "lines": ["segment4 = spectrum4.make_wave()\n", "segment4.make_audio()"]}, {"block": 43, "type": "code", "linesLength": 1, "startIndex": 120, "lines": ["thinkdsp.TriangleSignal(freq=1378).make_wave(duration=0.5).make_audio()"]}, {"block": 44, "type": "markdown", "linesLength": 1, "startIndex": 121, "lines": ["And if we look at the autocorrelation function, we find the highest peak at lag=32, which corresponds to 1378 Hz."]}, {"block": 45, "type": "code", "linesLength": 3, "startIndex": 122, "lines": ["corrs = autocorr(segment4)\n", "thinkplot.plot(corrs[:200])\n", "thinkplot.config(xlabel='Lag', ylabel='Correlation', ylim=[-1.05, 1.05])"]}, {"block": 46, "type": "code", "linesLength": 1, "startIndex": 125, "lines": ["find_frequency(corrs, 30, 50)"]}, {"block": 47, "type": "markdown", "linesLength": 3, "startIndex": 126, "lines": ["For convenience, here are all the versions together.\n", "\n", "A triangle signal at 464 Hz:"]}, {"block": 48, "type": "code", "linesLength": 1, "startIndex": 129, "lines": ["thinkdsp.TriangleSignal(freq=464).make_wave(duration=0.5).make_audio()"]}, {"block": 49, "type": "markdown", "linesLength": 1, "startIndex": 130, "lines": ["The original segment:"]}, {"block": 50, "type": "code", "linesLength": 1, "startIndex": 131, "lines": ["segment.make_audio()"]}, {"block": 51, "type": "markdown", "linesLength": 1, "startIndex": 132, "lines": ["After removing the fundamental:"]}, {"block": 52, "type": "code", "linesLength": 1, "startIndex": 133, "lines": ["segment2.make_audio()"]}, {"block": 53, "type": "markdown", "linesLength": 1, "startIndex": 134, "lines": ["After removing the fundamental and first harmonic."]}, {"block": 54, "type": "code", "linesLength": 1, "startIndex": 135, "lines": ["segment3.make_audio()"]}, {"block": 55, "type": "markdown", "linesLength": 1, "startIndex": 136, "lines": ["After removing the harmonics above the dominant frequency, too."]}, {"block": 56, "type": "code", "linesLength": 1, "startIndex": 137, "lines": ["segment4.make_audio()"]}, {"block": 57, "type": "markdown", "linesLength": 1, "startIndex": 138, "lines": ["And a pure sinusoid:"]}, {"block": 58, "type": "code", "linesLength": 1, "startIndex": 139, "lines": ["thinkdsp.SinSignal(freq=1378).make_wave(duration=0.5).make_audio()"]}, {"block": 59, "type": "markdown", "linesLength": 1, "startIndex": 140, "lines": ["In summary, these experiments suggest that pitch perception is not based entirely on spectral analysis, but is also informed by something like autocorrelation."]}, {"block": 60, "type": "code", "linesLength": 0, "startIndex": 141, "lines": []}]