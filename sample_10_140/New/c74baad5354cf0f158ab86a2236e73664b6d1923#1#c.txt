[{"block": 0, "type": "markdown", "linesLength": 9, "startIndex": 0, "lines": ["# Working with the MagIC database using PmagPy\n", "\n", "The Magnetics Information Consortium (MagIC) maintains a database of published rock and paleomagnetic data: https://www.earthref.org/MagIC \n", "\n", "Many **PmagPy** scripts are designed to work with data in the MagIC format.  This notebook uses Data Model 3.0: https://www.earthref.org/MagIC/data-models/3.0   \n", "\n", "There are nine basic tables: contribution, locations, sites, samples, specimens, measurements, criteria, ages and images.   These are tab delimited data tables with the first line consisting of a delimiter and the table name: (e.g.,  tab    measurements).  All of the examples here are tab delimited.  The second line contains the column names: (e.g., specimen experiment method_codes treat_temp.....).  Each subsequent line is a single record.\n", "\n", "See the first few lines of this sample file below:"]}, {"block": 1, "type": "code", "linesLength": 3, "startIndex": 9, "lines": ["with open('data_files/3_0/McMurdo/samples.txt') as f:\n", "    for line in f.readlines()[:3]:\n", "        print(line, end=\"\")"]}, {"block": 2, "type": "markdown", "linesLength": 19, "startIndex": 12, "lines": ["## Guide to PmagPy\n", "\n", "The notebook is one of a series of notebooks that demonstrate the functionality of PmagPy. The other notebooks are:\n", "\n", "- [PmagPy_introduction.ipynb](PmagPy_introduction.ipynb) This notebook introduces PmagPy and lists the functions that are demonstrated in the other notebooks. \n", "- [PmagPy_calculations.ipynb](PmagPy_calculations.ipynb) This notebook demonstrates many of the PmagPy calculation functions such as those that rotate directions, return statistical parameters, and simulate data from specified distributions. \n", "- [PmagPy_plots_analysis.ipynb](PmagPy_plots_analysis.ipynb) This notebook demonstrates PmagPy functions that can be used to visualize data as well as those that conduct statistical tests that have associated visualizations.\n", "\n", "## Customizing this notebook\n", "\n", "If you want to make changes to this notebook, you should make a copy (see File menu).  Otherwise each time you update **PmagPy**, your changes will be overwritten.\n", "\n", "## Get started\n", "\n", "To use the functions in this notebook, we have to   import the **PmagPy** modules **pmagplotlib**, **pmag** and **ipmag** and some other handy functions for use in the notebook.  This is done in the following code block which must be executed before running any other code block. To execute, click on the code block and then click on the \"Run\" button in the menu.  \n", "\n", "In order to access the example data, this notebook is meant to be run in the PmagPy-data directory (PmagPy directory for developers).\n", "\n", "Try it!  Run the code block below (click on the cell and then click 'Run'):"]}, {"block": 3, "type": "code", "linesLength": 23, "startIndex": 31, "lines": ["import pmagpy.pmag as pmag\n", "import pmagpy.pmagplotlib as pmagplotlib\n", "import pmagpy.ipmag as ipmag\n", "import pmagpy.contribution_builder as cb\n", "from pmagpy import convert_2_magic as convert\n", "import matplotlib.pyplot as plt # our plotting buddy\n", "import numpy as np # the fabulous NumPy package\n", "import pandas as pd # and of course Pandas\n", "# test if Basemap and/or cartopy is installed\n", "has_basemap, Basemap = pmag.import_basemap()\n", "has_cartopy, Cartopy = pmag.import_cartopy()\n", "# test if xlwt is installed (allows you to export to excel)\n", "try:\n", "    import xlwt\n", "    has_xlwt = True\n", "except ImportError:\n", "    has_xlwt = False\n", "# This allows you to make matplotlib plots inside the notebook.  \n", "%matplotlib inline \n", "from IPython.display import Image\n", "import os\n", "\n", "print('All modules imported!')"]}, {"block": 4, "type": "markdown", "linesLength": 44, "startIndex": 54, "lines": ["# Table of contents\n", "- Functions in **PmagPy_MagIC.ipynb**\n", "    - [reading MagIC files](#magic_read) : reading in MagIC formatted files\n", "    - [writing MagIC files](#magic_write) : outputing MagIC formatted files\n", "    - [combine_magic](#combine_magic) : combines two MagIC formatted files of same type\n", "    - [convert_ages](#convert_ages) : convert ages in downloaded MagIC file to Ma\n", "    - [grab_magic_key](#grab_magic_key) : prints out a single column from a MagIC format file\n", "    - [magic_select](#magic_select) : selects data from MagIC format file given conditions (e.g., method_codes contain string)\n", "    - [sites_extract](#sites_extract) : makes excel or latex files from sites.txt for publications\n", "    - [criteria_extract](#criteria_extract) : makes excel or latex files from criteria.txt for publications\n", "    - [specimens_extract](#specimens_extract) : makes excel or latex files from specimens.txt for publications\n", "    - [contributions](#Contributions) work with data model 3.0 MagIC contributions\n", "        - [download_magic](#download_magic) : how to download and unpack a contribution text file from the MagIC website\n", "        - [upload_magic](#upload_magic) : prepares a directory with a MagIC contribution for uploading to MagIC\n", "        - [cb.add_sites_to_meas_table](#cb.add_sites_to_meas_table) : completes a measurements data frame with the information required for plotting by site. \n", "        - [cb.get_intensity_col](#cb.get_intensity_col) : finds the first non-zero type of intensity data in a measurements dataframe.\n", "    - [conversion scripts](#Conversion-Scripts) : convert many laboratory measurement formats to the MagIC data model 3 format\n", "        - [\\_2g\\_asc_magic](#\\_2g\\_asc\\_magic) : converts 2G ascii files to MagIC\n", "        - [\\_2g\\_bin_magic](#\\_2g\\_bin\\_magic) : converts 2G binary files to MagIC\n", "        - [agm_magic](#agm_magic) : converts Princeton Measurements alternating gradient force magnetization (AGM) files to MagIC.\n", "        - [bgc_magic](#bgc_magic) : convert Berkeley Geochronology Center files to MagIC. \n", "        - [cit_magic](#cit_magic) : convert Cal Tech format files to MagIC.\n", "        - [generic_magic](#generic_magic) : converts generic files to MagIC. \n", "        - [huji_magic](#huji_magic) : converts Hebrew University, Jerusalem, Israel files to MagIC.\n", "        - [huji_sample_magic](#huji_sample_magic) : converts HUJI files to a MagIC format. \n", "        - [iodp_dscr_lore](#iodp_dscr_lore) : converts IODP discrete measurement files to MagIC\n", "        - [iodp_jr6_lore](#iodp_jr6_lore) : converts IODP JR6 measurement files to MagIC\n", "        - [iodp_samples_csv](#iodp_dscr_lore) : converts IODP samples file to MagIC\n", "        - [iodp_srm_lore](#iodp_srm_lore) : converts IODP archive half measurement files to MagIC   \n", "        - [jr6_jr6_magic](#jr6_jr6_magic) : converts the AGICO JR6 spinner .jr6 files to MagIC \n", "        - [jr6_txt_magic](#jr6_txt_magic) : converts the AGICO JR6 .txt files to MagIC\n", "        - [k15_magic](#k15_magic) : converts 15 measurement anisotropy of magnetic susceptibility files to MagIC.\n", "        - [kly4s_magic](#kly4s_magic) : converts SIO KLY4S formatted files to MagIC.\n", "        - [ldeo_magic](#ldeo_magic) : converts Lamont-Doherty files to MagIC.  \n", "        - [livdb_magic](#livdb_magic) : converts Liverpool files to MagIC.  \n", "        - [mst_magic](#mst_magic) : converts Curie Temperature experimental data to MagIC\n", "        - [sio_magic](#sio_magic) : converts Scripps Institution of Oceanography data files to MagIC \n", "        - [sufar4_magic](#sufar4_magic) : converts AGICO SUFAR program (ver.1.2.) ascii files to MagIC\n", "        - [tdt_magic](#tdt_magic) : converts Thellier Tool files to MagIC\n", "        - [utrecht_magic](#utrecht_magic) : converts Fort Hoofddijk, Utrecht University Robot files to MagIC\n", "        - [orientation_magic](#orientation_magic) : converts an \"orient.txt\" formatted file with field notebook information into MagIC formatted files\n", "        - [azdip_magic](#azdip_magic) : converts an \"azdip\" formatted file to a samples.txt file format\n", "- other handy scripts\n", "    - [chartmaker](#chartmaker) : script for making chart to guide IZZI lab experiment"]}, {"block": 5, "type": "markdown", "linesLength": 1, "startIndex": 98, "lines": ["### I/O with MagIC data files"]}, {"block": 6, "type": "markdown", "linesLength": 12, "startIndex": 99, "lines": ["### magic_read\n", "\n", "- MagIC formatted data files can be imported to a notebook in one of two ways: a\n", "\n", "    - importing to a Pandas DataFrame using the Pandas pd.read_csv() function\n", "    - importing to a list of dictionaries using the pmag.magic_read() function.  \n", "    \n", "    In this notebook, we generally read MagIC tables into a Pandas Dataframe with a command like: \n", "\n", "`meas_df = pd.read_csv('MEASUREMENTS_FILE_PATH',sep='\\t',header=1)`\n", "\n", "These data can then be manipulated with **Pandas** functions (https://pandas.pydata.org/)\n"]}, {"block": 7, "type": "code", "linesLength": 2, "startIndex": 111, "lines": ["meas_df=pd.read_csv('data_files/3_0/McMurdo/measurements.txt',sep='\\t',header=1)\n", "meas_df.head()"]}, {"block": 8, "type": "markdown", "linesLength": 1, "startIndex": 113, "lines": ["Alternatively, the user may wish to use a list of dictionaries compatible with many **pmag** functions.  For that, use the **pmag.magic_read()** function: "]}, {"block": 9, "type": "code", "linesLength": 1, "startIndex": 114, "lines": ["help (pmag.magic_read)"]}, {"block": 10, "type": "code", "linesLength": 3, "startIndex": 115, "lines": ["meas_dict,file_type=pmag.magic_read('data_files/3_0/McMurdo/measurements.txt')\n", "print (file_type)\n", "print (meas_dict[0])"]}, {"block": 11, "type": "markdown", "linesLength": 12, "startIndex": 118, "lines": ["### magic_write\n", "\n", "To write out a  MagIC table from a Pandas DataFrame, first convert it to a list of dictionaries using a command like:\n", "\n", "`dicts = df.to_dict('records')`\n", "\n", "\n", "\n", "then call **pmag.magic_write()**.\n", "\n", "From a list of dictionaries, you can just call **pmag.magic_write()** directly.  \n", "\n"]}, {"block": 12, "type": "markdown", "linesLength": 1, "startIndex": 130, "lines": ["### pmag.magic_write"]}, {"block": 13, "type": "code", "linesLength": 1, "startIndex": 131, "lines": ["help(pmag.magic_write)"]}, {"block": 14, "type": "code", "linesLength": 2, "startIndex": 132, "lines": ["meas_dicts = meas_df.to_dict('records')\n", "pmag.magic_write('my_measurements.txt', meas_dicts, 'measurements')"]}, {"block": 15, "type": "markdown", "linesLength": 6, "startIndex": 134, "lines": ["### combine_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#combine_magic.py)\n", " \n", " MagIC tables have many columns only some of which are used in a particular instance. So combining files of the same type must be done carefully to ensure that the right data come under the right headings. The program **combine_magic** can be used to combine any number of MagIC files from a given type.  \n", "It  reads in MagIC formatted files of a common type (e.g., sites.txt) and combines them into a single file, taking care that all the columns are preserved. For example, if there are both AF and thermal data from a study and we created a measurements.txt formatted file for each, we could use **combine_magic.py** on the command line to combine them together into a single measurements.txt file.   In a notebook, we use  **ipmag.combine_magic()**.  \n"]}, {"block": 16, "type": "code", "linesLength": 1, "startIndex": 140, "lines": ["help(ipmag.combine_magic)"]}, {"block": 17, "type": "markdown", "linesLength": 1, "startIndex": 141, "lines": ["Here we make a list of names of two MagIC formatted measurements.txt files and use **ipmag.combine_magic()** to put them together."]}, {"block": 18, "type": "code", "linesLength": 3, "startIndex": 142, "lines": ["filenames=['data_files/combine_magic/af_measurements.txt','../combine_magic/therm_measurements.txt']\n", "outfile='data_files/combine_magic/measurements.txt'\n", "ipmag.combine_magic(filenames,outfile)"]}, {"block": 19, "type": "markdown", "linesLength": 6, "startIndex": 145, "lines": ["### convert_ages\n", "\n", "Files downloaded from the MagIC search interface have ages that are in the original units, but what is often desired is for them to be in a single unit.  For example, if we searched the MagIC database for all absolute paleointensity data (records with method codes of 'LP-PI-TRM') from the last five million years, the data sets have a variety of age units.  We can use **pmag.convert_ages()**    to convert them all to millions of years.  \n", "\n", "First we follow the instructions for unpacking downloaded files in [download_magic](#download_magic).  \n", "\n"]}, {"block": 20, "type": "code", "linesLength": 2, "startIndex": 151, "lines": ["ipmag.download_magic('magic_downloaded_rows.txt',dir_path='data_files/convert_ages/',\n", "      input_dir_path='data_files/convert_ages/')"]}, {"block": 21, "type": "markdown", "linesLength": 3, "startIndex": 153, "lines": ["After some minimal filtering using Pandas, we can convert a DataFrame to a list of dictionaries required by most PmagPy functions and use **pmag.convert_ages()** to convert all the ages.  The converted list of dictionaries can then be turned back into a Pandas DataFrame and either plotted or filtered further as desired.  \n", "\n", "In this example, we filter for data older than the Brunhes (0.78 Ma) and younger than 5 Ma, then plot them against latitude.  We can also use [vdm_b](#vdm_b) to plot the intensities expected from the present dipole moment (~80 ZAm$^2$). "]}, {"block": 22, "type": "code", "linesLength": 1, "startIndex": 156, "lines": ["help(pmag.convert_ages)"]}, {"block": 23, "type": "code", "linesLength": 24, "startIndex": 157, "lines": ["# read in the sites.txt file as a dataframe\n", "site_df=pd.read_csv('data_files/convert_ages/sites.txt',sep='\\t',header=1)\n", "# get rid aof any records without intensity data or latitude\n", "site_df=site_df.dropna(subset=['int_abs','lat'])\n", "# Pick out the sites with 'age' filled in\n", "site_df_age=site_df.dropna(subset=['age'])\n", "# pick out those with age_low and age_high filled in\n", "site_df_lowhigh=site_df.dropna(subset=['age_low','age_high'])\n", "# concatenate the two\n", "site_all_ages=pd.concat([site_df_age,site_df_lowhigh]) \n", "# get rid of duplicates (records with age, age_high AND age_low)\n", "site_all_ages.drop_duplicates(inplace=True)\n", "# Pandas reads in blanks as NaN, which pmag.convert_ages hates\n", "# this replaces all the NaNs with blanks\n", "site_all_ages.fillna('',inplace=True)\n", "# converts to a list of dictionaries\n", "sites=site_all_ages.to_dict('records')\n", "# converts the ages to Ma\n", "converted_df=pmag.convert_ages(sites)\n", "# turn it back into a DataFrame\n", "site_ages=pd.DataFrame(converted_df)\n", "# filter away\n", "site_ages=site_ages[site_ages.age.astype(float) <= 5]\n", "site_ages=site_ages[site_ages.age.astype(float) >=0.05]"]}, {"block": 24, "type": "markdown", "linesLength": 1, "startIndex": 181, "lines": ["Let's plot them up and see what we get."]}, {"block": 25, "type": "code", "linesLength": 11, "startIndex": 182, "lines": ["plt.plot(site_ages.lat,site_ages.int_abs*1e6,'bo')\n", "\n", "# put on the expected values for the present dipole moment (~80 ZAm^2)\n", "\n", "lats=np.arange(-80,70,1)\n", "vdms=80e21*np.ones(len(lats))\n", "bs=pmag.vdm_b(vdms,lats)*1e6\n", "plt.plot(lats,bs,'r-')\n", "plt.xlabel('Latitude')\n", "plt.ylabel('Intensity ($\\mu$T)')\n", "plt.show()"]}, {"block": 26, "type": "markdown", "linesLength": 1, "startIndex": 193, "lines": ["That is pretty awful agreement.  Someday we need to figure out what is wrong with the data or  our GAD hypothesis.  "]}, {"block": 27, "type": "markdown", "linesLength": 5, "startIndex": 194, "lines": ["### grab_magic_key\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC) [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#grab_magic_key.py)\n", "\n", "Sometimes you want to read in a MagIC file and print out the desired key. **Pandas** makes this easy!  In this example, we will print out latitudes for each site record."]}, {"block": 28, "type": "code", "linesLength": 2, "startIndex": 199, "lines": ["sites=pd.read_csv('data_files/download_magic/sites.txt',sep='\\t',header=1)\n", "print (sites.lat)"]}, {"block": 29, "type": "markdown", "linesLength": 8, "startIndex": 201, "lines": ["### magic_select\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC) [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#magic_select.py)\n", "\n", "This example demonstrates how to select MagIC records that meet a certain criterion, like having a particular method code.\n", "\n", "Note:  to output into a MagIC formatted file, we can change the DataFrame to a list of dictionaries (with df.to_dict(\"records\")) and\n", "use **pmag.magic_write()**.. "]}, {"block": 30, "type": "code", "linesLength": 1, "startIndex": 209, "lines": ["help(pmag.magic_write)"]}, {"block": 31, "type": "code", "linesLength": 7, "startIndex": 210, "lines": ["# read in the data file\n", "spec_df=pd.read_csv('data_files/magic_select/specimens.txt',sep='\\t',header=1)\n", "# pick out the desired data \n", "method_key='method_codes' # change to method_codes for data model 3\n", "spec_df=spec_df[spec_df.method_codes.str.contains('LP-DIR-AF')]\n", "specs=spec_df.to_dict('records') # export to list of dictionaries\n", "success,ofile=pmag.magic_write('data_files/magic_select/AF_specimens.txt',specs,'pmag_specimens') # specimens for data model 3.0\n"]}, {"block": 32, "type": "markdown", "linesLength": 3, "startIndex": 217, "lines": ["### sites_extract\n", "\n", "It is frequently desirable to format tables for publications from the MagIC formatted files.  This example is for the sites.txt formatted file.  It will create a site information table with the location and age information,  and directions and/or intenisty summary tables.  The function to call is **ipmag.sites_extract()**."]}, {"block": 33, "type": "code", "linesLength": 1, "startIndex": 220, "lines": ["help(ipmag.sites_extract)"]}, {"block": 34, "type": "markdown", "linesLength": 1, "startIndex": 221, "lines": ["Here is an example for how to create Latex files: "]}, {"block": 35, "type": "code", "linesLength": 3, "startIndex": 222, "lines": ["#latex way:\n", "ipmag.sites_extract(directions_file='directions.tex',intensity_file='intensities.tex',\n", "              output_dir_path='data_files/3_0/McMurdo',info_file='site_info.tex',latex=True)"]}, {"block": 36, "type": "markdown", "linesLength": 1, "startIndex": 225, "lines": ["And here is how to create Excel files:"]}, {"block": 37, "type": "code", "linesLength": 3, "startIndex": 226, "lines": ["#xls way:\n", "if has_xlwt:\n", "    print(ipmag.sites_extract(output_dir_path='data_files/3_0/McMurdo'))"]}, {"block": 38, "type": "markdown", "linesLength": 3, "startIndex": 229, "lines": ["### criteria_extract\n", "\n", "This example is for the criteria.txt formatted file.  It will create a criteria  table suitable for publication in either LaTex or .csv format.  The function to call is **ipmag.criteria_extract()**."]}, {"block": 39, "type": "code", "linesLength": 1, "startIndex": 232, "lines": ["help(ipmag.criteria_extract)"]}, {"block": 40, "type": "code", "linesLength": 3, "startIndex": 233, "lines": ["# latex way:\n", "ipmag.criteria_extract(output_dir_path='data_files/3_0/Megiddo',\n", "                       latex=True,output_file='criteria.tex',)"]}, {"block": 41, "type": "code", "linesLength": 3, "startIndex": 236, "lines": ["#xls way:\n", "if has_xlwt:\n", "    print(ipmag.criteria_extract(output_dir_path='data_files/3_0/Megiddo'))"]}, {"block": 42, "type": "markdown", "linesLength": 3, "startIndex": 239, "lines": ["### specimens_extract\n", "\n", "Similarly, it is useful to make tables for specimen (intensity) data to include in publications.  Here are examples using a specimens.txt file.  "]}, {"block": 43, "type": "code", "linesLength": 1, "startIndex": 242, "lines": ["help(ipmag.specimens_extract)"]}, {"block": 44, "type": "code", "linesLength": 3, "startIndex": 243, "lines": ["#latex way:\n", "ipmag.specimens_extract(output_file='specimens.tex',landscape=True,\n", "              output_dir_path='data_files/3_0/Megiddo',latex=True,longtable=True)"]}, {"block": 45, "type": "code", "linesLength": 3, "startIndex": 246, "lines": ["#xls way:\n", "if has_xlwt:\n", "    print(ipmag.specimens_extract(output_dir_path='data_files/3_0/Megiddo'))"]}, {"block": 46, "type": "markdown", "linesLength": 3, "startIndex": 249, "lines": ["## Contributions\n", "\n", "Here are some useful functions for working with MagIC data model 3.0 contributions. "]}, {"block": 47, "type": "markdown", "linesLength": 9, "startIndex": 252, "lines": ["### download_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#download_magic.py)\n", "\n", "The programs ipmag.download_magic_from_id() and ipmag.download_magic_from_doi() download files from the MagIC website and ipmag.download_magic( ) unpacks the downloaded .txt file  into individual text files. This program has an option to also separate the contribution into separate folders for each location.\n", " \n", " As an example, download the cotribution with the DOI of 10.1029/2019GC008479.    Make a folder into which you should put the downloaded txt file (called \"magic_contribution.txt\")  into it. Then use **ipmag.download_magic** to unpack the .txt file (magic_contribution.txt).\n", "\n", "Here is an example."]}, {"block": 48, "type": "code", "linesLength": 1, "startIndex": 261, "lines": ["help(ipmag.download_magic_from_doi)"]}, {"block": 49, "type": "code", "linesLength": 1, "startIndex": 262, "lines": ["help(ipmag.download_magic)"]}, {"block": 50, "type": "markdown", "linesLength": 1, "startIndex": 263, "lines": ["And here we go... "]}, {"block": 51, "type": "code", "linesLength": 6, "startIndex": 264, "lines": ["dir_path='data_files/download_magic' # set the path to the correct working directory\n", "reference_doi='10.1029/2019GC008479'  # set the reference DOI\n", "magic_contribution='magic_contribution.txt' # default filename for downloaded file\n", "ipmag.download_magic_from_doi(reference_doi)\n", "os.rename(magic_contribution, dir_path+'/'+magic_contribution)\n", "ipmag.download_magic(magic_contribution,dir_path=dir_path,print_progress=False)"]}, {"block": 52, "type": "code", "linesLength": 1, "startIndex": 270, "lines": ["help(ipmag.download_magic_from_id)"]}, {"block": 53, "type": "code", "linesLength": 6, "startIndex": 271, "lines": ["dir_path='data_files/download_magic' # set the path to the correct working directory\n", "magic_id='16676' # set the magic ID number\n", "magic_contribution='magic_contribution_'+magic_id+'.txt' # set the file name string\n", "ipmag.download_magic_from_id(magic_id) # download the contribution from MagIC\n", "os.rename(magic_contribution, dir_path+'/'+magic_contribution) # move the contribution to the directory\n", "ipmag.download_magic(magic_contribution,dir_path=dir_path,print_progress=False) # unpack the file"]}, {"block": 54, "type": "markdown", "linesLength": 1, "startIndex": 277, "lines": ["You could look at these data with **dmag_magic** for example... (see the **PmagPy_plots_analysis** notebook)."]}, {"block": 55, "type": "markdown", "linesLength": 6, "startIndex": 278, "lines": ["### upload_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#upload_magic.py)\n", "\n", "We can just turn around and try to upload the file downloaded in [download_magic](#download_magic).  For this we use **ipmag.upload_magic()** in the same directory as for the download.   You can try to upload the file you create to the MagIC data base as a private contribution here: https://www2.earthref.org/MagIC/upload\n", "\n"]}, {"block": 56, "type": "code", "linesLength": 1, "startIndex": 284, "lines": ["help(ipmag.upload_magic)"]}, {"block": 57, "type": "code", "linesLength": 1, "startIndex": 285, "lines": ["ipmag.upload_magic(dir_path='data_files/download_magic',concat=True)"]}, {"block": 58, "type": "markdown", "linesLength": 1, "startIndex": 286, "lines": ["If this were your own study, you could now go to https://earthref.org/MagIC and upload your contribution to a Private Workspace, validate, assign a DOI and activate!  "]}, {"block": 59, "type": "markdown", "linesLength": 3, "startIndex": 287, "lines": ["### cb.add_sites_to_meas_table\n", "\n", "MagIC data model 3 took out redundant columns in the MagIC tables so the hierarchy of specimens (in the measurements and specimens tables) up to samples, sites and locations is lost.  To put these back into the measurement table, we have the function **cb.add_sites_to_meas_table()**, which is super handy when data analysis requires it.  "]}, {"block": 60, "type": "code", "linesLength": 1, "startIndex": 290, "lines": ["help(cb.add_sites_to_meas_table)"]}, {"block": 61, "type": "code", "linesLength": 2, "startIndex": 291, "lines": ["status,meas_df=cb.add_sites_to_meas_table('data_files/3_0/McMurdo')\n", "meas_df.columns"]}, {"block": 62, "type": "markdown", "linesLength": 3, "startIndex": 293, "lines": ["### cb.get_intensity_col\n", "\n", "The MagIC data model has several different forms of magnetization with different normalizations (moment, volume, or mass).  So to find the one used in a particular measurements table we can use this handy function.  "]}, {"block": 63, "type": "code", "linesLength": 1, "startIndex": 296, "lines": ["help(cb.get_intensity_col)"]}, {"block": 64, "type": "code", "linesLength": 2, "startIndex": 297, "lines": ["magn_col=cb.get_intensity_col(meas_df)\n", "print (magn_col)"]}, {"block": 65, "type": "markdown", "linesLength": 6, "startIndex": 299, "lines": ["# Conversion Scripts\n", "\n", "## convert_2_magic\n", "\n", "We imported this module as **convert**.  It provides many functions for creating MagIC format files from non-MagIC formats. The MagIC formatted files can then be used with PmagPy programs and uploaded to the MagIC database. Let's take a look at the options:\n", "\n"]}, {"block": 66, "type": "markdown", "linesLength": 3, "startIndex": 305, "lines": ["### \\_2g\\_asc\\_magic\n", "\n", "This conversion has not been written yet. If you have this file format and wish to convert it to the MagIC file format, please let us know."]}, {"block": 67, "type": "markdown", "linesLength": 5, "startIndex": 308, "lines": ["### \\_2g\\_bin\\_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#_2g_bin_magic.py)\n", "\n", "To convert the binary formatted 2G Enterprises measurement files, we  can use the function **convert.\\_2g_bin()** in the **convert_2_magic** module (imported as **convert**). "]}, {"block": 68, "type": "code", "linesLength": 1, "startIndex": 313, "lines": ["help(convert._2g_bin)"]}, {"block": 69, "type": "code", "linesLength": 4, "startIndex": 314, "lines": ["# set the input directory\n", "input_dir='data_files/convert_2_magic/2g_bin_magic/mn1/'\n", "mag_file='mn001-1a.dat'\n", "convert._2g_bin(mag_file=mag_file,input_dir=input_dir,dir_path=input_dir)"]}, {"block": 70, "type": "markdown", "linesLength": 1, "startIndex": 318, "lines": ["These are measurement data for a single specimen, so we can take a quickie look at the data in an equal area projection."]}, {"block": 71, "type": "code", "linesLength": 1, "startIndex": 319, "lines": ["help(ipmag.plot_di)"]}, {"block": 72, "type": "code", "linesLength": 3, "startIndex": 320, "lines": ["meas_df=pd.read_csv(input_dir+'measurements.txt',sep='\\t',header=1)\n", "ipmag.plot_net(1)\n", "ipmag.plot_di(dec=meas_df['dir_dec'],inc=meas_df['dir_inc'])"]}, {"block": 73, "type": "markdown", "linesLength": 8, "startIndex": 323, "lines": ["### agm_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#agm_magic.py)\n", "\n", " This program converts Micromag hysteresis files into MagIC formatted files. Because this program creates files for uploading to the MagIC database, specimens should also have sample/site/location information, which can be provided on the command line. If this information is not available, for example if this is a synthetic specimen, specify syn= True for synthetic name. \n", "\n", "Someone named Lima Tango has measured a synthetic specimen named myspec for hysteresis and saved the data in a file named agm_magic_example.agm in the agm_magic/agm_directory folder. The backfield IRM curve for the same specimen was saved in same directory as agm_magic_example.irm. Use the function **convert.agm()** to convert the data into a measurements.txt output file. For the backfield IRM file, set the keyword \"bak\" to True.  These were measured using cgs units, so be sure to set the units key word argument properly. Combine the two output files together using the instructions for [combine_magic](#combine_magic).  The agm files can be plotted using [hysteresis_magic](#hysteresis_magic) but the back-field plots are broken.  \n", "\n"]}, {"block": 74, "type": "code", "linesLength": 1, "startIndex": 331, "lines": ["help(convert.agm)"]}, {"block": 75, "type": "code", "linesLength": 2, "startIndex": 332, "lines": ["convert.agm('agm_magic_example.agm',dir_path='data_files/convert_2_magic/agm_magic/',\n", "            specimen='myspec',fmt='old',meas_outfile='agm.magic')"]}, {"block": 76, "type": "code", "linesLength": 2, "startIndex": 334, "lines": ["convert.agm('agm_magic_example.irm',dir_path='data_files/convert_2_magic/agm_magic/',\n", "            specimen='myspec',fmt='old',meas_outfile='irm.magic')"]}, {"block": 77, "type": "code", "linesLength": 2, "startIndex": 336, "lines": ["infiles=['data_files/convert_2_magic/agm_magic/agm.magic','data_files/convert_2_magic/agm_magic/irm.magic']\n", "ipmag.combine_magic(infiles,'data_files/convert_2_magic/agm_magic/measurements.txt')"]}, {"block": 78, "type": "markdown", "linesLength": 1, "startIndex": 338, "lines": ["We can look at these data using **hysteresis_magic**:"]}, {"block": 79, "type": "code", "linesLength": 23, "startIndex": 339, "lines": ["# read in the measurements data\n", "meas_data=pd.read_csv('data_files/convert_2_magic/agm_magic/agm.magic',sep='\\t',header=1)\n", "# pick out the hysteresis data using the method code for hysteresis lab protocol\n", "hyst_data=meas_data[meas_data.method_codes.str.contains('LP-HYS')]\n", "\n", "# make the dictionary for figures that pmagplotlib likes\n", "\n", "# make a list of specimens\n", "specimens=hyst_data.specimen.unique()\n", "cnt=1\n", "for specimen in specimens:\n", "    HDD={'hyst':cnt,'deltaM':cnt+1,'DdeltaM':cnt+2}\n", "    spec_data=hyst_data[hyst_data.specimen==specimen]\n", "# make a list of the field data\n", "    B=spec_data.meas_field_dc.tolist()\n", "# make a list o the magnetizaiton data\n", "    M=spec_data.magn_moment.tolist()\n", "# call the plotting function\n", "    hpars=pmagplotlib.plot_hdd(HDD,B,M,specimen)\n", "    hpars['specimen']=specimen\n", "# print out the hysteresis parameters\n", "    print (specimen,': \\n',hpars)\n", "    cnt+=3"]}, {"block": 80, "type": "markdown", "linesLength": 6, "startIndex": 362, "lines": ["### bgc_magic \n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#bgc_magic.py)\n", "\n", "Here we convert the Berkeley Geochronology Center's AutoCore format to MagIC use **convert.bgc()**. \n", "\n"]}, {"block": 81, "type": "code", "linesLength": 1, "startIndex": 368, "lines": ["help(convert.bgc)"]}, {"block": 82, "type": "code", "linesLength": 2, "startIndex": 369, "lines": ["dir_path='data_files/convert_2_magic/bgc_magic/'\n", "convert.bgc('15HHA1-2A',dir_path=dir_path)"]}, {"block": 83, "type": "markdown", "linesLength": 1, "startIndex": 371, "lines": ["And let's take a look"]}, {"block": 84, "type": "code", "linesLength": 3, "startIndex": 372, "lines": ["meas_df=pd.read_csv(dir_path+'measurements.txt',sep='\\t',header=1)\n", "ipmag.plot_net(1)\n", "ipmag.plot_di(dec=meas_df['dir_dec'],inc=meas_df['dir_inc'])"]}, {"block": 85, "type": "markdown", "linesLength": 11, "startIndex": 375, "lines": ["### cit_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#cit_magic.py)\n", "\n", "To convert the CalTech format to MagIC, use **convert.cit()**. \n", "\n", "Craig Jones\u2019 PaleoMag software package (http://cires.colorado.edu/people/jones.craig/PMag3.html) imports various file formats, including the \u2019CIT\u2019 format developed for the Caltech lab and now used in magnetometer control software that ships with 2G magnetometers that utilized a vertical sample changer system. The documentation for the CIT sample format is here: http://cires.colorado.edu/people/jones.craig/PMag_Formats.html#SAM_format. Demagnetization data for each specimen are in their own file in a directory with all the data for a site or study. These files are strictly formatted with fields determined by the character number in the line. There must be a file with the suffix \u2018.sam\u2019 in the same directory as the specimen data files which gives details about the specimens and a list of the specimen measurementfiles in the directory. \n", "\n", " The first line in the .sam file is a comment (in this case the site name), the second is the latitude and longitude followed by a declination correction. In these data, the declination correction was applied to the specimen orientations so the value of the declination correction is set to be 0.\n", "\n", "For detailed description of the .sam and sample file formats, check the PaleoMag Formats website linked to above.\n"]}, {"block": 86, "type": "code", "linesLength": 1, "startIndex": 386, "lines": ["help(convert.cit)"]}, {"block": 87, "type": "markdown", "linesLength": 1, "startIndex": 387, "lines": ["Use the function **convert.cit()** to covert the CIT data files from Swanson-Hysell lab at Berkeley for the PI47 site in the data_files/convert_2_magic/cit_magic/PI47 directory. The site (PI47) was part of a data set published in Fairchild et al., (2016) (available in the MagIC database: (https://earthref.org/MagIC/11292/). The location name was \u201cSlate Islands\u201d, the naming convention was #2, the specimen name is specified with 1 character, we don\u2019t wish to average replicate measurements  and they were collected by drilling and with a magnetic compass (\u201dFS-FD\",and \"SO-MAG\u201d). "]}, {"block": 88, "type": "code", "linesLength": 4, "startIndex": 388, "lines": ["dir_path='data_files/convert_2_magic/cit_magic/PI47/'\n", "convert.cit(dir_path=dir_path,\n", "           magfile='PI47-.sam',locname=\"Slate Islands\",specnum=1,samp_con='2',\n", "           methods=['FS-FD','SO-MAG'],noave=True)"]}, {"block": 89, "type": "markdown", "linesLength": 1, "startIndex": 392, "lines": ["We can make some Zijderveld diagrams (see **zeq_magic** in the **PmagPy_plots_analysis** notebook). "]}, {"block": 90, "type": "code", "linesLength": 1, "startIndex": 393, "lines": ["ipmag.zeq_magic(input_dir_path=dir_path, save_plots=False)"]}, {"block": 91, "type": "markdown", "linesLength": 1, "startIndex": 394, "lines": ["Use the function convert.cit() to covert the CIT data files from the USGS lab at Menlo Park. The data file is in the data_files/convert_2_magic/cit_magic/USGS/bl9-1 directory, the file name is bl9-1.sam, and the analyst was Hagstrum. The location name was \u201cBoring volcanic field\u201d, and this site name was set by Hagstrum to BL9001 because the site name cannot be determined from the sample name with the current available options. The samples were collected by drilling and with a magnetic compass and sun compass (\u201dFS-FD\",and \"SO-MAG\u201d), the measurement are in Oersted instead of the standard milliTesla, and we don\u2019t wish to average replicate measurements."]}, {"block": 92, "type": "code", "linesLength": 5, "startIndex": 395, "lines": ["dir_path='data_files/convert_2_magic/cit_magic/USGS/bl9-1'\n", "convert.cit(dir_path=dir_path,\n", "           magfile='bl9-1.sam',user='Hagstrum',locname=\"Boring volcanic field\",\n", "           sitename='BL9001',methods=['FS-FD','SO-SM','LT-AF-Z'], oersted=True,\n", "           noave=True)"]}, {"block": 93, "type": "markdown", "linesLength": 1, "startIndex": 400, "lines": ["We can look at the Zijderveld, etc.  Diagrams with [zeq_magic](#zeq_magic)."]}, {"block": 94, "type": "code", "linesLength": 1, "startIndex": 401, "lines": ["ipmag.zeq_magic(input_dir_path=dir_path, save_plots=False)"]}, {"block": 95, "type": "markdown", "linesLength": 4, "startIndex": 402, "lines": ["Use the function convert.cit() to convert the CIT data files from Ben Wiess's lab at MIT. This data was part of a set published in ESPL. \"A nonmagnetic differentiated early planetary body\", \n", "doi:10.1016/j.epsl.2017.03.026 The data can be found in MagIC at https://earthref.org/MagIC/11943\n", "\n", "The data file is in the data_files/convert_2_magic/cit_magic/MIT/7325B directory, the file name is 7325B.sam, and the analyst was Wiess. The location name was \u201cNWA 7325\u201d with the site name coming from the sample name with the \"1\" convention. The samples are described with the method codes DE-VM, LP-DIR-T, LT-AF-Z, LT-NO, LT-T-Z, and SO-CMD-NORTH (see https://www2.earthref.org/MagIC/method-codes for full descriptions). We also don\u2019t wish to average replicate measurements."]}, {"block": 96, "type": "code", "linesLength": 4, "startIndex": 406, "lines": ["convert.cit(dir_path='data_files/convert_2_magic/cit_magic/MIT/7325B',\n", "           magfile='7325B.sam',user='Wiess',locname=\"NWA 7325\",samp_con='1',\n", "           methods=['DE-VM', 'LP-DIR-T', 'LT-AF-Z', 'LT-NO', 'LT-T-Z', 'SO-CMD-NORTH'],\n", "           noave=True)"]}, {"block": 97, "type": "markdown", "linesLength": 1, "startIndex": 410, "lines": ["And take a look see:"]}, {"block": 98, "type": "code", "linesLength": 1, "startIndex": 411, "lines": ["ipmag.zeq_magic(input_dir_path=dir_path, save_plots=False)"]}, {"block": 99, "type": "markdown", "linesLength": 7, "startIndex": 412, "lines": ["### generic_magic \n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#generic_magic.py)\n", "\n", "If you have a data file format that is not supported, you can relabel column headers to fit the generic format as in the generic_magic example data file. \n", "\n", "To import the generic file format, use **convert.generic()**.\n"]}, {"block": 100, "type": "code", "linesLength": 1, "startIndex": 419, "lines": ["help(convert.generic)"]}, {"block": 101, "type": "code", "linesLength": 2, "startIndex": 420, "lines": ["convert.generic(magfile='data_files/convert_2_magic/generic_magic/generic_magic_example.txt',\n", "                experiment='PI',dir_path='data_files/convert_2_magic/generic_magic')"]}, {"block": 102, "type": "code", "linesLength": 3, "startIndex": 422, "lines": ["# let's take a look\n", "dir_path='data_files/convert_2_magic/generic_magic/'\n", "ipmag.zeq_magic(input_dir_path=dir_path, save_plots=False)"]}, {"block": 103, "type": "markdown", "linesLength": 5, "startIndex": 425, "lines": ["### huji_magic \n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#huji_magic.py)\n", "\n", "To import the Hebrew University, Jerusalem, Israel file format to MagIC, use **convert.huji()**.   "]}, {"block": 104, "type": "code", "linesLength": 1, "startIndex": 430, "lines": ["help(convert.huji)"]}, {"block": 105, "type": "code", "linesLength": 3, "startIndex": 431, "lines": ["dir_path='data_files/convert_2_magic/huji_magic/'\n", "convert.huji(dir_path=dir_path,\n", "             magfile='Massada_AF_HUJI_new_format.txt',codelist='T')"]}, {"block": 106, "type": "code", "linesLength": 1, "startIndex": 434, "lines": ["ipmag.zeq_magic(input_dir_path=dir_path, save_plots=False, n_plots=10)"]}, {"block": 107, "type": "markdown", "linesLength": 6, "startIndex": 435, "lines": ["### huji_sample_magic\n", "\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#huji_sample_magic.py)\n", "\n", "To convert a Hebrew University Jersalem, Israel sample format to MagIC, use **convert.huji_sample()**.  "]}, {"block": 108, "type": "code", "linesLength": 1, "startIndex": 441, "lines": ["help(convert.huji_sample)"]}, {"block": 109, "type": "code", "linesLength": 2, "startIndex": 442, "lines": ["convert.huji_sample('magdelkrum_datafile.txt',\n", "                   dir_path='data_files/convert_2_magic/huji_magic/')"]}, {"block": 110, "type": "code", "linesLength": 1, "startIndex": 444, "lines": ["help(ipmag.combine_magic)"]}, {"block": 111, "type": "markdown", "linesLength": 3, "startIndex": 445, "lines": ["### iodp_dscr_lore\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#iodp_dscr_magic.py)"]}, {"block": 112, "type": "code", "linesLength": 5, "startIndex": 448, "lines": ["# first, generate specimens/samples/sites/locations files\n", "convert.iodp_samples_csv('data_files/iodp_magic/U999A/samples_17_5_2019.csv')\n", "# then, convert IODP discrete measurement files into measurements files\n", "convert.iodp_dscr_lore(\"data_files/iodp_magic/U999A/SRM_discrete_data/srmdiscrete_17_5_2019.csv\")\n", "pmag.remove_files([\"measurements.txt\", \"specimens.txt\", \"samples.txt\", \"sites.txt\", \"locations.txt\"])"]}, {"block": 113, "type": "markdown", "linesLength": 2, "startIndex": 453, "lines": ["### iodp_jr6_lore\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#iodp_jr6_magic.py)"]}, {"block": 114, "type": "code", "linesLength": 5, "startIndex": 455, "lines": ["# first, generate specimens/samples/sites/locations files\n", "convert.iodp_samples_csv('data_files/iodp_magic/U999A/samples_17_5_2019.csv')\n", "# then, convert IODP discrete measurement files into measurements files\n", "convert.iodp_jr6_lore(\"data_files/iodp_magic/U999A/JR6_data/spinner_17_5_2019.csv\")\n", "pmag.remove_files([\"measurements.txt\", \"specimens.txt\", \"samples.txt\", \"sites.txt\", \"locations.txt\"])"]}, {"block": 115, "type": "markdown", "linesLength": 2, "startIndex": 460, "lines": ["### iodp_srm_lore\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#iodp_srm_magic.py)"]}, {"block": 116, "type": "code", "linesLength": 1, "startIndex": 462, "lines": ["convert.iodp_srm_lore(\"data_files/iodp_magic/U999A/SRM_archive_data/srmsection_17_5_2019.csv\")"]}, {"block": 117, "type": "markdown", "linesLength": 5, "startIndex": 463, "lines": ["### jr6_jr6_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#jr6_jr6_magic.py)\n", "\n", "The AGICO JR6 spinner magnetometer has two output formats, the .jr6 and the .txt.  Here we illustrate the conversion of the .jr6 format.  There are data from two different studies in the example folder.  One (from Anita di Chiara) has the suffix '.JR6' and the other (from Roi Granot) are lower case (.jr6'). Each file has the data from a single specimen's experiment.  So, we can convert Anita's data to a series of MagIC formatted measurement files, combine them with [ipmag.combine_magic](#ipmag.combine_magic) and look at them with Demag GUI (on the command line) or [zeq_magic](#zeq_magic) within the notebook. \n"]}, {"block": 118, "type": "code", "linesLength": 1, "startIndex": 468, "lines": ["help(convert.jr6_jr6)"]}, {"block": 119, "type": "markdown", "linesLength": 2, "startIndex": 469, "lines": ["\n", "Let's start with Anita's files"]}, {"block": 120, "type": "code", "linesLength": 24, "startIndex": 471, "lines": ["dir_path='data_files/convert_2_magic/jr6_magic/'\n", "files=os.listdir(dir_path)\n", "meas_files,spec_files,samp_files,site_files=[],[],[],[]\n", "for file in files:\n", "    if '.JR6' in file:\n", "        print (file)\n", "        stem=file.split('.')[0]\n", "        meas_file=stem+'_measurements.txt' # make a unique measurements file\n", "        spec_file=stem+'_specimens.txt'\n", "        samp_file=stem+'_samples.txt'\n", "        site_file=stem+'_sites.txt'\n", "        convert.jr6_jr6(file,dir_path=dir_path,\n", "                        meas_file=meas_file,spec_file=spec_file,samp_file=samp_file,\n", "                        site_file=site_file,user='Anita')\n", "        meas_files.append(dir_path+meas_file) # save the file name to a list\n", "        spec_files.append(dir_path+spec_file)\n", "        samp_files.append(dir_path+samp_file)\n", "        site_files.append(dir_path+site_file)\n", "\n", "# combine the files\n", "ipmag.combine_magic(meas_files,dir_path+'measurements.txt')\n", "ipmag.combine_magic(spec_files,dir_path+'specimens.txt',magic_table='specimens')\n", "ipmag.combine_magic(samp_files,dir_path+'samples.txt',magic_table='samples')\n", "ipmag.combine_magic(site_files,dir_path+'sites.txt',magic_table='sites')\n"]}, {"block": 121, "type": "code", "linesLength": 1, "startIndex": 495, "lines": ["ipmag.zeq_magic(input_dir_path=dir_path, save_plots=False)"]}, {"block": 122, "type": "markdown", "linesLength": 1, "startIndex": 496, "lines": ["Now we can do Roi's files"]}, {"block": 123, "type": "code", "linesLength": 23, "startIndex": 497, "lines": ["dir_path='data_files/convert_2_magic/jr6_magic/'\n", "files=os.listdir(dir_path)\n", "meas_files,spec_files,samp_files,site_files=[],[],[],[]\n", "for file in files:\n", "    if file.endswith('.jr6'):\n", "        stem=file.split('.')[0]\n", "        meas_file=stem+'_measurements.txt' # make a unique measurements file\n", "        spec_file=stem+'_specimens.txt'\n", "        samp_file=stem+'_samples.txt'\n", "        site_file=stem+'_sites.txt'\n", "        convert.jr6_jr6(file,dir_path=dir_path,\n", "                        meas_file=meas_file,spec_file=spec_file,samp_file=samp_file,\n", "                        site_file=site_file,user='Roi')\n", "        meas_files.append(dir_path+meas_file) # save the file name to a list\n", "        spec_files.append(dir_path+spec_file)\n", "        samp_files.append(dir_path+samp_file)\n", "        site_files.append(dir_path+site_file)\n", "\n", "# combine the files\n", "ipmag.combine_magic(meas_files,dir_path+'measurements.txt')\n", "ipmag.combine_magic(spec_files,dir_path+'specimens.txt',magic_table='specimens')\n", "ipmag.combine_magic(samp_files,dir_path+'samples.txt',magic_table='samples')\n", "ipmag.combine_magic(site_files,dir_path+'sites.txt',magic_table='sites')\n"]}, {"block": 124, "type": "code", "linesLength": 1, "startIndex": 520, "lines": ["ipmag.zeq_magic(input_dir_path=dir_path, save_plots=False)"]}, {"block": 125, "type": "markdown", "linesLength": 5, "startIndex": 521, "lines": ["### jr6_txt_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#jr6_txt_magic.py)\n", "\n", "We can repeat the exercise for the JR6 .txt format using **convert.jr6_txt()**.  "]}, {"block": 126, "type": "code", "linesLength": 1, "startIndex": 526, "lines": ["help(convert.jr6_txt)"]}, {"block": 127, "type": "markdown", "linesLength": 1, "startIndex": 527, "lines": ["There are only data from Roi Granot in this format. The measurement values should be identical to the **convert.jr6_jr6()** function on .jr6 files with the same stem. Additional columns will be found when converting the .JR6 format as that format contains more information than the .txt files."]}, {"block": 128, "type": "code", "linesLength": 23, "startIndex": 528, "lines": ["dir_path='data_files/convert_2_magic/jr6_magic/'\n", "files=['AF.txt','TRM.txt','AP12.txt']\n", "meas_files,spec_files,samp_files,site_files=[],[],[],[]\n", "for file in files:\n", "        print (file)\n", "        stem=file.split('.')[0]\n", "        meas_file=stem+'_measurements.txt' # make a unique measurements file\n", "        spec_file=stem+'_specimens.txt'\n", "        samp_file=stem+'_samples.txt'\n", "        site_file=stem+'_sites.txt'\n", "        convert.jr6_txt(file,dir_path=dir_path,\n", "                        meas_file=meas_file,spec_file=spec_file,samp_file=samp_file,\n", "                        site_file=site_file,user='Roi')\n", "        meas_files.append(dir_path+meas_file) # save the file name to a list\n", "        spec_files.append(dir_path+spec_file)\n", "        samp_files.append(dir_path+samp_file)\n", "        site_files.append(dir_path+site_file)\n", "\n", "# combine the files\n", "ipmag.combine_magic(meas_files,dir_path+'measurements.txt')\n", "ipmag.combine_magic(spec_files,dir_path+'specimens.txt',magic_table='specimens')\n", "ipmag.combine_magic(samp_files,dir_path+'samples.txt',magic_table='samples')\n", "ipmag.combine_magic(site_files,dir_path+'sites.txt',magic_table='sites')"]}, {"block": 129, "type": "code", "linesLength": 1, "startIndex": 551, "lines": ["ipmag.zeq_magic(meas_file='AP12_measurements.txt',input_dir_path=dir_path, save_plots=False)"]}, {"block": 130, "type": "markdown", "linesLength": 7, "startIndex": 552, "lines": ["### k15_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#k15_magic.py)\n", "\n", "Someone took a set of samples from a dike margin in the Troodos Ophiolite and measured their anisotropy of magnetic susceptibility on an a Kappabridge KLY 2.0 instrument in the SIO laboratory.  An example of the  data file format is in k15_magic.  \n", "\n", "The first line of each set of four has the specimen name, azimuth, plunge, and bedding strike and dip the next three lines are sets of five measurements in the 15 positions recommended by Jelinek (1977): \n"]}, {"block": 131, "type": "code", "linesLength": 1, "startIndex": 559, "lines": ["Image('data_files/Figures/meas15.png')"]}, {"block": 132, "type": "markdown", "linesLength": 3, "startIndex": 560, "lines": ["The 15 measurements for each specimen, along with orientation information and the specimen name were saved in the file data_files/k15_magic/k15_example.dat. \n", "\n", "To convert 15 measurement anisotropy of magnetic susceptibility file format to MagIC,   use **convert.k15()**. "]}, {"block": 133, "type": "code", "linesLength": 1, "startIndex": 563, "lines": ["help(convert.k15)"]}, {"block": 134, "type": "code", "linesLength": 2, "startIndex": 564, "lines": ["convert.k15('k15_example.dat',dir_path='data_files/convert_2_magic/k15_magic/',\n", "            location='Troodos Ophiolite')"]}, {"block": 135, "type": "code", "linesLength": 1, "startIndex": 566, "lines": ["ipmag.aniso_magic_nb(infile='specimens.txt',dir_path='data_files/convert_2_magic/k15_magic/') "]}, {"block": 136, "type": "markdown", "linesLength": 19, "startIndex": 567, "lines": ["### kly4s_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#kly4s_magic.py)\n", "\n", " The program AMSSpin available for downloading from http://earthref.org/ERDA/940/ generates data for the Kappabridge KLY4S spinning magnetic susceptibility instrument as described by Gee et al. (2008).\n", "\n", "\n", "\n", "Output files are in the format of the file KLY4S_magic_example.dat (found in the measurement_import/kly4s_magic folder). \n", "\n", "The columns in the example file are:\n", "\n", "Specimen S_1 S_2 S_3 S_4 S_5 S_6 \u03c7b(\u03bcSI) date time user\n", "\n", "\n", "\n", "\n", "To convert the Agico Kappabridge KLY4S files generated by the SIO labview program (written by Jeff Gee), use **convert.kly4s()**. \n", "This function will create the files needed by the MagIC database and the data can be plotted using [aniso_magic](#aniso_magic).   If you were to import the sample files from the LIMS data base for these samples, you could plot them versus depth, or as equal area projections using **ani_depthplot** and **aniso_magic** respectively. \n"]}, {"block": 137, "type": "code", "linesLength": 1, "startIndex": 586, "lines": ["help(convert.kly4s)"]}, {"block": 138, "type": "code", "linesLength": 2, "startIndex": 587, "lines": ["convert.kly4s('KLY4S_magic_example.dat',\n", "              dir_path='data_files/convert_2_magic/kly4s_magic/')"]}, {"block": 139, "type": "code", "linesLength": 1, "startIndex": 589, "lines": ["ipmag.aniso_magic(infile='specimens.txt',dir_path='data_files/convert_2_magic/kly4s_magic/', save_plots=False) "]}, {"block": 140, "type": "markdown", "linesLength": 7, "startIndex": 590, "lines": ["### ldeo_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#ldeo_magic.py)\n", "\n", "To convert Lamont-Doherty Earth Observatory data files to MagIC, use **convert.ldeo()**. \n", "\n", "NB:  this doesn't seem to work properly at all.  "]}, {"block": 141, "type": "code", "linesLength": 1, "startIndex": 597, "lines": ["help(convert.ldeo)"]}, {"block": 142, "type": "code", "linesLength": 2, "startIndex": 598, "lines": ["convert.ldeo('ldeo_magic_example.dat',codelist='AF',\n", "             dir_path='data_files/convert_2_magic/ldeo_magic/')"]}, {"block": 143, "type": "code", "linesLength": 1, "startIndex": 600, "lines": ["ipmag.zeq_magic(input_dir_path='data_files/convert_2_magic/ldeo_magic/', save_plots=False)"]}, {"block": 144, "type": "markdown", "linesLength": 8, "startIndex": 601, "lines": ["### livdb_magic \n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#livdb_magic.py)\n", "\n", "To convert the Liverpool university database  format to MagIC use **convert.livdb()**.  \n", "\n", "Here we have several experiment types as examples as examples.  \n", "\n"]}, {"block": 145, "type": "code", "linesLength": 1, "startIndex": 609, "lines": ["help(convert.livdb)"]}, {"block": 146, "type": "markdown", "linesLength": 1, "startIndex": 610, "lines": ["Here's an example for an IZZI style, thermal experiment:"]}, {"block": 147, "type": "code", "linesLength": 3, "startIndex": 611, "lines": ["convert.livdb('data_files/convert_2_magic/livdb_magic/TH_IZZI+/',\n", "             output_dir_path='data_files/convert_2_magic/livdb_magic/TH_IZZI+',\n", "             site_name_con=2,site_num_chars=3)"]}, {"block": 148, "type": "code", "linesLength": 2, "startIndex": 614, "lines": ["ipmag.thellier_magic(input_dir_path='data_files/convert_2_magic/livdb_magic/TH_IZZI+', \n", "                     save_plots=False, interactive=False, n_specs=5)"]}, {"block": 149, "type": "markdown", "linesLength": 1, "startIndex": 616, "lines": ["here's one for microwave \"C+\" experiment"]}, {"block": 150, "type": "code", "linesLength": 3, "startIndex": 617, "lines": ["convert.livdb('data_files/convert_2_magic/livdb_magic/MW_C+/',\n", "             output_dir_path='data_files/convert_2_magic/livdb_magic/MW_C+',\n", "             site_name_con=2,site_num_chars=3)"]}, {"block": 151, "type": "markdown", "linesLength": 1, "startIndex": 620, "lines": ["An example for both microwave IZZI and C++:"]}, {"block": 152, "type": "code", "linesLength": 3, "startIndex": 621, "lines": ["convert.livdb('data_files/convert_2_magic/livdb_magic/MW_IZZI+andC++/',\n", "             output_dir_path='data_files/convert_2_magic/livdb_magic/MW_IZZI+andC++',\n", "             samp_name_con='2', samp_num_chars=1,site_name_con=2,site_num_chars=1)"]}, {"block": 153, "type": "markdown", "linesLength": 1, "startIndex": 624, "lines": ["An example for both microwave OT+:"]}, {"block": 154, "type": "code", "linesLength": 3, "startIndex": 625, "lines": ["convert.livdb('data_files/convert_2_magic/livdb_magic/MW_OT+/',\n", "             output_dir_path='data_files/convert_2_magic/livdb_magic/MW_OT+',\n", "             site_name_con=2,site_num_chars=3)"]}, {"block": 155, "type": "markdown", "linesLength": 1, "startIndex": 628, "lines": ["And an example for MW_P experiments.   "]}, {"block": 156, "type": "code", "linesLength": 3, "startIndex": 629, "lines": ["convert.livdb('data_files/convert_2_magic/livdb_magic/MW_P/',\n", "             output_dir_path='data_files/convert_2_magic/livdb_magic/MW_P',\n", "             site_name_con=2,site_num_chars=3)"]}, {"block": 157, "type": "markdown", "linesLength": 1, "startIndex": 632, "lines": ["Now you can look at these data (except for MW_P) with thellier_gui or [thellier_magic](#thellier_magic)."]}, {"block": 158, "type": "markdown", "linesLength": 5, "startIndex": 633, "lines": ["### mst_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#mst_magic.py)\n", "\n", "To convert a Curie Temperature experiment to MagIC, use **convert.mst()**.  The data file format should be a space delimited file with temperature and magnetization couplets.   "]}, {"block": 159, "type": "code", "linesLength": 1, "startIndex": 638, "lines": ["help(convert.mst)"]}, {"block": 160, "type": "code", "linesLength": 2, "startIndex": 639, "lines": ["convert.mst('curie_example.dat',samp_con=\"5\",\n", "           dir_path='data_files/convert_2_magic/mst_magic/')"]}, {"block": 161, "type": "markdown", "linesLength": 1, "startIndex": 641, "lines": ["We can now use [curie](#curie) to plot the data. "]}, {"block": 162, "type": "code", "linesLength": 1, "startIndex": 642, "lines": ["ipmag.curie(path_to_file='data_files/convert_2_magic/mst_magic/',file_name='measurements.txt',magic=True)"]}, {"block": 163, "type": "markdown", "linesLength": 10, "startIndex": 643, "lines": ["### pmd_magic \n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#pmd_magic.py)\n", "\n", " This format is the one used to import .PMD formatted magnetometer files (used for example in the PaleoMac software of Cogn\u00e9, 2003) into the MagIC format. (See http://www.ipgp.fr/~cogne/pub/paleomac/PMhome.html for the PaleoMac home page. The version of these files that **pmd_magic** expects (UCSC version) contains demagnetization data for a single specimen and has a format as in the example file in ../measurement_import/pmd_magic/PMD/ss0207a.pmd\n", "\n", "\n", "The first line is a comment line. The second line has the specimen name, the core azimuth (a=) and plunge (b=) which are assumed to be the lab arrow azimuth and plunge (Orientation scheme #4)D. The third line is a header explaining the columns in the file.\n", "\n", "Use **convert.pmd()**  to convert the file ss0101a.pmd in the directory \u2019PMD\u2019 in the \u2019pmd_magic\u2019 folder of the measurement_import directory in the example data_files directory. These were taken at a location named \u2019Summit Springs\u2019 and have a naming convention of the type XXXX[YYY], where YYY is sample designation with Z characters from site XXX, or naming convention # 4-2. A single character distinguishes the specimen from the sample (specnum=1). All samples were oriented with a magnetic compass. "]}, {"block": 164, "type": "code", "linesLength": 1, "startIndex": 653, "lines": ["help(convert.pmd)"]}, {"block": 165, "type": "code", "linesLength": 2, "startIndex": 654, "lines": ["convert.pmd('ss0207a.pmd',dir_path='data_files/convert_2_magic/pmd_magic/PMD/',\n", "           samp_con='4-2',location='Summit Springs',specnum=1)"]}, {"block": 166, "type": "markdown", "linesLength": 9, "startIndex": 656, "lines": ["### sio_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#sio_magic.py)\n", "\n", "This program allows conversion of the SIO format magnetometer files to the MagIC common measurements format. The columns in the example data file are: \n", "\n", "Specimen treatment intensity declination inclination optional_string \n", "\n", "The treatment field is the temperature (in centigrade), the AF field (in mT), the impulse field strength, etc. For special experiments like IRM acquisition, the coil number of the popular ASC impulse magnetizer can be specified if the treatment steps are in volts. The position for anisotropy experiments or whether the treatment is \u201cin-field\u201d or in zero field also require special formatting. The units of the intensity field are in cgs and the directions are relative to the \u2018lab arrow\u2019 on the specimen. Here are some examples of commonly used specimens and conversions from field arrow to lab arrow. "]}, {"block": 167, "type": "code", "linesLength": 1, "startIndex": 665, "lines": ["Image('data_files/Figures/samples.png')"]}, {"block": 168, "type": "markdown", "linesLength": 3, "startIndex": 666, "lines": ["As an example, we use data from Sbarbori et al. (2009) done on a set of samples from the location \u201cSocorro\u201d, including AF, thermal, and thellier experimental data. These were saved in sio_af_example.dat, sio_thermal_example.dat, and sio_thellier_example.dat respectively. The lab field for the thellier experiment was 25 \u03bcT and was applied along the specimen\u2019s Z axis (phi=0,theta=90).] \n", "\n", "We can convert the example files into measurement formatted files with names like af_measurements.txt, etc. using the function **convert.sio()**.   Then combine them together following the instructions for  [combine_magic](#combine_magic).   "]}, {"block": 169, "type": "code", "linesLength": 1, "startIndex": 669, "lines": ["help(convert.sio)"]}, {"block": 170, "type": "code", "linesLength": 4, "startIndex": 670, "lines": ["convert.sio('sio_af_example.dat',dir_path='data_files/convert_2_magic/sio_magic/',\n", "           specnum=1,location='Isla Soccoro',codelist='AF',samp_con='1',\n", "           meas_file='af_measurements.txt',spec_file='af_specimens.txt',\n", "           samp_file='af_samples.txt',site_file='af_sites.txt')"]}, {"block": 171, "type": "code", "linesLength": 4, "startIndex": 674, "lines": ["convert.sio('sio_thermal_example.dat',dir_path='data_files/convert_2_magic/sio_magic/',\n", "            specnum=1,location='Isla Soccoro',codelist='T',\n", "            meas_file='thermal_measurements.txt',spec_file='thermal_specimens.txt',\n", "            samp_file='thermal_samples.txt',site_file='thermal_sites.txt')"]}, {"block": 172, "type": "markdown", "linesLength": 1, "startIndex": 678, "lines": ["And combine them together... "]}, {"block": 173, "type": "code", "linesLength": 12, "startIndex": 679, "lines": ["# combine the measurements files\n", "measfiles=['data_files/convert_2_magic/sio_magic/af_measurements.txt',\n", "           'data_files/convert_2_magic/sio_magic/thermal_measurements.txt']\n", "ipmag.combine_magic(measfiles,'data_files/convert_2_magic/sio_magic/measurements.txt')\n", "\n", "specfiles=['data_files/convert_2_magic/sio_magic/af_specimens.txt',\n", "           'data_files/convert_2_magic/sio_magic/thermal_specimens.txt']\n", "ipmag.combine_magic(specfiles,'data_files/convert_2_magic/sio_magic/specimens.txt', magic_table='specimens')\n", "\n", "sitefiles=['data_files/convert_2_magic/sio_magic/af_sites.txt',\n", "           'data_files/convert_2_magic/sio_magic/thermal_sites.txt']\n", "ipmag.combine_magic(sitefiles,'data_files/convert_2_magic/sio_magic/sites.txt',magic_table='sites')\n"]}, {"block": 174, "type": "markdown", "linesLength": 5, "startIndex": 691, "lines": ["### sufar4_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#sufar4_asc_magic.py)\n", "\n", "The AGICO program SUFAR creates ascii txt files as output.  **convert.sufar4()** will convert these to the MagIC format."]}, {"block": 175, "type": "code", "linesLength": 1, "startIndex": 696, "lines": ["help(convert.sufar4)"]}, {"block": 176, "type": "code", "linesLength": 2, "startIndex": 697, "lines": ["convert.sufar4('sufar4-asc_magic_example.txt',dir_path='data_files/convert_2_magic/sufar_asc_magic/',\n", "              sample_naming_con='5',locname='U1356A')"]}, {"block": 177, "type": "markdown", "linesLength": 1, "startIndex": 699, "lines": ["Now we can test it out with, for example, [ipmag.aniso_magic_nb()](#aniso_magic)"]}, {"block": 178, "type": "code", "linesLength": 1, "startIndex": 700, "lines": ["ipmag.aniso_magic_nb(infile='data_files/convert_2_magic/sufar_asc_magic/specimens.txt')"]}, {"block": 179, "type": "markdown", "linesLength": 5, "startIndex": 701, "lines": ["### tdt_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#tdt_magic.py)\n", "\n", "Convertions of the Thellier Tool format of Leonhardt et al., 2004 can be done with **convert.tdt()**.  THERE IS A PROBLEM WITH THE XXX.4 TREATMENT STEP CONVERSION.  "]}, {"block": 180, "type": "code", "linesLength": 1, "startIndex": 706, "lines": ["help(convert.tdt)"]}, {"block": 181, "type": "code", "linesLength": 1, "startIndex": 707, "lines": ["convert.tdt('data_files/convert_2_magic/tdt_magic/')"]}, {"block": 182, "type": "markdown", "linesLength": 3, "startIndex": 708, "lines": ["### utrecht_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#utrecht_magic.py)\n"]}, {"block": 183, "type": "code", "linesLength": 1, "startIndex": 711, "lines": ["help(convert.utrecht)"]}, {"block": 184, "type": "code", "linesLength": 2, "startIndex": 712, "lines": ["convert.utrecht('Utrecht_Example.af',dir_path='data_files/convert_2_magic/utrecht_magic',\n", "               specnum=0,samp_con='3')"]}, {"block": 185, "type": "markdown", "linesLength": 6, "startIndex": 714, "lines": ["### orientation_magic\n", "\n", "[\\[Preparing for MagIC\\]](https://earthref.org/PmagPy/cookbook/#QQ2-1-25) [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#orientation_magic.py)\n", "\n", "**orientation_magic** is meant to import the field book data as entered into the format like in  orientation_example.txt into the MagIC format samples, sites and location tables.  \n", "Click [here](https://earthref.org/PmagPy/cookbook/#field_info)  for details about the orient.txt file format. The example file used here has field information for a few sites. The samples were oriented with a Pomeroy orientation device (the default) and it is desirable to calculate the magnetic declination from the IGRF at the time of sampling (also the default). Sample names follow the rule that the sample is designated by a letter at the end of the site name (convention \\#1 - which is also the default). We can do this from within a notebook by calling  **ipmag.orientation_magic()**.\n"]}, {"block": 186, "type": "code", "linesLength": 1, "startIndex": 720, "lines": ["help(ipmag.orientation_magic)"]}, {"block": 187, "type": "markdown", "linesLength": 1, "startIndex": 721, "lines": [" We need to know which orientation convention was used to take the samples (it was with a Pomeroy, so, the default).  We want to use the igrf calculated magnetic declination at each site (so dec_correction_con=1, the default).  These samples were collected in Antarctica with a local time of GMT+13, so we need to subtract 13 hours so hours_from_gmt should be 13.  we are using data model 3.0 for this notebook, so data_model=3.  Also, input_dir_path and output_dir_path are both ../orientation_magic.  "]}, {"block": 188, "type": "code", "linesLength": 2, "startIndex": 722, "lines": ["ipmag.orientation_magic(input_dir_path='data_files/orientation_magic',orient_file='orient_example.txt',\n", "                        hours_from_gmt=13,data_model=3,output_dir_path='data_files/orientation_magic')"]}, {"block": 189, "type": "markdown", "linesLength": 8, "startIndex": 724, "lines": ["### azdip_magic\n", "\n", "[\\[MagIC Database\\]](https://earthref.org/MagIC)  [\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#azdip_magic.py)\n", "\n", "Many paleomagnetists save orientation information in files in this format: Sample Azimuth Plunge Strike Dip (AZDIP format), where the Azimuth and Plunge are the declination and inclination of the drill direction and the strike and dip are the attitude of the sampled unit (with dip to the right of strike). Of course there are many ways to think about sample orientation and the MagIC database convention is to store the direction of the X coordinate of the specimen measurements. To convert an AzDip formatted file (example in data_files/azdip_magic/azdip_magic_example.dat), we can use **ipmag.azdip_magic()**.  \n", "\n", "\n", "\n"]}, {"block": 190, "type": "code", "linesLength": 1, "startIndex": 732, "lines": ["help(ipmag.azdip_magic)"]}, {"block": 191, "type": "markdown", "linesLength": 2, "startIndex": 733, "lines": ["The method_codes are important. If you don't specify any sample orientation method, for example, the program will assume that they are unoriented.  Pick the appropriate method codes for field sampling (FS-) and sample orientation (SO-) from the lists here:  https://www2.earthref.org/MagIC/method-codes\n", "\n"]}, {"block": 192, "type": "code", "linesLength": 2, "startIndex": 735, "lines": ["ipmag.azdip_magic(orient_file='azdip_magic_example.dat',input_dir='data_files/azdip_magic/',\n", "                  output_dir='data_files/azdip_magic/', method_codes='FS-FD:SO-MAG')"]}, {"block": 193, "type": "markdown", "linesLength": 1, "startIndex": 737, "lines": ["## Other handy scripts"]}, {"block": 194, "type": "markdown", "linesLength": 5, "startIndex": 738, "lines": ["### chartmaker\n", "\n", "[\\[command line version\\]](https://pmagpy.github.io/PmagPy-cli.html#chartmaker.py)\n", "\n", "Chartmaker makes a chart like this: "]}, {"block": 195, "type": "code", "linesLength": 1, "startIndex": 743, "lines": ["Image('data_files/Figures/chartmaker.png')"]}, {"block": 196, "type": "markdown", "linesLength": 3, "startIndex": 744, "lines": ["You can print it out and tape it to the oven in the lab to help keep track of this annoyingly complicated experiment.  :)  \n", "\n", "To make this from within a notebook, call **pmag.chart_maker()**. "]}, {"block": 197, "type": "code", "linesLength": 1, "startIndex": 747, "lines": ["help(pmag.chart_maker)"]}, {"block": 198, "type": "markdown", "linesLength": 1, "startIndex": 748, "lines": ["To perform 50 degree intervals from 100 to 500, followed by 10 degree intervals from 500 to 600 set up the Int and Top lists like this:"]}, {"block": 199, "type": "code", "linesLength": 2, "startIndex": 749, "lines": ["Int=[50,10]\n", "Top=[500,600]"]}, {"block": 200, "type": "code", "linesLength": 1, "startIndex": 751, "lines": ["pmag.chart_maker(Int,Top)"]}, {"block": 201, "type": "markdown", "linesLength": 1, "startIndex": 752, "lines": ["You can now print out chart.txt.  Happy IZZI-ing.  "]}, {"block": 202, "type": "markdown", "linesLength": 1, "startIndex": 753, "lines": ["## Clean up"]}, {"block": 203, "type": "code", "linesLength": 62, "startIndex": 754, "lines": ["import glob\n", "import os\n", "# remove some individual files\n", "\n", "filenames = ['chart.txt',\n", "            'data_files/azdip_magic/samples.txt', 'data_files/download_magic/criteria.txt', \n", "            'data_files/orientation_magic/samples.txt', 'data_files/orientation_magic/sites.txt',\n", "            'data_files/download_magic/ages.txt', 'data_files/download_magic/contribution.txt', \n", "            'data_files/download_magic/measurements.txt', 'data_files/download_magic/samples.txt',\n", "            'data_files/download_magic/specimens.txt', 'data_files/download_magic/locations.txt']\n", "\n", "\n", "for fname in filenames:\n", "    try:\n", "        os.remove(fname)\n", "    except FileNotFoundError:\n", "        pass\n", "  \n", "\n", "# remove all MagIC-generated files from a given directory\n", "\n", "def remove_magic_files(directory):\n", "    magic_files = ['specimens.txt', 'samples.txt', 'sites.txt', 'locations.txt', 'measurements.txt', \n", "                   'contribution.txt', 'ages.txt']\n", "    dir_files = os.listdir(directory)\n", "    for dtype in magic_files:\n", "        try:\n", "            os.remove(dtype)\n", "        except FileNotFoundError:\n", "            pass\n", "        for fname in dir_files:\n", "            if fname.endswith(dtype):\n", "                try:\n", "                    os.remove(os.path.join(directory, fname))\n", "                except FileNotFoundError:\n", "                    pass\n", "    for full_fname in glob.glob(os.path.join(directory, '*.magic')):\n", "        os.remove(full_fname)\n", "        \n", "        \n", "        \n", "# not convert_2_magic/jr6_magic\n", "\n", "for directory in ['.', 'data_files/convert_2_magic/2g_bin_magic/mn1', 'data_files/convert_2_magic/pmd_magic/PMD/',\n", "                  'data_files', 'data_files/k15_s', 'data_files/convert_2_magic/agm_magic', \n", "                  'data_files/convert_2_magic/huji_magic', 'data_files/convert_2_magic/bgc_magic',\n", "                  'data_files/convert_2_magic/kly4s_magic', 'data_files/convert_2_magic/mst_magic',\n", "                  'data_files/convert_ages', 'data_files/convert_2_magic/cit_magic/MIT/7325B',\n", "                  'data_files/convert_2_magic/cit_magic/USGS/bl9-1', 'data_files/convert_2_magic/tdt_magic',\n", "                  'data_files/convert_2_magic/ldeo_magic', 'data_files/convert_2_magic/k15_magic',\n", "                  'data_files/convert_2_magic/generic_magic']:\n", "    remove_magic_files(directory)\n", "\n", "\n", "lst = ['*.png', './data_files/convert_2_magic/jr6_magic/SML*.txt', './data_files/download_magic/Snake*',\n", "      './data_files/convert_2_magic/jr6_magic/AP12_*.txt', \n", "      './data_files/convert_2_magic/jr6_magic/*_measurements.txt', './data_files/convert_2_magic/jr6_magic/*.magic',\n", "      './data_files/3_0/McMurdo/*.tex', './data_files/3_0/McMurdo/*.xls', './data_files/3_0/Megiddo/*.tex',\n", "      'data_files/3_0/Megiddo/*.xls', \"./srm_arch*\"]\n", "for directory in lst:\n", "    for fname in glob.glob(directory):\n", "        os.remove(fname)  "]}, {"block": 204, "type": "code", "linesLength": 0, "startIndex": 816, "lines": []}]