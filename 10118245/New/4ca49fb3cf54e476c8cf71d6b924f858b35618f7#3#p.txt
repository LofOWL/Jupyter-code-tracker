[{"block": 0, "type": "markdown", "linesLength": 5, "startIndex": 0, "lines": ["<style>div.title-slide {    width: 100%;    display: flex;    flex-direction: row;            /* default value; can be omitted */    flex-wrap: nowrap;              /* default value; can be omitted */    justify-content: space-between;}</style><div class=\"title-slide\">\n", "<span style=\"float:left;\">Licence CC BY-NC-ND</span>\n", "<span>Thierry Parmentelat &amp; Arnaud Legout</span>\n", "<span><img src=\"media/both-logos-small-alpha.png\" style=\"display:inline\" /></span>\n", "</div>"]}, {"block": 1, "type": "markdown", "linesLength": 2, "startIndex": 5, "lines": ["\n", "# Op\u00e9ration avanc\u00e9es en pandas"]}, {"block": 2, "type": "markdown", "linesLength": 1, "startIndex": 7, "lines": ["## Compl\u00e9ment - niveau interm\u00e9diaire"]}, {"block": 3, "type": "markdown", "linesLength": 1, "startIndex": 8, "lines": ["### Introduction"]}, {"block": 4, "type": "markdown", "linesLength": 5, "startIndex": 9, "lines": ["Pandas supporte des op\u00e9rations de manipulation des `Series` et `DataFrame` qui sont similaires dans l'esprit \u00e0 ce que l'on peut faire avec une base de donn\u00e9es et le langage SQL, mais de mani\u00e8re plus intuitive et expressive et beaucoup plus efficacement puisque les op\u00e9rations se d\u00e9roulent toutes en m\u00e9moire.\n", "\n", "Vous pouvez concat\u00e9ner (`concat`) des `DataFrame`, faire des jointures (`merge`), faire des regroupements (`groupby`) ou r\u00e9organiser les indexes (`pivot`).\n", "\n", "Nous allons dans la suite d\u00e9velopper ces diff\u00e9rentes techniques."]}, {"block": 5, "type": "code", "linesLength": 2, "startIndex": 14, "lines": ["import numpy as np\n", "import pandas as pd"]}, {"block": 6, "type": "markdown", "linesLength": 1, "startIndex": 16, "lines": ["### Concat\u00e9nations avec `concat`"]}, {"block": 7, "type": "markdown", "linesLength": 1, "startIndex": 17, "lines": ["`concat` est utilis\u00e9 pour concat\u00e9ner des `Series` ou des `DataFrame`. Regardons un exemple."]}, {"block": 8, "type": "code", "linesLength": 2, "startIndex": 18, "lines": ["s1 = pd.Series([30, 35], index=['alice', 'bob'])\n", "s2 = pd.Series([32, 22, 29], index=['bill', 'alice', 'jo'])"]}, {"block": 9, "type": "code", "linesLength": 1, "startIndex": 20, "lines": ["s1"]}, {"block": 10, "type": "code", "linesLength": 1, "startIndex": 21, "lines": ["s2"]}, {"block": 11, "type": "code", "linesLength": 1, "startIndex": 22, "lines": ["pd.concat([s1, s2])"]}, {"block": 12, "type": "markdown", "linesLength": 1, "startIndex": 23, "lines": ["On remarque, cependant, que par d\u00e9faut il n'y a pas de contr\u00f4le sur les labels d'index dupliqu\u00e9s. On peut corriger cela avec l'argument `verify_integrity`, qui va produire une exception s'il y a des labels d'index communs. \u00c9videmment, cela a un co\u00fbt de calcul suppl\u00e9mentaire, \u00e7a n'est donc \u00e0 utiliser que si c'est n\u00e9cessaire."]}, {"block": 13, "type": "code", "linesLength": 4, "startIndex": 24, "lines": ["try:\n", "    pd.concat([s1, s2], verify_integrity=True)\n", "except ValueError as e:\n", "    print(f\"erreur de concat\u00e9nation:\\n{e}\")"]}, {"block": 14, "type": "code", "linesLength": 3, "startIndex": 28, "lines": ["# cr\u00e9ons deux Series avec les index sans recouvrement\n", "s1 = pd.Series(range(1000), index=[chr(x) for x in range(1000)])\n", "s2 = pd.Series(range(1000), index=[chr(x+2000) for x in range(1000)])"]}, {"block": 15, "type": "code", "linesLength": 2, "startIndex": 31, "lines": ["# temps de concat\u00e9nation avec v\u00e9rification des recouvrements\n", "%timeit pd.concat([s1, s2], verify_integrity=True)"]}, {"block": 16, "type": "code", "linesLength": 2, "startIndex": 33, "lines": ["# temps de concat\u00e9nation sans v\u00e9rification des recouvrements\n", "%timeit pd.concat([s1, s2])"]}, {"block": 17, "type": "markdown", "linesLength": 1, "startIndex": 35, "lines": ["Par d\u00e9faut, `concat` concat\u00e8ne les lignes, c'est-\u00e0-dire que `s2` sera sous `s1`, mais on peut changer ce comportement en utilisant l'argument `axis`\u00a0:"]}, {"block": 18, "type": "code", "linesLength": 2, "startIndex": 36, "lines": ["p1 = pd.DataFrame(np.random.randint(1, 10, size=(2,2)), columns=list('ab'), index=list('xy'))\n", "p2 = pd.DataFrame(np.random.randint(1, 10, size=(2,2)), columns=list('ab'), index=list('zt'))"]}, {"block": 19, "type": "code", "linesLength": 1, "startIndex": 38, "lines": ["p1"]}, {"block": 20, "type": "code", "linesLength": 1, "startIndex": 39, "lines": ["p2"]}, {"block": 21, "type": "code", "linesLength": 3, "startIndex": 40, "lines": ["# \u00e9quivalent \u00e0 pd.concat([p1, p2], axis=0)\n", "# concat\u00e9nation des lignes\n", "pd.concat([p1, p2])"]}, {"block": 22, "type": "code", "linesLength": 2, "startIndex": 43, "lines": ["p1 = pd.DataFrame(np.random.randint(1, 10, size=(2,2)), columns=list('ab'), index=list('xy'))\n", "p2 = pd.DataFrame(np.random.randint(1, 10, size=(2,2)), columns=list('cd'), index=list('xy'))"]}, {"block": 23, "type": "code", "linesLength": 1, "startIndex": 45, "lines": ["p1"]}, {"block": 24, "type": "code", "linesLength": 1, "startIndex": 46, "lines": ["p2"]}, {"block": 25, "type": "code", "linesLength": 2, "startIndex": 47, "lines": ["# concat\u00e9nation des colonnes\n", "pd.concat([p1, p2], axis=1)"]}, {"block": 26, "type": "markdown", "linesLength": 1, "startIndex": 49, "lines": ["Regardons maintenant ce cas\u00a0:"]}, {"block": 27, "type": "code", "linesLength": 1, "startIndex": 50, "lines": ["pd.concat([p1, p2])"]}, {"block": 28, "type": "markdown", "linesLength": 1, "startIndex": 51, "lines": ["Vous remarquez que lors de la concat\u00e9nation, on prend l'union des tous les labels des index de `p1` et `p2`, il y a donc des valeurs absentes qui sont mises \u00e0 `NaN`. On peut contr\u00f4ler ce comportement de plusieurs mani\u00e8res comme nous allons le voir ci-dessous."]}, {"block": 29, "type": "markdown", "linesLength": 1, "startIndex": 52, "lines": ["Par d\u00e9faut (ce que l'on a fait ci-dessus), join utilise la strat\u00e9gie dite `outer`, c'est-\u00e0-dire qu'on prend l'union des labels."]}, {"block": 30, "type": "code", "linesLength": 6, "startIndex": 53, "lines": ["# on concat\u00e8ne les lignes, l'argument join d\u00e9cide quels labels on garde\n", "# sur l'autre axe  (ici sur les colonnes).\n", "\n", "# si on sp\u00e9cifie 'inner' on prend l'intersection des labels\n", "# du coup il ne reste rien ..\n", "pd.concat([p1, p2], join='inner')"]}, {"block": 31, "type": "markdown", "linesLength": 1, "startIndex": 59, "lines": ["Avec `join_axes`, on peut sp\u00e9cifier les labels qu'on veut garder, sous la forme d'un objet `Index`\u00a0:"]}, {"block": 32, "type": "code", "linesLength": 1, "startIndex": 60, "lines": ["pd.concat([p1, p2], join_axes=[p1.columns])"]}, {"block": 33, "type": "code", "linesLength": 2, "startIndex": 61, "lines": ["# du coup je peux choisir tr\u00e8s finement\n", "pd.concat([p1, p2], join_axes=[pd.Index(['a', 'c'])])"]}, {"block": 34, "type": "markdown", "linesLength": 5, "startIndex": 63, "lines": ["Notons que les `Series` et `DataFrame` ont une m\u00e9thode `append` qui est un raccourci vers `concat`, mais avec moins d'options.\n", "\n", "Pour aller plus loin, voici la documentation officielle\u00a0:\n", "\n", "http://pandas.pydata.org/pandas-docs/stable/merging.html#concatenating-objects"]}, {"block": 35, "type": "markdown", "linesLength": 1, "startIndex": 68, "lines": ["### Jointures avec `merge`"]}, {"block": 36, "type": "markdown", "linesLength": 1, "startIndex": 69, "lines": ["`merge` est dans l'esprit similaire au `JOIN` en SQL. L'id\u00e9e est de combiner deux `DataFrame` en fonction d'un crit\u00e8re d'\u00e9galit\u00e9 sur des colonnes. Regardons un exemple."]}, {"block": 37, "type": "code", "linesLength": 4, "startIndex": 70, "lines": ["df1 = pd.DataFrame({'employee': ['Bob', 'Lisa', 'Sue'],\n", "                    'group': ['Accounting', 'Engineering', 'HR']})\n", "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Sue'],\n", "                    'hire_date': [2004, 2008, 2014]})"]}, {"block": 38, "type": "code", "linesLength": 1, "startIndex": 74, "lines": ["df1"]}, {"block": 39, "type": "code", "linesLength": 1, "startIndex": 75, "lines": ["df2"]}, {"block": 40, "type": "markdown", "linesLength": 1, "startIndex": 76, "lines": ["On souhaite ici combiner `df1` et `df2` de mani\u00e8re \u00e0 ce que les lignes contenant le m\u00eame _employee_ soient align\u00e9es. Notre crit\u00e8re de merge est donc l'\u00e9galit\u00e9 des labels sur la colonne _employee_."]}, {"block": 41, "type": "code", "linesLength": 1, "startIndex": 77, "lines": ["pd.merge(df1, df2)"]}, {"block": 42, "type": "markdown", "linesLength": 1, "startIndex": 78, "lines": ["Par d\u00e9faut, `merge` fait un *inner join* (ou jointure interne) en utilisant comme crit\u00e8re de jointure les colonnes de m\u00eame nom (ici `employee`). *inner join* veut dire que pour joindre deux lignes il faut que le m\u00eame `employee` apparaisse dans les deux `DataFrame`."]}, {"block": 43, "type": "markdown", "linesLength": 9, "startIndex": 79, "lines": ["Il existe trois type de merges\u00a0:\n", "\n", "- one-to-one, c'est celui que l'on vient de voir. C'est le merge lorqu'il n'y a pas de labels dupliqu\u00e9s dans les colonnes utilis\u00e9es comme crit\u00e8re de merge\u00a0;\n", "\n", "- many-to-one, c'est le merge lorsque l'une des deux colonnes contient des labels dupliqu\u00e9s, dans ce cas, on applique la strat\u00e9gie one-to-one pour chaque label dupliqu\u00e9, donc les entr\u00e9es dupliqu\u00e9es sont pr\u00e9serv\u00e9es\u00a0;\n", "\n", "- many-to-many, c'est la strat\u00e9gie lorsqu'il y a des entr\u00e9es dupliqu\u00e9es dans les deux colonnes. Dans ce cas, on fait un produit cart\u00e9sien des lignes.\n", "\n", "D'une mani\u00e8re g\u00e9n\u00e9rale, gardez en t\u00eate que pandas fait essentiellement ce \u00e0 quoi on s'attend. Regardons cela sur des exemples."]}, {"block": 44, "type": "code", "linesLength": 4, "startIndex": 88, "lines": ["df1 = pd.DataFrame({'patient': ['Bob', 'Lisa', 'Sue'],\n", "                    'repas': ['SS', 'SS', 'SSR']})\n", "df2 = pd.DataFrame({'repas': ['SS', 'SSR'],\n", "                    'explication': ['sans sel', 'sans sucre']})"]}, {"block": 45, "type": "code", "linesLength": 1, "startIndex": 92, "lines": ["df1"]}, {"block": 46, "type": "code", "linesLength": 1, "startIndex": 93, "lines": ["df2"]}, {"block": 47, "type": "code", "linesLength": 3, "startIndex": 94, "lines": ["# la colonne commune pour le merge est 'repas' et dans une des colonnes\n", "# (sur df1), il y a des labels dupliqu\u00e9s, on applique la strat\u00e9gie many-to-one\n", "pd.merge(df1, df2)"]}, {"block": 48, "type": "code", "linesLength": 4, "startIndex": 97, "lines": ["df1 = pd.DataFrame({'patient': ['Bob', 'Lisa', 'Sue'],\n", "                    'repas': ['SS', 'SS', 'SSR']})\n", "df2 = pd.DataFrame({'repas': ['SS', 'SS', 'SSR'],\n", "                    'explication': ['sans sel', 'l\u00e9gumes', 'sans sucre']})"]}, {"block": 49, "type": "code", "linesLength": 1, "startIndex": 101, "lines": ["df1"]}, {"block": 50, "type": "code", "linesLength": 1, "startIndex": 102, "lines": ["df2"]}, {"block": 51, "type": "code", "linesLength": 3, "startIndex": 103, "lines": ["# la colonne commune pour le merge est 'repas' et dans les deux colonnes\n", "# il y a des labels dupliqu\u00e9s, on applique la strat\u00e9gie many-to-many\n", "pd.merge(df1,df2)"]}, {"block": 52, "type": "markdown", "linesLength": 1, "startIndex": 106, "lines": ["Dans un merge, on peut contr\u00f4ler les colonnes \u00e0 utiliser comme crit\u00e8re de merge. Regardons ces diff\u00e9rents cas sur des exemples."]}, {"block": 53, "type": "code", "linesLength": 4, "startIndex": 107, "lines": ["df1 = pd.DataFrame({'employee': ['Bob', 'Lisa', 'Sue'],\n", "                    'group': ['Accounting', 'Engineering', 'HR']})\n", "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Sue'],\n", "                    'hire_date': [2004, 2008, 2014]})"]}, {"block": 54, "type": "code", "linesLength": 1, "startIndex": 111, "lines": ["df1"]}, {"block": 55, "type": "code", "linesLength": 1, "startIndex": 112, "lines": ["df2"]}, {"block": 56, "type": "code", "linesLength": 2, "startIndex": 113, "lines": ["# on d\u00e9cide d'utiliser la colonne 'employee' comme crit\u00e8re de merge\n", "pd.merge(df1, df2, on='employee')"]}, {"block": 57, "type": "code", "linesLength": 4, "startIndex": 115, "lines": ["df1 = pd.DataFrame({'employee': ['Bob', 'Lisa', 'Sue'],\n", "                    'group': ['Accounting', 'Engineering', 'HR']})\n", "df2 = pd.DataFrame({'name': ['Lisa', 'Bob', 'Sue'],\n", "                    'hire_date': [2004, 2008, 2014]})"]}, {"block": 58, "type": "code", "linesLength": 1, "startIndex": 119, "lines": ["df1"]}, {"block": 59, "type": "code", "linesLength": 1, "startIndex": 120, "lines": ["df2"]}, {"block": 60, "type": "code", "linesLength": 4, "startIndex": 121, "lines": ["# mais on peut \u00e9galement d\u00e9finir un nom de colonne diff\u00e9rent\n", "# \u00e0 gauche et \u00e0 droite\n", "m = pd.merge(df1,df2, left_on='employee', right_on='name')\n", "m"]}, {"block": 61, "type": "code", "linesLength": 3, "startIndex": 125, "lines": ["# dans ce cas, comme on garde les colonnes utilis\u00e9es comme crit\u00e8re dans\n", "# le r\u00e9sultat du merge, on peut effacer la colonne inutile ainsi\n", "m.drop('name', axis=1)"]}, {"block": 62, "type": "markdown", "linesLength": 1, "startIndex": 128, "lines": ["`merge` permet \u00e9galement de contr\u00f4ler la strat\u00e9gie \u00e0 appliquer lorsqu'il y a des valeurs dans une colonne utilis\u00e9e comme crit\u00e8re de merge qui sont absentes dans l'autre colonne. C'est ce que l'on appelle jointure \u00e0 gauche, jointure \u00e0 droite, jointure interne (comportement par d\u00e9faut) et jointure externe. Pour ceux qui ne sont pas familiers avec ces notions, regardons des exemples."]}, {"block": 63, "type": "code", "linesLength": 4, "startIndex": 129, "lines": ["df1 = pd.DataFrame({'name': ['Bob', 'Lisa', 'Sue'],\n", "                    'pulse': [70, 63, 81]})\n", "df2 = pd.DataFrame({'name': ['Eric', 'Bob', 'Marc'],\n", "                    'weight': [60, 100, 70]})"]}, {"block": 64, "type": "code", "linesLength": 1, "startIndex": 133, "lines": ["df1"]}, {"block": 65, "type": "code", "linesLength": 1, "startIndex": 134, "lines": ["df2"]}, {"block": 66, "type": "code", "linesLength": 5, "startIndex": 135, "lines": ["# la colonne 'name' est le crit\u00e8re de merge dans les deux DataFrame.\n", "# Seul Bob existe dans les deux colonnes. Dans un inner join\n", "# (le cas par d\u00e9faut) on ne garde que les lignes pour lesquelles il y a une\n", "# m\u00eame valeur pr\u00e9sente \u00e0 gauche et \u00e0 droite\n", "pd.merge(df1, df2) # \u00e9quivalent \u00e0 pd.merge(df1, df2, how='inner')"]}, {"block": 67, "type": "code", "linesLength": 3, "startIndex": 140, "lines": ["# le outer join va au contraire faire une union des lignes et compl\u00e9ter ce\n", "# qui manque avec NaN\n", "pd.merge(df1, df2, how='outer')"]}, {"block": 68, "type": "code", "linesLength": 2, "startIndex": 143, "lines": ["# le left join ne garde que les valeurs de la colonne de gauche\n", "pd.merge(df1, df2, how='left')"]}, {"block": 69, "type": "code", "linesLength": 2, "startIndex": 145, "lines": ["# et le right join ne garde que les valeurs de la colonne de droite\n", "pd.merge(df1, df2, how='right')"]}, {"block": 70, "type": "markdown", "linesLength": 3, "startIndex": 147, "lines": ["Pour aller plus loin, vous pouvez lire la documentation. Vous verrez notamment que vous pouvez merger sur les indexes (au lieu des colonnes) ou le cas o\u00f9 vous avez des colonnes de m\u00eame nom qui ne font pas partie du crit\u00e8re de merge\u00a0:\n", "\n", "http://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging"]}, {"block": 71, "type": "markdown", "linesLength": 1, "startIndex": 150, "lines": ["### Regroupement avec `groupby`"]}, {"block": 72, "type": "markdown", "linesLength": 8, "startIndex": 151, "lines": ["Regardons maintenant cette notion de groupement. Il s'agit d'une notion tr\u00e8s puissante avec de nombreuses options que nous ne couvrirons que partiellement.\n", "La logique derri\u00e8re `groupby` est de cr\u00e9er des groupes dans une `DataFrame` en fonction des valeurs d'une (ou plusieurs) colonne(s), toutes les lignes contenant la m\u00eame valeur sont dans le m\u00eame groupe. On peut ensuite appliquer \u00e0 chaque groupe des op\u00e9rations qui sont\u00a0:\n", "\n", "- soit des calculs sur chaque groupe\u00a0;\n", "- soit un filtre sur chaque groupe qui peut garder ou supprimer un groupe\u00a0;\n", "- soit une transformation qui va modifier tout le groupe (par exemple, pour centrer les valeurs sur la moyenne du groupe).\n", "\n", "Regardons quelques exemples."]}, {"block": 73, "type": "code", "linesLength": 2, "startIndex": 159, "lines": ["d = pd.DataFrame({'key': list('ABCABC'), 'val': range(6)})\n", "d"]}, {"block": 74, "type": "code", "linesLength": 3, "startIndex": 161, "lines": ["# utilisons comme colonne de groupement 'key'\n", "g = d.groupby('key')\n", "g"]}, {"block": 75, "type": "markdown", "linesLength": 1, "startIndex": 164, "lines": ["`groupby` produit un nouvel objet, mais ne fait aucun calcul. Les calculs seront affectu\u00e9s lors de l'appel d'une fonction sur ce nouvel objet. Par exemple, calculons la somme pour chaque groupe."]}, {"block": 76, "type": "code", "linesLength": 1, "startIndex": 165, "lines": ["g.sum()"]}, {"block": 77, "type": "markdown", "linesLength": 3, "startIndex": 166, "lines": ["`groupby` peut utiliser comme crit\u00e8re de groupement une colonne, une liste de colonnes, ou un index (c'est notamment utile pour les `Series`).\n", "\n", "Une particularit\u00e9 de `groupby` est que le crit\u00e8re de groupement devient un index dans le nouvel objet g\u00e9n\u00e9r\u00e9. L'avantage est que l'on a maintenant un acc\u00e8s optimis\u00e9 sur ce crit\u00e8re, mais l'inconv\u00e9nient est que sur certaines op\u00e9rations qui d\u00e9truisent l'index on peut perdre ce crit\u00e8re. On peut contr\u00f4ler ce comportement avec `as_index`."]}, {"block": 78, "type": "code", "linesLength": 2, "startIndex": 169, "lines": ["g = d.groupby('key', as_index=False)\n", "g.sum()"]}, {"block": 79, "type": "markdown", "linesLength": 1, "startIndex": 171, "lines": ["L'objet produit par `groupby` pemet de manipuler les groupes, regardons cela."]}, {"block": 80, "type": "code", "linesLength": 4, "startIndex": 172, "lines": ["d = pd.DataFrame({'key': list('ABCABC'),\n", "                  'val1': range(6),\n", "                  'val2' : range(100, 106)})\n", "d"]}, {"block": 81, "type": "code", "linesLength": 7, "startIndex": 176, "lines": ["g = d.groupby('key')\n", "\n", "# g.groups donne acc\u00e8s au dictionnaire des groupes,\n", "# les clefs sont le nom du groupe\n", "# et les valeurs les indexes des lignes\n", "# appartenant au groupe\n", "g.groups"]}, {"block": 82, "type": "code", "linesLength": 2, "startIndex": 183, "lines": ["# pour acc\u00e9der directement au groupe, on peut utiliser get_group\n", "g.get_group('A')"]}, {"block": 83, "type": "code", "linesLength": 3, "startIndex": 185, "lines": ["# on peut \u00e9galement filtrer un groupe par colonne\n", "# lors d'une op\u00e9ration\n", "g.sum()['val2']"]}, {"block": 84, "type": "code", "linesLength": 2, "startIndex": 188, "lines": ["# ou directement sur l'objet produit par groupby\n", "g['val2'].sum()"]}, {"block": 85, "type": "markdown", "linesLength": 1, "startIndex": 190, "lines": ["On peut \u00e9galement it\u00e9rer sur les groupes avec un boucle `for` classique"]}, {"block": 86, "type": "code", "linesLength": 6, "startIndex": 191, "lines": ["import seaborn as sns\n", "# on charge le fichier de donn\u00e9es des pourboires\n", "tips = sns.load_dataset('tips')\n", "\n", "# pour rappel\n", "tips.head()"]}, {"block": 87, "type": "code", "linesLength": 6, "startIndex": 197, "lines": ["# on groupe le DataFrame par jours\n", "g = tips.groupby('day')\n", "\n", "# on calcule la moyenne du pourboire par jour\n", "for (group, index) in g:\n", "    print(f\"On {group} the mean tip is {index['tip'].mean():.3}\")"]}, {"block": 88, "type": "markdown", "linesLength": 1, "startIndex": 203, "lines": ["L'objet produit par `groupby` supporte ce que l'on appelle le _dispatch_ de m\u00e9thodes. Si une m\u00e9thode n'est pas directement d\u00e9finie sur l'objet produit par `groupby`, elle est appel\u00e9e sur chaque groupe (il faut donc qu'elle soit d\u00e9finie sur les `DataFrame` ou les `Series`). Regardons cela."]}, {"block": 89, "type": "code", "linesLength": 11, "startIndex": 204, "lines": ["# on groupe par jour et on extrait uniquement la colonne 'total_bill'\n", "# pour chaque groupe\n", "g = tips.groupby('day')['total_bill']\n", "\n", "# on demande \u00e0 pandas d'afficher les float avec seulement deux chiffres\n", "# apr\u00e8s la virgule\n", "pd.set_option('display.float_format', '{:.2f}'.format)\n", "\n", "# on appelle describe() sur g, mais elle n'est pas d\u00e9finie sur cet objet,\n", "# elle va donc \u00eatre appel\u00e9e (dispatch) sur chaque groupe\n", "g.describe()"]}, {"block": 90, "type": "code", "linesLength": 5, "startIndex": 215, "lines": ["# Mais, il y a tout de m\u00eame un grand nombre de m\u00e9thodes\n", "# d\u00e9finies directement sur l'objet produit par le groupby\n", "\n", "methods = [x for x in dir(g) if not x.startswith('_')]\n", "f\"Le type {type(g).__name__} expose {len(methods)} m\u00e9thodes.\""]}, {"block": 91, "type": "code", "linesLength": 9, "startIndex": 220, "lines": ["# profitons de la mise en page des dataframes\n", "# pour afficher ces m\u00e9thodes sur plusieurs colonnes\n", "# on fait un peu de gymnastique\n", "# il y a d'ailleurs s\u00fbrement plus simple..\n", "columns = 7\n", "nb_methods = len(methods)\n", "nb_pad = (columns - nb_methods % columns) % columns\n", "\n", "array = np.array(methods + nb_pad * ['']).reshape((columns, -1))"]}, {"block": 92, "type": "code", "linesLength": 1, "startIndex": 229, "lines": ["pd.DataFrame(data=array.transpose())"]}, {"block": 93, "type": "markdown", "linesLength": 3, "startIndex": 230, "lines": ["Nous allons regarder la m\u00e9thode `aggregate` (dont l'alias est `agg`). Cette m\u00e9thode permet d'appliquer une fonction (ou liste de fonctions) \u00e0 chaque groupe avec la possibilit\u00e9 d'appliquer une fonction \u00e0 une colonne sp\u00e9cifique du groupe.\n", "\n", "Une subtilit\u00e9 de `aggregate` est que l'on peut passer soit un objet fonction, soit un nom de fonction sous forme d'une `str`. Pour que l'utilisation du nom de la fonction marche, il faut que la fonction soit d\u00e9finie sur l'objet produit par le `groupby` ou qu'elle soit d\u00e9finie sur les groupes (donc avec dispatching)."]}, {"block": 94, "type": "code", "linesLength": 3, "startIndex": 233, "lines": ["# calculons la moyenne et la variance pour chaque groupe\n", "# et chaque colonne num\u00e9rique\n", "tips.groupby('day').agg(['mean', 'std'])"]}, {"block": 95, "type": "code", "linesLength": 2, "startIndex": 236, "lines": ["# de mani\u00e8re \u00e9quivalente avec les objets fonctions\n", "tips.groupby('day').agg([np.mean, np.std])"]}, {"block": 96, "type": "code", "linesLength": 4, "startIndex": 238, "lines": ["# en appliquant une fonction diff\u00e9rente pour chaque colonne,\n", "# on passe alors un dictionnaire qui a pour clef le nom de la\n", "# colonne et pour valeur la fonction \u00e0 appliquer \u00e0 cette colonne\n", "tips.groupby('day').agg({'tip': np.mean, 'total_bill': np.std})"]}, {"block": 97, "type": "markdown", "linesLength": 1, "startIndex": 242, "lines": ["La m\u00e9thode `filter` a pour but de filtrer les groupes en fonction d'un crit\u00e8re. Mais attention, `filter` retourne **un sous ensemble des donn\u00e9es originales** dans lesquelles les \u00e9l\u00e9ments appartenant aux groupes filtr\u00e9s ont \u00e9t\u00e9 enlev\u00e9s."]}, {"block": 98, "type": "code", "linesLength": 2, "startIndex": 243, "lines": ["d = pd.DataFrame({'key': list('ABCABC'), 'val1': range(6), 'val2' : range(100, 106)})\n", "d"]}, {"block": 99, "type": "code", "linesLength": 2, "startIndex": 245, "lines": ["# regardons la somme par groupe\n", "d.groupby('key').sum()"]}, {"block": 100, "type": "code", "linesLength": 4, "startIndex": 247, "lines": ["# maintenant enlevons dans les donn\u00e9es originales toutes les lignes\n", "# pour lesquelles la somme de leur groupe est sup\u00e9rieur \u00e0 3\n", "# (ici le groupe A)\n", "d.groupby('key').filter(lambda x: x['val1'].sum() > 3)"]}, {"block": 101, "type": "markdown", "linesLength": 3, "startIndex": 251, "lines": ["La m\u00e9thode `transform` a pour but de retourner **un sous ensemble des donn\u00e9es originales** dans lesquelles une fonction a \u00e9t\u00e9 appliqu\u00e9e par groupe. Un usage classique est de centrer des valeurs par groupe, ou de remplacer les `NaN` d'un groupe par la valeur moyenne du groupe.\n", "\n", "Attention, `transform` ne doit pas faire de modifications en place, sinon le r\u00e9sultat peut \u00eatre faux. Faites donc bien attention de ne pas appliquer des fonctions qui font des modications en place."]}, {"block": 102, "type": "code", "linesLength": 3, "startIndex": 254, "lines": ["r = np.random.normal(0.5, 2, 4)\n", "d = pd.DataFrame({'key': list('ab'*2), 'data': r,'data2': r*2})\n", "d"]}, {"block": 103, "type": "code", "linesLength": 2, "startIndex": 257, "lines": ["# je groupe sur la colonne 'key'\n", "g = d.groupby('key')"]}, {"block": 104, "type": "code", "linesLength": 2, "startIndex": 259, "lines": ["# maintenant je centre chaque groupe par rapport \u00e0 sa moyenne\n", "g.transform(lambda x: x - x.mean())"]}, {"block": 105, "type": "markdown", "linesLength": 7, "startIndex": 261, "lines": ["Notez que la colonne `key` a disparu, ce comportement est expliqu\u00e9 ici\u00a0:\n", "\n", "http://pandas.pydata.org/pandas-docs/stable/groupby.html#automatic-exclusion-of-nuisance-columns\n", "\n", "Pour aller plus loin sur `groupby` vous pouvez lire la documentation\u00a0:\n", "\n", "http://pandas.pydata.org/pandas-docs/stable/groupby.html"]}, {"block": 106, "type": "markdown", "linesLength": 1, "startIndex": 268, "lines": ["### R\u00e9organisation des indexes avec `pivot`"]}, {"block": 107, "type": "markdown", "linesLength": 1, "startIndex": 269, "lines": ["Un mani\u00e8re de voir la notion de pivot est de consid\u00e9rer qu'il s'agit d'une extension de `groupy` \u00e0 deux dimensions. Pour illustrer cela, prenons un exemple en utilisant le jeux de donn\u00e9es seaborn sur les passagers du Titanic."]}, {"block": 108, "type": "code", "linesLength": 1, "startIndex": 270, "lines": ["titanic = sns.load_dataset('titanic')"]}, {"block": 109, "type": "code", "linesLength": 2, "startIndex": 271, "lines": ["# regardons le format de ce jeux de donn\u00e9es\n", "titanic.head()"]}, {"block": 110, "type": "code", "linesLength": 2, "startIndex": 273, "lines": ["# regardons maintenant le taux de survie par classe et par sex\n", "titanic.pivot_table('survived', index='class', columns='sex')"]}, {"block": 111, "type": "markdown", "linesLength": 9, "startIndex": 275, "lines": ["Je ne vais pas entrer plus dans le d\u00e9tail, mais vous voyez qu'il s'agit d'un outil tr\u00e8s puissant.\n", "\n", "Pour aller plus loin, vous pouvez regarder la documentation officielle\u00a0:\n", "\n", "http://pandas.pydata.org/pandas-docs/stable/reshaping.html\n", "\n", "mais vous aurez des exemples beaucoup plus parlant en regardant ces examples\u00a0:\n", "\n", "https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.09-Pivot-Tables.ipynb"]}, {"block": 112, "type": "markdown", "linesLength": 1, "startIndex": 284, "lines": ["### Gestion des s\u00e9ries temporelles"]}, {"block": 113, "type": "markdown", "linesLength": 5, "startIndex": 285, "lines": ["Il y a un sujet que je n'aborderai pas ici, mais qui est tr\u00e8s important pour certains usages, c'est la gestion des s\u00e9ries temporelles. Sachez que pandas supporte des index sp\u00e9cialis\u00e9s dans les s\u00e9ries temporelles et que par cons\u00e9quent toutes les op\u00e9rations qui consistent \u00e0 filtrer ou grouper par p\u00e9riode de temps sont support\u00e9es nativement par pandas.\n", "\n", "Je vous invite de nouveau \u00e0 regarder la documentation officielle de pandas \u00e0 ce sujet\u00a0:\n", "\n", "http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n"]}, {"block": 114, "type": "markdown", "linesLength": 1, "startIndex": 290, "lines": ["### Conclusion"]}, {"block": 115, "type": "markdown", "linesLength": 3, "startIndex": 291, "lines": ["Ce notebook cl\u00f4t notre survol de pandas. C'est un sujet vaste que nous avons d\u00e9j\u00e0 largement d\u00e9grossi. Pour aller plus loin vous avez \u00e9videmment la documentation officielle de pandas\u00a0:\n", "\n", "http://pandas.pydata.org/pandas-docs/stable/index.html"]}, {"block": 116, "type": "markdown", "linesLength": 7, "startIndex": 294, "lines": ["Mais vous avez aussi l'excellent livre de Jake VanderPlas \"Python Data Science Handbook\" qui est enti\u00e8rement disponible sous forme de notebooks en ligne\u00a0:\n", "\n", "https://github.com/jakevdp/PythonDataScienceHandbook\n", "\n", "Il s'agit d'un tr\u00e8s beau travail (c'est rare) utilisant les derni\u00e8res versions de python, pandas and numpy (c'est encore plus rare), fait par un physicien qui fait de la data science et qui a contribu\u00e9 au d\u00e9veloppement de nombreux modules de data science en Python.\n", "\n", "Je vous conseille par ailleurs, pour ceux qui sont \u00e0 l'aise en anglais, [une s\u00e9rie de 10 vid\u00e9os sur YouTube](https://www.youtube.com/watch?v=_ZEWDGpM-vM) publi\u00e9es par le m\u00eame Jake VanderPlas, o\u00f9 il \u00e9tudie un jeu de donn\u00e9es du d\u00e9but (chargement des donn\u00e9es) \u00e0 la fin (classification)."]}, {"block": 117, "type": "markdown", "linesLength": 5, "startIndex": 301, "lines": ["Pour finir, si vous voulez faire de la data science, il y a un livre incontournable\u00a0: \"An Introduction de Statistical Learning\" de G. James, D. Witten, T. Hastie, R. Tibshirani. Ce livre utilise R, mais vous pouvez facilement l'appliquer en utilisant pandas.\n", "\n", "Les auteurs mettent \u00e0 disposition gratuitement le PDF du livre ici\u00a0:\n", "\n", "http://www-bcf.usc.edu/~gareth/ISL/"]}, {"block": 118, "type": "markdown", "linesLength": 1, "startIndex": 306, "lines": ["N'oubliez pas, si ces ressources vous sont utiles, d'acheter ces livres pour supporter ces auteurs. Les ressources de grande qualit\u00e9 sont rares, elles demandent un travail \u00e9norme \u00e0 produire, elles doivent \u00eatre encourag\u00e9es et recompens\u00e9es."]}]